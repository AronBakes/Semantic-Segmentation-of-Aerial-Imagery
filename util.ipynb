{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfkCy82a_1IM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import itertools\n",
    "import copy\n",
    "import collections\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Input\n",
    "\n",
    "\n",
    "# --- Sanity ---\n",
    "def test_util_sanity():\n",
    "    print(\"‚úÖ from util.ipynb\")\n",
    "\n",
    "# Define the mapping from RGB color to class index and vice-versa\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,       # BUILDING\n",
    "    (145, 30, 180): 1,      # CLUTTER\n",
    "    (60, 180, 75): 2,       # VEGETATION\n",
    "    (245, 130, 48): 3,      # WATER\n",
    "    (255, 255, 255): 4,     # GROUND\n",
    "    (0, 130, 200): 5        # CAR\n",
    "}\n",
    "\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items()}\n",
    "NUM_CLASSES = len(COLOR_TO_CLASS)\n",
    "COLOR_PALETTE = np.array(list(COLOR_TO_CLASS.keys()), dtype=np.uint8)\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "\n",
    "# --- Visualisation ---\n",
    "def visualise_prediction(rgb, true_mask_onehot, pred_mask):\n",
    "    \"\"\"\n",
    "    Visualise prediction with magenta overlay for ignore regions.\n",
    "    \"\"\"\n",
    "    IGNORE_COLOR = (255, 0, 255)\n",
    "    CLASS_TO_COLOR = {\n",
    "        0: (230, 25, 75),    # Building\n",
    "        1: (145, 30, 180),   # Clutter\n",
    "        2: (60, 180, 75),    # Vegetation\n",
    "        3: (245, 130, 48),   # Water\n",
    "        4: (255, 255, 255),  # Background\n",
    "        5: (0, 130, 200),    # Car\n",
    "    }\n",
    "\n",
    "    ignore_mask = np.all(true_mask_onehot == 0, axis=-1)  # üü£ Detect ignored pixels\n",
    "\n",
    "    true_mask = np.argmax(true_mask_onehot, axis=-1)      # üî¢ Decode only after ignore_mask is made\n",
    "\n",
    "    h, w = true_mask.shape\n",
    "    true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for cid, col in CLASS_TO_COLOR.items():\n",
    "        true_rgb[true_mask == cid] = col\n",
    "        pred_rgb[pred_mask == cid] = col\n",
    "\n",
    "    # üü£ Overlay ignored regions\n",
    "    true_rgb[ignore_mask] = IGNORE_COLOR\n",
    "    pred_rgb[ignore_mask] = IGNORE_COLOR\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    axs[0].imshow(rgb)\n",
    "    axs[0].set_title(\"RGB Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(true_rgb)\n",
    "    axs[1].set_title(\"True Mask\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(pred_rgb)\n",
    "    axs[2].set_title(\"Predicted Mask\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Class Weights ---\n",
    "def compute_class_weights(generator):\n",
    "    pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n",
    "\n",
    "    for _, labels in generator:\n",
    "        flat = np.argmax(labels, axis=-1).flatten()\n",
    "        counts = np.bincount(flat, minlength=NUM_CLASSES)\n",
    "        pixel_counts[:len(counts)] += counts\n",
    "\n",
    "    total = np.sum(pixel_counts)\n",
    "    weights = total / (NUM_CLASSES * np.maximum(pixel_counts, 1))\n",
    "    weights = weights / np.sum(weights) * NUM_CLASSES\n",
    "    return tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "\n",
    "out_dir=\"/content/figs\"\n",
    "\n",
    "# --- Distribution ---\n",
    "def plot_class_distribution(class_counts, title=\"Class Distribution\"):\n",
    "    if isinstance(class_counts, dict):\n",
    "        pixel_counts = [class_counts.get(i, 0) for i in range(NUM_CLASSES)]\n",
    "    else:\n",
    "        pixel_counts = list(class_counts)\n",
    "\n",
    "    total_pixels = sum(pixel_counts)\n",
    "    if total_pixels == 0:\n",
    "        print(\"No pixels counted for class distribution plot.\")\n",
    "        return\n",
    "\n",
    "    class_names = [f\"{i}: {name}\" for i, name in enumerate(CLASS_NAMES)]\n",
    "    colours = [np.array(CLASS_TO_COLOR[i]) / 255.0 for i in range(NUM_CLASSES)]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(class_names, pixel_counts, color=colours, edgecolor='black')\n",
    "\n",
    "    max_height = max(pixel_counts)\n",
    "    plt.ylim(0, max_height * 1.15)  # Add 15% headroom above the tallest bar\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Pixel Count\")\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    for bar, count in zip(bars, pixel_counts):\n",
    "        percent = 100.0 * count / total_pixels\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + max_height * 0.01,\n",
    "            f\"{count:,}\\n({percent:.2f}%)\",\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=9\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"epoch_dist.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_class_distribution(generator, title=\"Class Distribution\", max_batches=32):\n",
    "    pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n",
    "    total_batches = 0\n",
    "\n",
    "    print(f\"\\nüìä {title}\")\n",
    "    print(f\"üîç Starting distribution scan (max {max_batches} batches)...\")\n",
    "\n",
    "    for i, (_, labels) in enumerate(generator):\n",
    "        if labels.size == 0:\n",
    "            print(f\"‚ö†Ô∏è Skipping empty batch at index {i}\")\n",
    "            continue\n",
    "        \n",
    "        flat = np.argmax(labels, axis=-1).flatten()\n",
    "        counts = np.bincount(flat, minlength=NUM_CLASSES)\n",
    "        pixel_counts[:len(counts)] += counts\n",
    "        total_batches += 1\n",
    "\n",
    "        if total_batches >= max_batches:\n",
    "            print(f\"‚úÖ Processed {total_batches} batches. Stopping early.\")\n",
    "            break\n",
    "\n",
    "    total_pixels = np.sum(pixel_counts)\n",
    "    if total_pixels == 0:\n",
    "        print(\"‚ùå No valid pixels found.\")\n",
    "        return\n",
    "\n",
    "    class_names = [\n",
    "        \"0: Building\", \"1: Clutter\", \"2: Vegetation\",\n",
    "        \"3: Water\", \"4: Background\", \"5: Car\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nüßÆ Total pixels processed: {total_pixels:,}\")\n",
    "    print(\"üìà Pixel Distribution (percentages):\\n\")\n",
    "    for i in range(NUM_CLASSES):\n",
    "        pct = (pixel_counts[i] / total_pixels) * 100\n",
    "        print(f\"Class {class_names[i]:<14} : {pct:6.2f}% ({pixel_counts[i]:,} px)\")\n",
    "\n",
    "    print(\"\\n‚úÖ Done.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =================================================================== \n",
    "# ------------------------------------------------------------------- \n",
    "# =================================================================== \n",
    "# ------------------------------------------------------------------- \n",
    "# =================================================================== \n",
    "# -------------------------------------------------------------------\n",
    "# =================================================================== \n",
    "\n",
    "\n",
    "\n",
    "# Class weights for 6 classes (0 to 5), based on imbalance\n",
    "weights = np.array([0.2374, 0.2374, 0.0356, 0.2374, 0.0148, 0.2374], dtype=np.float32)\n",
    "\n",
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    # Ensure inputs are float32\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Flatten predictions and ground truth\n",
    "    y_true_f = tf.reshape(y_true, [-1, 6])  # Shape: [batch_size * pixels, 6]\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, 6])\n",
    "    \n",
    "    # Compute intersection and union per class\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)  # Sum over pixels, per class\n",
    "    denominator = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0) + smooth\n",
    "    \n",
    "    # Dice score per class\n",
    "    dice = (2.0 * intersection + smooth) / denominator\n",
    "    \n",
    "    # Apply class weights and compute mean loss\n",
    "    weighted_dice = weights * dice\n",
    "    dice_loss = 1.0 - tf.reduce_mean(weighted_dice)\n",
    "    \n",
    "    return dice_loss\n",
    "\n",
    "# Categorical Focal Loss\n",
    "def categorical_focal_loss(gamma=2.0):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Ensure inputs are float32\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        # Clip predictions to avoid log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        # Compute cross-entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Focal factor: (1 - p_t)^gamma\n",
    "        focal_factor = tf.pow(1.0 - y_pred, gamma)\n",
    "        \n",
    "        # Weighted focal loss\n",
    "        loss = focal_factor * ce\n",
    "        \n",
    "        # Mean over classes and pixels\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "# Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return dice_loss(y_true, y_pred) + categorical_focal_loss(gamma=2.0)(y_true, y_pred)\n",
    "\n",
    "# Example: Compile model\n",
    "# model = your_model  # e.g., U-Net with 6 classes\n",
    "# model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
