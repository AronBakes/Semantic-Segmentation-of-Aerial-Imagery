{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfkCy82a_1IM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import itertools\n",
    "import copy\n",
    "import collections\n",
    "import h5py\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import hinge_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "# --- Sanity ---\n",
    "def test_util_sanity():\n",
    "    print(\"âœ… from util.ipynb\")\n",
    "\n",
    "# Define the mapping from RGB color to class index and vice-versa\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,       # BUILDING\n",
    "    (145, 30, 180): 1,      # CLUTTER\n",
    "    (60, 180, 75): 2,       # VEGETATION\n",
    "    (245, 130, 48): 3,      # WATER\n",
    "    (255, 255, 255): 4,     # GROUND\n",
    "    (0, 130, 200): 5        # CAR\n",
    "}\n",
    "\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items()}\n",
    "NUM_CLASSES = len(COLOR_TO_CLASS)\n",
    "COLOR_PALETTE = np.array(list(COLOR_TO_CLASS.keys()), dtype=np.uint8)\n",
    "\n",
    "# --- Visualisation ---\n",
    "def visualise_prediction(rgb, true_mask, pred_mask):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    axs[0].imshow(rgb)\n",
    "    axs[0].set_title(\"RGB Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(COLOR_PALETTE[true_mask])\n",
    "    axs[1].set_title(\"True Mask\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(COLOR_PALETTE[pred_mask])\n",
    "    axs[2].set_title(\"Predicted Mask\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Class Weights ---\n",
    "def compute_class_weights(generator):\n",
    "    pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n",
    "\n",
    "    for _, labels in generator:\n",
    "        flat = np.argmax(labels, axis=-1).flatten()\n",
    "        counts = np.bincount(flat, minlength=NUM_CLASSES)\n",
    "        pixel_counts[:len(counts)] += counts\n",
    "\n",
    "    total = np.sum(pixel_counts)\n",
    "    weights = total / (NUM_CLASSES * np.maximum(pixel_counts, 1))\n",
    "    weights = weights / np.sum(weights) * NUM_CLASSES\n",
    "    return tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "# --- Distribution Plot ---\n",
    "def plot_class_distribution(generator, title=\"Class Distribution\"):\n",
    "    pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n",
    "\n",
    "    for _, labels in generator:\n",
    "        if labels.size == 0:\n",
    "            continue\n",
    "        flat = np.argmax(labels, axis=-1).flatten()\n",
    "        counts = np.bincount(flat, minlength=NUM_CLASSES)\n",
    "        pixel_counts[:len(counts)] += counts\n",
    "\n",
    "    class_names = [\n",
    "        \"0: Building\",\n",
    "        \"1: Clutter\",\n",
    "        \"2: Vegetation\",\n",
    "        \"3: Water\",\n",
    "        \"4: Background\",\n",
    "        \"5: Car\"\n",
    "    ]\n",
    "\n",
    "    colours = [np.array(CLASS_TO_COLOR[i]) / 255.0 for i in range(NUM_CLASSES)]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(class_names, pixel_counts, color=colours, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Pixel Count\")\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Annotate bar values\n",
    "    for bar, count in zip(bars, pixel_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{count:,}\", \n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Class weights for 6 classes (0 to 5), based on imbalance\n",
    "weights = np.array([0.2374, 0.2374, 0.0356, 0.2374, 0.0148, 0.2374], dtype=np.float32)\n",
    "\n",
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    # Ensure inputs are float32\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Flatten predictions and ground truth\n",
    "    y_true_f = tf.reshape(y_true, [-1, 6])  # Shape: [batch_size * pixels, 6]\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, 6])\n",
    "    \n",
    "    # Compute intersection and union per class\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)  # Sum over pixels, per class\n",
    "    denominator = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0) + smooth\n",
    "    \n",
    "    # Dice score per class\n",
    "    dice = (2.0 * intersection + smooth) / denominator\n",
    "    \n",
    "    # Apply class weights and compute mean loss\n",
    "    weighted_dice = weights * dice\n",
    "    dice_loss = 1.0 - tf.reduce_mean(weighted_dice)\n",
    "    \n",
    "    return dice_loss\n",
    "\n",
    "# Categorical Focal Loss\n",
    "def categorical_focal_loss(gamma=2.0):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Ensure inputs are float32\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        # Clip predictions to avoid log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "        \n",
    "        # Compute cross-entropy\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        \n",
    "        # Focal factor: (1 - p_t)^gamma\n",
    "        focal_factor = tf.pow(1.0 - y_pred, gamma)\n",
    "        \n",
    "        # Weighted focal loss\n",
    "        loss = focal_factor * ce\n",
    "        \n",
    "        # Mean over classes and pixels\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "# Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return dice_loss(y_true, y_pred) + categorical_focal_loss(gamma=2.0)(y_true, y_pred)\n",
    "\n",
    "# Example: Compile model\n",
    "# model = your_model  # e.g., U-Net with 6 classes\n",
    "# model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
