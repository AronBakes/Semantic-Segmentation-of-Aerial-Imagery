{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **init**"
      ],
      "metadata": {
        "id": "dHvUUJxQo2Ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foyR1XBZ2inw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a504a84f-0d26-4735-bcd3-8af4cabe2a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: segmentation-models 1.0.1\n",
            "Uninstalling segmentation-models-1.0.1:\n",
            "  Successfully uninstalled segmentation-models-1.0.1\n",
            "Collecting segmentation-models==1.0.1\n",
            "  Using cached segmentation_models-1.0.1-py3-none-any.whl.metadata (938 bytes)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (2.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.14.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.4)\n",
            "Using cached segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: segmentation-models\n",
            "Successfully installed segmentation-models-1.0.1\n",
            "‚úÖ Drive already mounted.\n",
            "‚úÖ Dataset already extracted.\n",
            "üì¶ Copying SYNTHETIC dataset from /content/drive/MyDrive/Aerial Segmentation Machine Learning/synthetic_dataset_v1...\n"
          ]
        }
      ],
      "source": [
        "# --- Installs ---\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "# Uninstall the current segmentation-models\n",
        "!pip uninstall -y segmentation-models\n",
        "# Install a specific, potentially more compatible version\n",
        "!pip install segmentation-models==1.0.1\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "# Notebook execution\n",
        "import nbformat\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.ismount(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    print(\"‚úÖ Drive already mounted.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Extract Dataset from Drive ---\n",
        "import zipfile\n",
        "zip_path = \"/content/drive/MyDrive/Aerial Segmentation Machine Learning/chipped_data.zip\"\n",
        "extract_to = \"/content/chipped_data\"\n",
        "\n",
        "if not os.path.exists(extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"üì¶ Extracting {len(file_list)} files...\")\n",
        "        for file in tqdm(file_list, desc=\"üîì Unzipping\"):\n",
        "            zip_ref.extract(file, path=extract_to)\n",
        "    print(\"‚úÖ Dataset unzipped.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already extracted.\")\n",
        "\n",
        "\n",
        "# --- Copy SYNTHETIC Dataset from Drive to local workspace ---\n",
        "synth_source_dir = \"/content/drive/MyDrive/Aerial Segmentation Machine Learning/synthetic_dataset_v1\"\n",
        "synth_extract_to = \"/content/synthetic_dataset_v1\"\n",
        "\n",
        "if not os.path.exists(synth_extract_to):\n",
        "    if os.path.exists(synth_source_dir):\n",
        "        print(f\"üì¶ Copying SYNTHETIC dataset from {synth_source_dir}...\")\n",
        "\n",
        "        # 1. Find all files in the source directory recursively\n",
        "        files_to_copy = glob.glob(os.path.join(synth_source_dir, '**', '*'), recursive=True)\n",
        "        # Filter out directories, we only want to copy files\n",
        "        files_to_copy = [f for f in files_to_copy if os.path.isfile(f)]\n",
        "\n",
        "        # 2. Loop through each file with a tqdm progress bar\n",
        "        for src_path in tqdm(files_to_copy, desc=\"üñ®Ô∏è Copying files\"):\n",
        "            # Create the corresponding destination path\n",
        "            dest_path = src_path.replace(synth_source_dir, synth_extract_to)\n",
        "\n",
        "            # 3. Create the destination sub-directory if it doesn't exist\n",
        "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "\n",
        "            # 4. Copy the file\n",
        "            shutil.copy2(src_path, dest_path)\n",
        "\n",
        "        print(\"‚úÖ Synthetic dataset copied.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Synthetic dataset folder not found at {synth_source_dir}\")\n",
        "else:\n",
        "    print(\"‚úÖ Synthetic dataset already copied.\")\n",
        "\n",
        "\n",
        "'''\n",
        "zip_path = \"/content/drive/MyDrive/Aerial Segmentation Machine Learning/dataset-medium.zip\"\n",
        "extract_to = \"/content/dataset-medium\"\n",
        "\n",
        "if not os.path.exists(extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"üì¶ Extracting {len(file_list)} files...\")\n",
        "        for file in tqdm(file_list, desc=\"üîì Unzipping\"):\n",
        "            zip_ref.extract(file, path=extract_to)\n",
        "    print(\"‚úÖ Dataset unzipped.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already extracted.\")\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# --- Directories ---\n",
        "base_dir = \"/content/chipped_data/chipped_data\"\n",
        "\n",
        "train_image_dir = os.path.join(base_dir, \"train/images\")\n",
        "train_elev_dir  = os.path.join(base_dir, \"train/elevations\")\n",
        "train_label_dir = os.path.join(base_dir, \"train/labels\")\n",
        "\n",
        "out_dir = \"/content/figs\"\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "    print(f\"üìÇ Created directory: {out_dir}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Directory already exists: {out_dir}\")\n",
        "\n",
        "checkpoints = \"/content/checkpoints\"\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)\n",
        "    print(f\"üìÇ Created directory: {checkpoints}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Directory already exists: {checkpoints}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "_Nx1wOuM2m3g",
        "outputId": "485fd0e0-b9c7-4e5b-9ebe-381c06570ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n",
            "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-4ogp91eh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-4ogp91eh\n",
            "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pydensecrf\n",
            "  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp311-cp311-linux_x86_64.whl size=3440294 sha256=bd134d0ae7fe5f5de60c5c3cd5b536b05c4ccda2f7593ba11005bbd2bc217e24\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ypi_ujy_/wheels/ce/8e/34/6dcfa200a9e2ae3627d8009b8bd1ca9b24512bec50a93304de\n",
            "Successfully built pydensecrf\n",
            "Installing collected packages: pydensecrf\n",
            "Successfully installed pydensecrf-1.0\n",
            "‚úÖ CRF imports working!\n",
            "üì• Cloning public repo...\n",
            "Cloning into '/content/Semantic-Segmentation-of-Aerial-Imagery'...\n",
            "remote: Enumerating objects: 2459, done.\u001b[K\n",
            "remote: Counting objects: 100% (297/297), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 2459 (delta 228), reused 121 (delta 121), pack-reused 2162 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2459/2459), 14.59 MiB | 21.77 MiB/s, done.\n",
            "Resolving deltas: 100% (1625/1625), done.\n",
            "/content/Semantic-Segmentation-of-Aerial-Imagery\n",
            "üì• Importing util.ipynb\n",
            "üì• Importing segformer.ipynb\n",
            "üì• Importing models.ipynb\n",
            "üì• Importing callbacks.ipynb\n",
            "üì• Importing distribute.ipynb\n",
            "üì• Importing data.ipynb\n",
            "üì• Importing scoring.ipynb\n",
            "Segmentation Models: using `tf.keras` framework.\n",
            "üì• Importing training.ipynb\n",
            "üì• Importing models_gen.ipynb\n",
            "üì• Importing data_gen.ipynb\n",
            "üì• Importing train_generator.ipynb\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport tensorflow as tf\\nimport os\\nimport time\\nimport matplotlib.pyplot as plt\\nfrom tqdm import tqdm\\nfrom google.colab import drive # NEW: Import for Google Drive\\n\\n# --- Configuration ---\\nEPOCHS = 80\\nLAMBDA = 100\\n\\n# --- NEW: Define Google Drive paths ---\\nDRIVE_MOUNT_PATH = \\'/content/drive\\'\\n# This is the folder you specified for all outputs\\nDRIVE_OUTPUT_PATH = \\'/content/drive/MyDrive/Aerial Segmentation Machine Learning/data_gen\\'\\n# Create specific subdirectories for organization\\nDRIVE_CHECKPOINT_DIR = os.path.join(DRIVE_OUTPUT_PATH, \\'checkpoints\\')\\nDRIVE_IMAGE_DIR = os.path.join(DRIVE_OUTPUT_PATH, \\'image_samples\\')\\n\\n# --- Main Training Function ---\\ndef train(dataset, epochs):\\n    # --- NEW: Mount Drive and Create Directories ---\\n    print(\"üíΩ Mounting Google Drive...\")\\n    if not os.path.ismount(DRIVE_MOUNT_PATH):\\n        drive.mount(DRIVE_MOUNT_PATH)\\n    else:\\n        print(\"‚úÖ Drive already mounted.\")\\n\\n    os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)\\n    os.makedirs(DRIVE_IMAGE_DIR, exist_ok=True)\\n    print(f\"‚úÖ Outputs will be saved to: {DRIVE_OUTPUT_PATH}\")\\n    # ---\\n\\n    # Initialize models and optimizers (assumes these functions are in the global scope)\\n    generator = Generator()\\n    discriminator = Discriminator()\\n    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\\n    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\\n\\n    # Loss function\\n    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\\n\\n    def discriminator_loss(disc_real_output, disc_generated_output):\\n        # ... (loss logic is the same)\\n        real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\\n        generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\\n        return real_loss + generated_loss\\n\\n    def generator_loss(disc_generated_output, gen_output, target):\\n        # ... (loss logic is the same)\\n        gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\\n        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\\n        return gan_loss + (LAMBDA * l1_loss)\\n\\n    # The core training step function\\n    @tf.function\\n    def train_step(input_image, target):\\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\\n            gen_output = generator(input_image, training=True)\\n            disc_real_output = discriminator([input_image, target], training=True)\\n            disc_generated_output = discriminator([input_image, gen_output], training=True)\\n            gen_loss = generator_loss(disc_generated_output, gen_output, target)\\n            disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\\n\\n        generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\\n        discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\\n        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\\n        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\\n        return disc_loss, gen_loss\\n\\n    # Image generation/plotting function\\n    def generate_and_save_images(model, test_input, tar, epoch):\\n        prediction = model(test_input, training=True)\\n        plt.figure(figsize=(15, 5))\\n        display_list = [test_input[0], tar[0], prediction[0]]\\n        title = [\\'Input Label Map\\', \\'Ground Truth\\', \\'Generated Image\\']\\n        for i in range(3):\\n            plt.subplot(1, 3, i+1)\\n            plt.title(title[i])\\n            plt.imshow(display_list[i] * 0.5 + 0.5) # Denormalize for viewing\\n            plt.axis(\\'off\\')\\n        \\n        # NEW: Save plot directly to Google Drive\\n        save_path = os.path.join(DRIVE_IMAGE_DIR, f\\'image_at_epoch_{epoch+1:04d}.png\\')\\n        plt.savefig(save_path)\\n        plt.close()\\n\\n    # --- The Main Training Loop ---\\n    example_input, example_target = next(iter(dataset.take(1)))\\n    start_time_total = time.time()\\n\\n    for epoch in range(epochs):\\n        start_time_epoch = time.time()\\n        print(f\"--- Starting Epoch {epoch + 1}/{epochs} ---\")\\n        \\n        disc_loss_epoch, gen_loss_epoch = [], []\\n\\n        for input_image, target in tqdm(dataset, desc=f\"  Training...\"):\\n            disc_loss, gen_loss = train_step(input_image, target)\\n            disc_loss_epoch.append(disc_loss)\\n            gen_loss_epoch.append(gen_loss)\\n\\n        # Generate and save a sample image at the end of the epoch\\n        generate_and_save_images(generator, example_input, example_target, epoch)\\n        print(f\"‚úÖ Sample image for epoch {epoch+1} saved to Drive.\")\\n\\n        # --- NEW: Save models periodically to Google Drive ---\\n        if (epoch + 1) % 20 == 0:\\n            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\\n            gen_save_path = os.path.join(DRIVE_CHECKPOINT_DIR, f\\'gen_{timestamp}_epoch{epoch+1}.keras\\')\\n            disc_save_path = os.path.join(DRIVE_CHECKPOINT_DIR, f\\'disc_{timestamp}_epoch{epoch+1}.keras\\')\\n            \\n            generator.save(gen_save_path)\\n            discriminator.save(disc_save_path)\\n            print(f\"‚úÖ Saved models to Drive for epoch {epoch+1}.\")\\n        # ---\\n        \\n        print(f\\'Time for epoch {epoch + 1} is {time.time()-start_time_epoch:.2f} sec\\')\\n        print(f\\'  -> Avg Discriminator Loss: {tf.reduce_mean(disc_loss_epoch):.4f}, Avg Generator Loss: {tf.reduce_mean(gen_loss_epoch):.4f}\\')\\n\\n    # --- Final Save ---\\n    print(\"--- Training finished. Saving final models. ---\")\\n    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\\n    generator.save(os.path.join(DRIVE_CHECKPOINT_DIR, f\\'gen_final_{timestamp}_epoch{epochs}.keras\\'))\\n    discriminator.save(os.path.join(DRIVE_CHECKPOINT_DIR, f\\'disc_final_{timestamp}_epoch{epochs}.keras\\'))\\n    print(f\"‚úÖ Final models saved to: {DRIVE_CHECKPOINT_DIR}\")\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Speeds up training by setting native GPU calculations to float16\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Install build tools and dependencies\n",
        "'''\n",
        "!apt-get install -y build-essential python3-dev\n",
        "!pip install cython\n",
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
        "print(\"‚úÖ CRF imports working!\")\n",
        "'''\n",
        "\n",
        "\n",
        "# GitHub repo details\n",
        "repo_owner = \"AronBakes\"\n",
        "repo_name = \"Semantic-Segmentation-of-Aerial-Imagery\"\n",
        "branch = \"master\"\n",
        "repo_url = f\"https://github.com/{repo_owner}/{repo_name}.git\"\n",
        "repo_dir = f\"/content/{repo_name}\"\n",
        "\n",
        "# Clone or pull repo\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(f\"üì• Cloning code from {repo_name}...\")\n",
        "    !git clone -b {branch} --depth 1 {repo_url} {repo_dir}\n",
        "else:\n",
        "    print(\"üîÑ Pulling latest code from GitHub...\")\n",
        "    %cd {repo_dir}\n",
        "    !git pull origin {branch}\n",
        "\n",
        "# Change directory into the repo to make sure paths are correct\n",
        "%cd {repo_dir}\n",
        "\n",
        "# Define the list of notebooks to load into the workspace\n",
        "notebooks_to_import = [\n",
        "    \"util.ipynb\",\n",
        "    \"data.ipynb\",\n",
        "    \"distribute.ipynb\",\n",
        "    \"models.ipynb\",\n",
        "    \"callbacks.ipynb\",\n",
        "    \"scoring.ipynb\",\n",
        "    \"training.ipynb\",\n",
        "    \"data_gan.ipynb\",\n",
        "    \"models_gan.ipynb\",\n",
        "    \"train_generator.ipynb\"\n",
        "]\n",
        "\n",
        "# Define the function to run notebook cells\n",
        "def run_notebook_cells(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        nb = nbformat.read(f, as_version=4)\n",
        "        shell = InteractiveShell.instance()\n",
        "        for cell in nb.cells:\n",
        "            if cell.cell_type == 'code' and cell.source: # Ensure source is not empty\n",
        "                shell.run_cell(cell.source)\n",
        "\n",
        "# Load and run all notebooks to define functions and classes globally\n",
        "print(\"\\n--- Loading all project notebooks into the workspace ---\")\n",
        "for nb_file in notebooks_to_import:\n",
        "    nb_path = os.path.join(repo_dir, nb_file)\n",
        "    if os.path.exists(nb_path):\n",
        "        print(f\"  -> Importing {nb_file}...\")\n",
        "        run_notebook_cells(nb_path)\n",
        "    else:\n",
        "        print(f\"  -> ‚ö†Ô∏è Warning: Notebook not found at {nb_path}\")\n",
        "\n",
        "print(\"\\n‚úÖ Setup complete. All functions and classes are loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentation Model Training**"
      ],
      "metadata": {
        "id": "tBYy4Vt0pQY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOv5JCv02qH6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "\n",
        "# --- Training ---\n",
        "train_unet(\n",
        "    base_dir=base_dir, out_dir=out_dir,\n",
        "    input_type=\"rgb\",\n",
        "    model_type=\"enhanced_unet\",\n",
        "    batch_size=32,\n",
        "    epochs=150,\n",
        "    train_time=240,\n",
        "    tile_size=512,\n",
        "    verbose=1,\n",
        "    yummy=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Synthetic Data Generation**"
      ],
      "metadata": {
        "id": "Ox2ceOk2pFEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# The path to your saved generator model.\n",
        "# Use the latest/best one from your training run.\n",
        "# From your screenshot, 'gen_final_20250625-085333_epoch80.keras' is a good choice.\n",
        "GENERATOR_MODEL_PATH = '/content/drive/MyDrive/Aerial Segmentation Machine Learning/data_gen/checkpoints/gen_final_20250625-085333_epoch80.keras'\n",
        "\n",
        "# The path to your real chipped data, where the label maps are.\n",
        "CHIPPED_DATA_DIR = '/content/chipped_data/chipped_data'\n",
        "\n",
        "# The NEW directory on your Drive where the final synthetic dataset will be saved.\n",
        "SYNTHETIC_DATASET_DIR = '/content/drive/MyDrive/Aerial Segmentation Machine Learning/synthetic_dataset_v1'\n",
        "\n",
        "# --- Setup Directories ---\n",
        "# Create the main output folder\n",
        "os.makedirs(SYNTHETIC_DATASET_DIR, exist_ok=True)\n",
        "# Create the subdirectories for images and labels\n",
        "SYNTHETIC_IMAGES_DIR = os.path.join(SYNTHETIC_DATASET_DIR, 'train', 'images')\n",
        "SYNTHETIC_LABELS_DIR = os.path.join(SYNTHETIC_DATASET_DIR, 'train', 'labels')\n",
        "os.makedirs(SYNTHETIC_IMAGES_DIR, exist_ok=True)\n",
        "os.makedirs(SYNTHETIC_LABELS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# --- Main Generation Logic ---\n",
        "\n",
        "print(\"--- Starting Synthetic Data Generation ---\")\n",
        "\n",
        "# 1. Load the trained generator model\n",
        "print(f\"Loading generator model from: {GENERATOR_MODEL_PATH}\")\n",
        "generator = tf.keras.models.load_model(GENERATOR_MODEL_PATH)\n",
        "print(\"‚úÖ Generator loaded successfully.\")\n",
        "\n",
        "# 2. Find all the real label maps to use as blueprints\n",
        "real_label_dir = os.path.join(CHIPPED_DATA_DIR, 'train', 'labels')\n",
        "label_paths = sorted(glob.glob(os.path.join(real_label_dir, '*.png')))\n",
        "print(f\"Found {len(label_paths)} label maps to use as blueprints.\")\n",
        "\n",
        "# 3. Loop, Generate, and Save\n",
        "for label_path in tqdm(label_paths, desc=\"Generating synthetic pairs\"):\n",
        "    try:\n",
        "        # Load the original label map\n",
        "        label_img_raw = tf.io.read_file(label_path)\n",
        "        label_img = tf.image.decode_png(label_img_raw, channels=3)\n",
        "\n",
        "        # Preprocess it for the GAN (normalize to [-1, 1])\n",
        "        label_tensor = tf.cast(label_img, tf.float32)\n",
        "        label_tensor = (label_tensor / 127.5) - 1\n",
        "\n",
        "        # The generator expects a batch, so add a batch dimension\n",
        "        input_tensor = tf.expand_dims(label_tensor, 0)\n",
        "\n",
        "        # Generate the synthetic RGB image\n",
        "        generated_image_tensor = generator(input_tensor, training=False)[0] # Get the first image from the batch\n",
        "\n",
        "        # Denormalize the output from [-1, 1] to [0, 255] for saving\n",
        "        generated_image_np = (generated_image_tensor * 0.5 + 0.5).numpy() * 255\n",
        "        generated_image_np = generated_image_np.astype('uint8')\n",
        "\n",
        "        # --- Save the new pair ---\n",
        "        base_filename = os.path.basename(label_path)\n",
        "\n",
        "        # Define the output paths\n",
        "        new_label_path = os.path.join(SYNTHETIC_LABELS_DIR, base_filename)\n",
        "        # Create the corresponding image filename\n",
        "        new_image_filename = base_filename.replace('-label.png', '-ortho.png')\n",
        "        new_image_path = os.path.join(SYNTHETIC_IMAGES_DIR, new_image_filename)\n",
        "\n",
        "        # Save the original label map (the blueprint)\n",
        "        # We need to convert the tensor back to an image file format\n",
        "        tf.keras.utils.save_img(new_label_path, tf.cast(label_img, tf.uint8).numpy())\n",
        "\n",
        "        # Save the newly generated synthetic RGB image\n",
        "        # Convert from RGB (for tensorflow) to BGR (for OpenCV/cv2)\n",
        "        generated_image_bgr = cv2.cvtColor(generated_image_np, cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(new_image_path, generated_image_bgr)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {label_path}. Error: {e}\")\n",
        "\n",
        "print(\"\\n--- Synthetic Data Generation Complete! ---\")\n",
        "print(f\"‚úÖ New dataset saved in: {SYNTHETIC_DATASET_DIR}\")"
      ],
      "metadata": {
        "id": "XAEVd0BK0RCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q05Ed20M1tS_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "if os.getcwd() not in sys.path:\n",
        "     sys.path.insert(0, os.getcwd())\n",
        "\n",
        "\n",
        "# --- 1. Define the exact paths to your saved models ---\n",
        "GEN_PATH = '/content/drive/MyDrive/Aerial Segmentation Machine Learning/data_gen/checkpoints/gen_final_20250625-085333_epoch80.keras'\n",
        "DISC_PATH = '/content/drive/MyDrive/Aerial Segmentation Machine Learning/data_gen/checkpoints/disc_final_20250625-085333_epoch80.keras'\n",
        "\n",
        "# --- 2. Define your training parameters ---\n",
        "# To train for another 70 epochs (from 80 to 150)\n",
        "START_EPOCH = 80\n",
        "TOTAL_EPOCHS = 150\n",
        "CHIPPED_DATA_DIR = '/content/chipped_data/chipped_data'\n",
        "\n",
        "# --- 3. Prepare dataset ---\n",
        "train_dataset = get_gan_dataset(CHIPPED_DATA_DIR, augment=True, shuffle=True)\n",
        "\n",
        "# --- 4. Call the train function ---\n",
        "train(\n",
        "    dataset=train_dataset,\n",
        "    epochs=TOTAL_EPOCHS,\n",
        "    generator_path=GEN_PATH,\n",
        "    discriminator_path=DISC_PATH,\n",
        "    initial_epoch=START_EPOCH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Other**"
      ],
      "metadata": {
        "id": "OfMVb_kVpd7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Distribution**"
      ],
      "metadata": {
        "id": "NDBkpAPnpZV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYVVU1420nU8"
      },
      "outputs": [],
      "source": [
        "df_full = csv_to_full_df()\n",
        "plot_class_distribution_from_df(df_full, \"Class Distribution\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}