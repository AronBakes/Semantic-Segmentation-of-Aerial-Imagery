{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-6gOfQHmAor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
    "    BatchNormalization, Activation, SpatialDropout2D, concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_flexible_unet(input_shape=(256, 256, 3), num_classes=6, freeze_rgb_encoder=True):\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "    inputs = Input(shape=input_shape, name=\"model_input\")\n",
    "\n",
    "    # --- Split RGB and Elevation ---\n",
    "    if input_shape[-1] == 4:\n",
    "        rgb = inputs[..., :3]\n",
    "        elev = inputs[..., 3:]\n",
    "    else:\n",
    "        rgb = inputs\n",
    "        elev = None\n",
    "\n",
    "    # --- ResNet50 Backbone (RGB encoder) ---\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=rgb, name=\"encoder\")\n",
    "    if freeze_rgb_encoder:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    x1 = base_model.get_layer(\"conv1_relu\").output        # 128x128\n",
    "    x2 = base_model.get_layer(\"conv2_block3_out\").output  # 64x64\n",
    "    x3 = base_model.get_layer(\"conv3_block4_out\").output  # 32x32\n",
    "    x4 = base_model.get_layer(\"conv4_block6_out\").output  # 16x16\n",
    "    x5 = base_model.get_layer(\"conv5_block3_out\").output  # 8x8\n",
    "\n",
    "    # --- Elevation Path ---\n",
    "    if elev is not None:\n",
    "        def elev_block(elev_input, size, filters):\n",
    "            x = Resizing(size, size)(elev_input)\n",
    "            x = Conv2D(filters, 3, padding=\"same\", activation=None)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = SpatialDropout2D(0.1)(x)\n",
    "            return x\n",
    "\n",
    "        # Initial processing\n",
    "        e = Conv2D(32, 3, padding=\"same\", activation=None)(elev)\n",
    "        e = BatchNormalization()(e)\n",
    "        e = Activation(\"relu\")(e)\n",
    "        e = SpatialDropout2D(0.1)(e)\n",
    "\n",
    "        # Merge elevation at multiple encoder stages\n",
    "        x1 = concatenate([x1, elev_block(e, 128, 64)])\n",
    "        x2 = concatenate([x2, elev_block(e, 64, 128)])\n",
    "        x3 = concatenate([x3, elev_block(e, 32, 256)])\n",
    "        x4 = concatenate([x4, elev_block(e, 16, 256)])\n",
    "\n",
    "    # --- Decoder Path ---\n",
    "    def decoder_block(x, skip, filters, drop_rate=0.2):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = concatenate([x, skip])\n",
    "        x = Conv2D(filters, 3, padding=\"same\", activation=None)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(drop_rate)(x)\n",
    "        return x\n",
    "\n",
    "    d1 = decoder_block(x5, x4, 256)\n",
    "    d2 = decoder_block(d1, x3, 256)\n",
    "    d3 = decoder_block(d2, x2, 128, 0.3)\n",
    "    d4 = decoder_block(d3, x1, 64, 0.3)\n",
    "\n",
    "    d5 = UpSampling2D()(d4)\n",
    "    d5 = Conv2D(32, 3, padding=\"same\", activation=None)(d5)\n",
    "    d5 = BatchNormalization()(d5)\n",
    "    d5 = Activation(\"relu\")(d5)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation=\"softmax\")(d5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape=(256, 256, 3), num_classes=6, dropout=0.05):\n",
    "    def conv_block(x, filters, dropout=dropout):\n",
    "        x_skip = x\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "    def decoder_block(x, skip, filters, dropout=dropout):\n",
    "        x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding=\"same\",\n",
    "                            kernel_regularizer=l2(1e-4))(x)\n",
    "        x = concatenate([x, skip])\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout)(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    n_filters = 64\n",
    "\n",
    "    # Encoder\n",
    "    c1, s1 = conv_block(inputs, n_filters, dropout=0.0)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2, s2 = conv_block(p1, n_filters * 2, dropout=0.00)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3, s3 = conv_block(p2, n_filters * 4, dropout=0.25)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4, s4 = conv_block(p3, n_filters * 8, dropout=0.4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5, _ = conv_block(p4, n_filters * 16, dropout=0.5)  # Heavier dropout\n",
    "\n",
    "    # Decoder\n",
    "    u6 = decoder_block(c5, s4, n_filters * 8, dropout=0.4)\n",
    "    u7 = decoder_block(u6, s3, n_filters * 4, dropout=0.3)\n",
    "    u8 = decoder_block(u7, s2, n_filters * 2, dropout=0.05)\n",
    "    u9 = decoder_block(u8, s1, n_filters, dropout=0.0)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", dtype=\"float32\")(u9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
    "    BatchNormalization, Activation, SpatialDropout2D, concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape=(256, 256, 3), num_classes=6) -> Model:\n",
    "    \"\"\"Builds an enhanced U-Net architecture with dropout and L2 regularisation.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the image, e.g., (256, 256, 3).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled U-Net model.\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_block(x, filters, dropout_rate):\n",
    "        \"\"\"Applies two convolutional layers with batch norm, ReLU and dropout.\"\"\"\n",
    "        x_skip = x\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "    def decoder_block(x, skip, filters, dropout_rate):\n",
    "        \"\"\"Upsamples and merges with skip connection, then applies conv block.\"\"\"\n",
    "        x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding=\"same\",\n",
    "                            kernel_regularizer=l2(1e-4))(x)\n",
    "        x = concatenate([x, skip])\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    n_filters = 64\n",
    "\n",
    "    # --- Encoder ---\n",
    "    c1, s1 = conv_block(inputs, n_filters, dropout_rate=0.05)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2, s2 = conv_block(p1, n_filters * 2, dropout_rate=0.1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3, s3 = conv_block(p2, n_filters * 4, dropout_rate=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4, s4 = conv_block(p3, n_filters * 8, dropout_rate=0.35)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5, _ = conv_block(p4, n_filters * 16, dropout_rate=0.5)  # Heavier dropout\n",
    "\n",
    "    # --- Decoder ---\n",
    "    u6 = decoder_block(c5, s4, n_filters * 8, dropout_rate=0.4)\n",
    "    u7 = decoder_block(u6, s3, n_filters * 4, dropout_rate=0.3)\n",
    "    u8 = decoder_block(u7, s2, n_filters * 2, dropout_rate=0.2)\n",
    "    u9 = decoder_block(u8, s1, n_filters, dropout_rate=0.1)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", dtype=\"float32\")(u9)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape: Tuple[int, int, int] = (256, 256, 3), num_classes: int = 6) -> Model:\n",
    "    \"\"\"Builds an enhanced U-Net architecture for semantic segmentation.\n",
    "\n",
    "    This U-Net implementation includes several enhancements over a basic U-Net:\n",
    "    -   Uses 'he_normal' kernel initializer for better weight initialization.\n",
    "    -   Applies L2 regularization to convolutional kernels to prevent overfitting.\n",
    "    -   Includes Batch Normalization after convolutions and before activation for\n",
    "        improved training stability and speed.\n",
    "    -   Uses ReLU activation functions throughout the encoder and decoder.\n",
    "    -   Incorporates Spatial Dropout 2D layers, with increasing dropout rates\n",
    "        in deeper encoder layers and decreasing rates in shallower decoder layers,\n",
    "        to further regularize the model and prevent overfitting.\n",
    "    -   The final output layer uses a 1x1 convolution with softmax activation\n",
    "        to produce class probabilities for each pixel.\n",
    "\n",
    "    Args:\n",
    "    input_shape: A `tuple` of three integers `(height, width, channels)`\n",
    "        specifying the input shape of the image tiles. Defaults to (256, 256, 3)\n",
    "        for RGB images.\n",
    "    num_classes: An `int` specifying the number of output classes for\n",
    "        segmentation. Defaults to 6.\n",
    "\n",
    "    Returns:\n",
    "    A `tf.keras.Model` instance representing the enhanced U-Net.\n",
    "    \"\"\"\n",
    "\n",
    "    def _conv_block(x: tf.Tensor, filters: int, dropout_rate: float) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"Applies two convolutional layers with batch normalization, ReLU, and spatial dropout.\n",
    "\n",
    "        This block is a building block for both the encoder and decoder paths. It\n",
    "        applies two 3x3 convolutions, each followed by Batch Normalization and ReLU\n",
    "        activation. Spatial Dropout 2D is applied at the end of the block.\n",
    "\n",
    "        Args:\n",
    "            x: The input `tf.Tensor` to the convolutional block.\n",
    "            filters: An `int` specifying the number of convolutional filters (output\n",
    "            channels) for the layers in this block.\n",
    "            dropout_rate: A `float` specifying the dropout rate for `SpatialDropout2D`.\n",
    "\n",
    "        Returns:\n",
    "            A `tuple` containing two `tf.Tensor` objects:\n",
    "            - The output of the convolutional block.\n",
    "            - The original input `x_skip` to this block, used for skip connections.\n",
    "        \"\"\"\n",
    "        x_skip = x # Store input for potential skip connection in the decoder.\n",
    "\n",
    "        # First convolutional layer\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\", # He initializer for ReLU activation.\n",
    "            kernel_regularizer=l2(1e-4), # L2 regularization to prevent overfitting.\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x) # Normalize activations to improve training speed and stability.\n",
    "        x = Activation(\"relu\")(x) # ReLU activation for non-linearity.\n",
    "\n",
    "        # Second convolutional layer\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Spatial Dropout 2D: drops entire 2D feature maps, effective for convolutional layers.\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "\n",
    "    def _decoder_block(x: tf.Tensor, skip_connection: tf.Tensor, filters: int, dropout_rate: float) -> tf.Tensor:\n",
    "        \"\"\"Performs upsampling, concatenates with a skip connection, and applies a conv block.\n",
    "\n",
    "        This block forms the decoding path of the U-Net. It first upsamples the input\n",
    "        using `Conv2DTranspose`, then concatenates it with the corresponding skip\n",
    "        connection from the encoder, and finally applies a convolutional block\n",
    "        (`_conv_block`) with the specified filters and dropout.\n",
    "\n",
    "        Args:\n",
    "            x: The input `tf.Tensor` from the previous decoder stage (low-resolution feature map).\n",
    "            skip_connection: The `tf.Tensor` from the corresponding encoder stage (high-resolution\n",
    "            feature map) used for concatenation.\n",
    "            filters: An `int` specifying the number of convolutional filters for the layers\n",
    "            in the internal conv block.\n",
    "            dropout_rate: A `float` specifying the dropout rate for `SpatialDropout2D`\n",
    "            within the internal conv block.\n",
    "\n",
    "        Returns:\n",
    "            A `tf.Tensor` representing the output of the decoder block.\n",
    "        \"\"\"\n",
    "        # Upsampling using Conv2DTranspose (transposed convolution).\n",
    "        x = Conv2DTranspose(\n",
    "            filters,\n",
    "            (2, 2), # Kernel size for upsampling.\n",
    "            strides=(2, 2), # Stride of 2 for upsampling.\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "\n",
    "        # Concatenate with the skip connection from the encoder path.\n",
    "        x = concatenate([x, skip_connection]) # Combines feature maps across resolutions.\n",
    "\n",
    "        # Apply two convolutional layers with batch norm, ReLU, and spatial dropout.\n",
    "        # Note: This is essentially a _conv_block without returning an x_skip.\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Define input layer for the model.\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Base number of filters for the first encoder block.\n",
    "    n_filters = 64\n",
    "\n",
    "    # --- Encoder Path ---\n",
    "    # Downsampling blocks. Each block consists of _conv_block followed by MaxPooling.\n",
    "    # Dropout rates are typically lower at shallower layers and increase deeper into the network.\n",
    "    c1, s1 = _conv_block(inputs, n_filters, dropout_rate=0.05) # c1 is output, s1 is skip connection.\n",
    "    p1 = MaxPooling2D((2, 2))(c1) # Halves spatial dimensions.\n",
    "\n",
    "    c2, s2 = _conv_block(p1, n_filters * 2, dropout_rate=0.1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3, s3 = _conv_block(p2, n_filters * 4, dropout_rate=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4, s4 = _conv_block(p3, n_filters * 8, dropout_rate=0.35)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- Bottleneck Layer ---\n",
    "    # The deepest part of the network, typically with the highest filter count and dropout.\n",
    "    c5, _ = _conv_block(p4, n_filters * 16, dropout_rate=0.5)\n",
    "\n",
    "    # --- Decoder Path ---\n",
    "    # Upsampling blocks. Each block consists of `_decoder_block`.\n",
    "    # Dropout rates typically decrease as the resolution increases.\n",
    "    u6 = _decoder_block(c5, s4, n_filters * 8, dropout_rate=0.4)\n",
    "    u7 = _decoder_block(u6, s3, n_filters * 4, dropout_rate=0.3)\n",
    "    u8 = _decoder_block(u7, s2, n_filters * 2, dropout_rate=0.2)\n",
    "    u9 = _decoder_block(u8, s1, n_filters, dropout_rate=0.1)\n",
    "\n",
    "    # Output layer: 1x1 convolution to map feature channels to `num_classes`,\n",
    "    # followed by softmax activation for probability distribution over classes.\n",
    "    # `dtype=\"float32\"` explicitly sets the output dtype, important for mixed precision.\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", dtype=\"float32\")(u9)\n",
    "\n",
    "    # Create the Keras Model.\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_multi_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "\n",
    "  inputs = Input(shape=input_shape)\n",
    "  source_input = inputs\n",
    "\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
    "  c1 = Dropout(0.2)(c1)\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "  p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "  c2 = Dropout(0.2)(c2)\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "  p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "  p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "  p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "  c5 = Dropout(0.2)(c5)\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "  c8 = Dropout(0.2)(c8)\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "  u9 = concatenate([u9, c1], axis=3)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "  c9 = Dropout(0.2)(c9)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "  outputs = Conv2D(num_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  return model\n",
    "     \n",
    "\n",
    "def build_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "    print(\"ðŸ§ª build_unet called with input_shape =\", input_shape)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    print(\"ðŸ§ª Input layer constructed with shape:\", inputs.shape)\n",
    "\n",
    "    # --- Contracting Path ---\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # --- Expansive Path ---\n",
    "    u6 = layers.UpSampling2D((2,2))(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D((2,2))(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.UpSampling2D((2,2))(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.UpSampling2D((2,2))(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    print(\"âœ… U-Net model built successfully.\")\n",
    "    print(\"ðŸ§ª Final model.input_shape =\", model.input_shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdEbicH3hTacctqMBAkyLk",
   "mount_file_id": "1O8D9sKuR6RRfxuisx8awj21FxGx_wScV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
