{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-6gOfQHmAor"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, UpSampling2D, \n",
    "    BatchNormalization, LeakyReLU, concatenate, Cropping2D\n",
    "    )\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# --- sanity ---\n",
    "def test_models_sanity():\n",
    "    print(\"âœ… from models.ipynb\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SegFormer_B0(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b0\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b0\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b0\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_unet_aux(input_shape=(256, 256, 3), num_classes=6):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    c1 = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = LeakyReLU()(c1)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), padding=\"same\")(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = LeakyReLU()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), padding=\"same\")(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = LeakyReLU()(c2)\n",
    "    c2 = Dropout(0.2)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), padding=\"same\")(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = LeakyReLU()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), padding=\"same\")(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = LeakyReLU()(c3)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), padding=\"same\")(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = LeakyReLU()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), padding=\"same\")(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = LeakyReLU()(c4)\n",
    "    c4 = Dropout(0.3)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), padding=\"same\")(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = LeakyReLU()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), padding=\"same\")(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = LeakyReLU()(c5)\n",
    "    c5 = Dropout(0.4)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), padding=\"same\")(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = LeakyReLU()(c5)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), padding=\"same\")(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = LeakyReLU()(c6)\n",
    "    c6 = Dropout(0.3)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), padding=\"same\")(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = LeakyReLU()(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), padding=\"same\")(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = LeakyReLU()(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), padding=\"same\")(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = LeakyReLU()(c7)\n",
    "\n",
    "    # Auxiliary output (upsample to final output size)\n",
    "    aux_out = UpSampling2D(size=(4, 4), interpolation='bilinear')(c7)\n",
    "    aux_out = Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"aux_output\")(aux_out)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), padding=\"same\")(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = LeakyReLU()(c8)\n",
    "    c8 = Dropout(0.2)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), padding=\"same\")(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = LeakyReLU()(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3, 3), padding=\"same\")(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = LeakyReLU()(c9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), padding=\"same\")(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = LeakyReLU()(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"main_output\")(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs, aux_out])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_multi_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "\n",
    "  inputs = Input(shape=input_shape)\n",
    "  source_input = inputs\n",
    "\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
    "  c1 = Dropout(0.2)(c1)\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "  p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "  c2 = Dropout(0.2)(c2)\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "  p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "  p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "  p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "  c5 = Dropout(0.2)(c5)\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "  c8 = Dropout(0.2)(c8)\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "  u9 = concatenate([u9, c1], axis=3)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "  c9 = Dropout(0.2)(c9)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "  outputs = Conv2D(num_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  return model\n",
    "     \n",
    "\n",
    "def build_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "    print(\"ðŸ§ª build_unet called with input_shape =\", input_shape)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    print(\"ðŸ§ª Input layer constructed with shape:\", inputs.shape)\n",
    "\n",
    "    # --- Contracting Path ---\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # --- Expansive Path ---\n",
    "    u6 = layers.UpSampling2D((2,2))(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D((2,2))(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.UpSampling2D((2,2))(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.UpSampling2D((2,2))(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    print(\"âœ… U-Net model built successfully.\")\n",
    "    print(\"ðŸ§ª Final model.input_shape =\", model.input_shape)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdEbicH3hTacctqMBAkyLk",
   "mount_file_id": "1O8D9sKuR6RRfxuisx8awj21FxGx_wScV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
