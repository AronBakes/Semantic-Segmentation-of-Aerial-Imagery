{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-6gOfQHmAor"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, concatenate,\n",
    "                                     BatchNormalization, Activation, SpatialDropout2D, Dropout, LeakyReLU, Cropping2D)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def build_flexible_unet(input_shape=(256, 256, 3), num_classes=6, freeze_rgb_encoder=True):\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "    from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D, concatenate, Dropout\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    # --- Input ---\n",
    "    inputs = Input(shape=input_shape, name=\"model_input\")\n",
    "\n",
    "    # --- Split RGB and Elevation ---\n",
    "    if input_shape[-1] == 4:\n",
    "        rgb = inputs[..., :3]\n",
    "        elev = inputs[..., 3:]\n",
    "    else:\n",
    "        rgb = inputs\n",
    "        elev = None\n",
    "\n",
    "    # --- ResNet50 Backbone ---\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=rgb, name=\"encoder\")\n",
    "    if freeze_rgb_encoder:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Encoder feature maps\n",
    "    x1 = base_model.get_layer(\"conv1_relu\").output       # 128x128\n",
    "    x2 = base_model.get_layer(\"conv2_block3_out\").output # 64x64\n",
    "    x3 = base_model.get_layer(\"conv3_block4_out\").output # 32x32\n",
    "    x4 = base_model.get_layer(\"conv4_block6_out\").output # 16x16\n",
    "    x5 = base_model.get_layer(\"conv5_block3_out\").output # 8x8\n",
    "\n",
    "    # --- Elevation branch ---\n",
    "    if elev is not None:\n",
    "        e = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(elev)     # 256x256\n",
    "        e = MaxPooling2D()(e)                                          # 128x128\n",
    "        e = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(e)        # 128x128\n",
    "        x1 = concatenate([x1, e])  # Match spatial shape with x1\n",
    "\n",
    "    # --- Decoder ---\n",
    "    d1 = UpSampling2D()(x5)\n",
    "    d1 = concatenate([d1, x4])\n",
    "    d1 = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(d1)\n",
    "    d1 = Dropout(0.2)(d1)\n",
    "\n",
    "    d2 = UpSampling2D()(d1)\n",
    "    d2 = concatenate([d2, x3])\n",
    "    d2 = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "\n",
    "    d3 = UpSampling2D()(d2)\n",
    "    d3 = concatenate([d3, x2])\n",
    "    d3 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "\n",
    "    d4 = UpSampling2D()(d3)\n",
    "    d4 = concatenate([d4, x1])\n",
    "    d4 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(d4)\n",
    "    d4 = Dropout(0.2)(d4)\n",
    "\n",
    "    d5 = UpSampling2D()(d4)\n",
    "    d5 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(d5)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation=\"softmax\")(d5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "\n",
    "def build_flexible_unet(input_shape=(256, 256, 3), num_classes=6, freeze_rgb_encoder=True):\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "    from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D, concatenate, Dropout\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    # --- Input ---\n",
    "    inputs = Input(shape=input_shape, name=\"model_input\")\n",
    "\n",
    "    # --- Split RGB and Elevation ---\n",
    "    if input_shape[-1] == 4:\n",
    "        rgb = inputs[..., :3]\n",
    "        elev = inputs[..., 3:]\n",
    "    else:\n",
    "        rgb = inputs\n",
    "        elev = None\n",
    "\n",
    "    # --- ResNet50 Backbone ---\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=rgb, name=\"encoder\")\n",
    "    if freeze_rgb_encoder:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Encoder feature maps\n",
    "    x1 = base_model.get_layer(\"conv1_relu\").output       # 128x128\n",
    "    x2 = base_model.get_layer(\"conv2_block3_out\").output # 64x64\n",
    "    x3 = base_model.get_layer(\"conv3_block4_out\").output # 32x32\n",
    "    x4 = base_model.get_layer(\"conv4_block6_out\").output # 16x16\n",
    "    x5 = base_model.get_layer(\"conv5_block3_out\").output # 8x8\n",
    "\n",
    "    # --- Elevation branch ---\n",
    "    if elev is not None:\n",
    "        # Downsample elevation to match encoder stages\n",
    "        e1 = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(elev)   # 256x256\n",
    "        e2 = MaxPooling2D()(e1)                                        # 128x128\n",
    "        e2 = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(e2)\n",
    "        e3 = MaxPooling2D()(e2)                                        # 64x64\n",
    "        e3 = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(e3)\n",
    "        e4 = MaxPooling2D()(e3)                                        # 32x32\n",
    "        e4 = Conv2D(16, 3, padding=\"same\", activation=\"relu\")(e4)\n",
    "\n",
    "        # Concatenate at multiple levels\n",
    "        x1 = concatenate([x1, e2])\n",
    "        x2 = concatenate([x2, e3])\n",
    "        x3 = concatenate([x3, e4])\n",
    "\n",
    "    # --- Decoder ---\n",
    "    d1 = UpSampling2D()(x5)\n",
    "    d1 = concatenate([d1, x4])\n",
    "    d1 = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(d1)\n",
    "    d1 = Dropout(0.2)(d1)\n",
    "\n",
    "    d2 = UpSampling2D()(d1)\n",
    "    d2 = concatenate([d2, x3])\n",
    "    d2 = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "\n",
    "    d3 = UpSampling2D()(d2)\n",
    "    d3 = concatenate([d3, x2])\n",
    "    d3 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "\n",
    "    d4 = UpSampling2D()(d3)\n",
    "    d4 = concatenate([d4, x1])\n",
    "    d4 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(d4)\n",
    "    d4 = Dropout(0.2)(d4)\n",
    "\n",
    "    d5 = UpSampling2D()(d4)\n",
    "    d5 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(d5)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation=\"softmax\")(d5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def build_flexible_unet(input_shape=(256, 256, 4), num_classes=6, freeze_rgb_encoder=True):\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "    from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D, concatenate, Dropout\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    # --- Input ---\n",
    "    inputs = Input(shape=input_shape, name=\"model_input\")\n",
    "\n",
    "    # --- Split RGB and Elevation ---\n",
    "    rgb = inputs[..., :3]\n",
    "    elev = inputs[..., 3:]\n",
    "\n",
    "    # --- ResNet50 Backbone ---\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=rgb, name=\"encoder\")\n",
    "    if freeze_rgb_encoder:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Encoder feature maps\n",
    "    x1 = base_model.get_layer(\"conv1_relu\").output       # 128x128\n",
    "    x2 = base_model.get_layer(\"conv2_block3_out\").output # 64x64\n",
    "    x3 = base_model.get_layer(\"conv3_block4_out\").output # 32x32\n",
    "    x4 = base_model.get_layer(\"conv4_block6_out\").output # 16x16\n",
    "    x5 = base_model.get_layer(\"conv5_block3_out\").output # 8x8\n",
    "\n",
    "    # --- Elevation branch ---\n",
    "    e1 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(elev)    # 256x256\n",
    "    e2 = MaxPooling2D()(e1)                                         # 128x128\n",
    "    e2 = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(e2)\n",
    "    e3 = MaxPooling2D()(e2)                                         # 64x64\n",
    "    e3 = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(e3)\n",
    "    e4 = MaxPooling2D()(e3)                                         # 32x32\n",
    "    e4 = Conv2D(512, 3, padding=\"same\", activation=\"relu\")(e4)\n",
    "    e5 = MaxPooling2D()(e4)                                         # 16x16\n",
    "    e5 = Conv2D(1024, 3, padding=\"same\", activation=\"relu\")(e5)\n",
    "\n",
    "    # --- Concatenate elevation with encoder ---\n",
    "    x1 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(concatenate([x1, e1]))\n",
    "    x2 = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(concatenate([x2, e2]))\n",
    "    x3 = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(concatenate([x3, e3]))\n",
    "    x4 = Conv2D(512, 3, padding=\"same\", activation=\"relu\")(concatenate([x4, e4]))\n",
    "    x5 = Conv2D(1024, 3, padding=\"same\", activation=\"relu\")(concatenate([x5, e5]))\n",
    "\n",
    "    # --- Decoder ---\n",
    "    d1 = UpSampling2D()(x5)\n",
    "    d1 = concatenate([d1, x4])\n",
    "    d1 = Conv2D(512, 3, padding=\"same\", activation=\"relu\")(d1)\n",
    "    d1 = Dropout(0.2)(d1)\n",
    "\n",
    "    d2 = UpSampling2D()(d1)\n",
    "    d2 = concatenate([d2, x3])\n",
    "    d2 = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "\n",
    "    d3 = UpSampling2D()(d2)\n",
    "    d3 = concatenate([d3, x2])\n",
    "    d3 = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "\n",
    "    d4 = UpSampling2D()(d3)\n",
    "    d4 = concatenate([d4, x1])\n",
    "    d4 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(d4)\n",
    "    d4 = Dropout(0.2)(d4)\n",
    "\n",
    "    d5 = UpSampling2D()(d4)\n",
    "    d5 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(d5)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation=\"softmax\")(d5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape=(256, 256, 4), num_classes=6, dropout_rate=0.2):\n",
    "    def conv_block(x, filters):\n",
    "        x_skip = x\n",
    "        x = Conv2D(filters, (3,3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3,3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "    def decoder_block(x, skip, filters):\n",
    "        x = Conv2DTranspose(filters, (2,2), strides=(2,2), padding=\"same\")(x)\n",
    "        x = concatenate([x, skip])\n",
    "        x = Conv2D(filters, (3,3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3,3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1, s1 = conv_block(inputs, 32)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2, s2 = conv_block(p1, 64)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3, s3 = conv_block(p2, 128)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4, s4 = conv_block(p3, 256)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5, _ = conv_block(p4, 512)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = decoder_block(c5, s4, 256)\n",
    "    u7 = decoder_block(u6, s3, 128)\n",
    "    u8 = decoder_block(u7, s2, 64)\n",
    "    u9 = decoder_block(u8, s1, 32)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1,1), activation=\"softmax\")(u9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_unet_aux(input_shape=(256, 256, 3), num_classes=6):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    c1 = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = LeakyReLU()(c1)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), padding=\"same\")(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = LeakyReLU()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), padding=\"same\")(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = LeakyReLU()(c2)\n",
    "    c2 = Dropout(0.2)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), padding=\"same\")(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = LeakyReLU()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), padding=\"same\")(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = LeakyReLU()(c3)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), padding=\"same\")(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = LeakyReLU()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), padding=\"same\")(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = LeakyReLU()(c4)\n",
    "    c4 = Dropout(0.3)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), padding=\"same\")(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = LeakyReLU()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), padding=\"same\")(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = LeakyReLU()(c5)\n",
    "    c5 = Dropout(0.4)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), padding=\"same\")(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = LeakyReLU()(c5)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), padding=\"same\")(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = LeakyReLU()(c6)\n",
    "    c6 = Dropout(0.3)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), padding=\"same\")(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = LeakyReLU()(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), padding=\"same\")(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = LeakyReLU()(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), padding=\"same\")(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = LeakyReLU()(c7)\n",
    "\n",
    "    # Auxiliary output (upsample to final output size)\n",
    "    aux_out = UpSampling2D(size=(4, 4), interpolation='bilinear')(c7)\n",
    "    aux_out = Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"aux_output\")(aux_out)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), padding=\"same\")(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = LeakyReLU()(c8)\n",
    "    c8 = Dropout(0.2)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), padding=\"same\")(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = LeakyReLU()(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3, 3), padding=\"same\")(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = LeakyReLU()(c9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), padding=\"same\")(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = LeakyReLU()(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"main_output\")(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs, aux_out])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_multi_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "\n",
    "  inputs = Input(shape=input_shape)\n",
    "  source_input = inputs\n",
    "\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
    "  c1 = Dropout(0.2)(c1)\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "  p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "  c2 = Dropout(0.2)(c2)\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "  p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "  p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "  p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "  c5 = Dropout(0.2)(c5)\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "  c8 = Dropout(0.2)(c8)\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "  u9 = concatenate([u9, c1], axis=3)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "  c9 = Dropout(0.2)(c9)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "  outputs = Conv2D(num_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  return model\n",
    "     \n",
    "\n",
    "def build_unet(input_shape=(256, 256, 3), num_classes=6):\n",
    "    print(\"ðŸ§ª build_unet called with input_shape =\", input_shape)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    print(\"ðŸ§ª Input layer constructed with shape:\", inputs.shape)\n",
    "\n",
    "    # --- Contracting Path ---\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # --- Expansive Path ---\n",
    "    u6 = layers.UpSampling2D((2,2))(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D((2,2))(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.UpSampling2D((2,2))(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.UpSampling2D((2,2))(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    print(\"âœ… U-Net model built successfully.\")\n",
    "    print(\"ðŸ§ª Final model.input_shape =\", model.input_shape)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdEbicH3hTacctqMBAkyLk",
   "mount_file_id": "1O8D9sKuR6RRfxuisx8awj21FxGx_wScV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
