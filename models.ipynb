{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-6gOfQHmAor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Input\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Cropping2D\n",
    "\n",
    "\n",
    "def test_models_sanity():\n",
    "    print(\"‚úÖ from models.ipynb\")\n",
    "\n",
    "\n",
    "def multi_unet_model(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Downsampling Path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    # Upsampling Path\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "    # Calculate the cropping amount needed to match c4's height and width\n",
    "    # Note: This assumes u6 is equal to or larger than c4\n",
    "    # If c4 is larger, the cropping should be applied to c4 or the upsampling adjusted\n",
    "    # Based on the error (36 vs 37), u6 is likely smaller, so adjust u6 size instead of cropping c4\n",
    "    # Let's adjust the Conv2DTranspose padding or stride if needed, or use UpSampling2D for simpler scaling.\n",
    "    # A simpler approach is often UpSampling2D followed by Conv2D, which explicitly doubles size.\n",
    "    # Let's switch to UpSampling2D + Conv2D for potentially more predictable sizing.\n",
    "\n",
    "    # Replace Conv2DTranspose with UpSampling2D + Conv2D\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = Conv2D(512, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "\n",
    "\n",
    "    # *** CROPPING ADDED HERE ***\n",
    "    # Get the target shape (height and width) from c4\n",
    "    target_h = tf.shape(c4)[1] # Height\n",
    "    target_w = tf.shape(c4)[2] # Width\n",
    "\n",
    "    # Get the current shape (height and width) of u6\n",
    "    current_h = tf.shape(u6)[1]\n",
    "    current_w = tf.shape(u6)[2]\n",
    "\n",
    "    # Calculate the amount to crop from top, bottom, left, right\n",
    "    # This handles cases where one dimension is slightly off.\n",
    "    # It crops symmetrically if the difference is even, or slightly unevenly if odd.\n",
    "    crop_h = current_h - target_h\n",
    "    crop_w = current_w - target_w\n",
    "\n",
    "    # Ensure crop values are non-negative before calculating padding\n",
    "    crop_h = tf.maximum(0, crop_h)\n",
    "    crop_w = tf.maximum(0, crop_w)\n",
    "\n",
    "    cropping_amount = ((crop_h // 2, crop_h - crop_h // 2),\n",
    "                       (crop_w // 2, crop_w - crop_w // 2))\n",
    "\n",
    "    # Only apply cropping if necessary\n",
    "    if crop_h > 0 or crop_w > 0:\n",
    "         u6 = Cropping2D(cropping=cropping_amount)(u6)\n",
    "         print(f\"‚ÑπÔ∏è Cropping u6 by {cropping_amount} to match c4 shape for concatenation.\")\n",
    "\n",
    "\n",
    "    # *** END CROPPING ***\n",
    "\n",
    "\n",
    "    u6 = concatenate([u6, c4]) # Now u6 and c4 should have matching spatial dimensions\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = Conv2D(256, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "\n",
    "    # *** CROPPING ADDED HERE ***\n",
    "    target_h = tf.shape(c3)[1]\n",
    "    target_w = tf.shape(c3)[2]\n",
    "    current_h = tf.shape(u7)[1]\n",
    "    current_w = tf.shape(u7)[2]\n",
    "\n",
    "    crop_h = tf.maximum(0, current_h - target_h)\n",
    "    crop_w = tf.maximum(0, current_w - target_w)\n",
    "    cropping_amount = ((crop_h // 2, crop_h - crop_h // 2),\n",
    "                       (crop_w // 2, crop_w - crop_w // 2))\n",
    "    if crop_h > 0 or crop_w > 0:\n",
    "        u7 = Cropping2D(cropping=cropping_amount)(u7)\n",
    "        print(f\"‚ÑπÔ∏è Cropping u7 by {cropping_amount} to match c3 shape for concatenation.\")\n",
    "    # *** END CROPPING ***\n",
    "\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = Conv2D(128, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "\n",
    "    # *** CROPPING ADDED HERE ***\n",
    "    target_h = tf.shape(c2)[1]\n",
    "    target_w = tf.shape(c2)[2]\n",
    "    current_h = tf.shape(u8)[1]\n",
    "    current_w = tf.shape(u8)[2]\n",
    "\n",
    "    crop_h = tf.maximum(0, current_h - target_h)\n",
    "    crop_w = tf.maximum(0, current_w - target_w)\n",
    "    cropping_amount = ((crop_h // 2, crop_h - crop_h // 2),\n",
    "                       (crop_w // 2, crop_w - crop_w // 2))\n",
    "    if crop_h > 0 or crop_w > 0:\n",
    "        u8 = Cropping2D(cropping=cropping_amount)(u8)\n",
    "        print(f\"‚ÑπÔ∏è Cropping u8 by {cropping_amount} to match c2 shape for concatenation.\")\n",
    "    # *** END CROPPING ***\n",
    "\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = Conv2D(64, (2, 2), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "\n",
    "    # *** CROPPING ADDED HERE ***\n",
    "    target_h = tf.shape(c1)[1]\n",
    "    target_w = tf.shape(c1)[2]\n",
    "    current_h = tf.shape(u9)[1]\n",
    "    current_w = tf.shape(u9)[2]\n",
    "\n",
    "    crop_h = tf.maximum(0, current_h - target_h)\n",
    "    crop_w = tf.maximum(0, current_w - target_w)\n",
    "    cropping_amount = ((crop_h // 2, crop_h - crop_h // 2),\n",
    "                       (crop_w // 2, crop_w - crop_w // 2))\n",
    "    if crop_h > 0 or crop_w > 0:\n",
    "        u9 = Cropping2D(cropping=cropping_amount)(u9)\n",
    "        print(f\"‚ÑπÔ∏è Cropping u9 by {cropping_amount} to match c1 shape for concatenation.\")\n",
    "    # *** END CROPPING ***\n",
    "\n",
    "\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def multi_unet_model_old(input_shape=(512, 512, 4), num_classes=6):\n",
    "\n",
    "  inputs = Input(shape=input_shape)\n",
    "  source_input = inputs\n",
    "\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
    "  c1 = Dropout(0.2)(c1)\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "  p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "  c2 = Dropout(0.2)(c2)\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "  p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "  p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "  p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "  c5 = Dropout(0.2)(c5)\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "  c8 = Dropout(0.2)(c8)\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "  u9 = concatenate([u9, c1], axis=3)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "  c9 = Dropout(0.2)(c9)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "  outputs = Conv2D(num_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  return model\n",
    "     \n",
    "\n",
    "def build_unet(input_shape=(512, 512, 4), num_classes=6):\n",
    "    print(\"üß™ build_unet called with input_shape =\", input_shape)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    print(\"üß™ Input layer constructed with shape:\", inputs.shape)\n",
    "\n",
    "    # --- Contracting Path ---\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # --- Expansive Path ---\n",
    "    u6 = layers.UpSampling2D((2,2))(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D((2,2))(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.UpSampling2D((2,2))(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.UpSampling2D((2,2))(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    outputs = layers.Conv2D(num_classes, (1,1), activation='softmax')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    print(\"‚úÖ U-Net model built successfully.\")\n",
    "    print(\"üß™ Final model.input_shape =\", model.input_shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_segformer(input_shape=(512, 512, 4), num_classes=6):\n",
    "    # Placeholder - You will replace with actual SegFormer loading (Huggingface transformers)\n",
    "    raise NotImplementedError(\"SegFormer model building not yet implemented.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdEbicH3hTacctqMBAkyLk",
   "mount_file_id": "1O8D9sKuR6RRfxuisx8awj21FxGx_wScV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
