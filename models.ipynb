{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-6gOfQHmAor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
    "    BatchNormalization, Activation, SpatialDropout2D, concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape=(256, 256, 3), num_classes=6) -> Model:\n",
    "    \"\"\"Builds an enhanced U-Net architecture with dropout and L2 regularisation.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The input shape of the image, e.g., (256, 256, 3).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled U-Net model.\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_block(x, filters, dropout_rate):\n",
    "        \"\"\"Applies two convolutional layers with batch norm, ReLU and dropout.\"\"\"\n",
    "        x_skip = x\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "    def decoder_block(x, skip, filters, dropout_rate):\n",
    "        \"\"\"Upsamples and merges with skip connection, then applies conv block.\"\"\"\n",
    "        x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding=\"same\",\n",
    "                            kernel_regularizer=l2(1e-4))(x)\n",
    "        x = concatenate([x, skip])\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    n_filters = 64\n",
    "\n",
    "    # --- Encoder ---\n",
    "    c1, s1 = conv_block(inputs, n_filters, dropout_rate=0.05)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2, s2 = conv_block(p1, n_filters * 2, dropout_rate=0.1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3, s3 = conv_block(p2, n_filters * 4, dropout_rate=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4, s4 = conv_block(p3, n_filters * 8, dropout_rate=0.35)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    c5, _ = conv_block(p4, n_filters * 16, dropout_rate=0.5)  # Heavier dropout\n",
    "\n",
    "    # --- Decoder ---\n",
    "    u6 = decoder_block(c5, s4, n_filters * 8, dropout_rate=0.4)\n",
    "    u7 = decoder_block(u6, s3, n_filters * 4, dropout_rate=0.3)\n",
    "    u8 = decoder_block(u7, s2, n_filters * 2, dropout_rate=0.2)\n",
    "    u9 = decoder_block(u8, s1, n_filters, dropout_rate=0.1)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", dtype=\"float32\")(u9)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_unet(input_shape: Tuple[int, int, int] = (256, 256, 3), num_classes: int = 6, n_filters: int = 32) -> Model:\n",
    "    \"\"\"Builds an enhanced U-Net architecture for semantic segmentation.\n",
    "\n",
    "    This U-Net implementation includes several enhancements over a basic U-Net:\n",
    "    -   Uses 'he_normal' kernel initializer for better weight initialization.\n",
    "    -   Applies L2 regularization to convolutional kernels to prevent overfitting.\n",
    "    -   Includes Batch Normalization after convolutions and before activation for\n",
    "        improved training stability and speed.\n",
    "    -   Uses ReLU activation functions throughout the encoder and decoder.\n",
    "    -   Incorporates Spatial Dropout 2D layers, with increasing dropout rates\n",
    "        in deeper encoder layers and decreasing rates in shallower decoder layers,\n",
    "        to further regularize the model and prevent overfitting.\n",
    "    -   The final output layer uses a 1x1 convolution with softmax activation\n",
    "        to produce class probabilities for each pixel.\n",
    "\n",
    "    Args:\n",
    "    input_shape: A `tuple` of three integers `(height, width, channels)`\n",
    "        specifying the input shape of the image tiles. Defaults to (256, 256, 3)\n",
    "        for RGB images.\n",
    "    num_classes: An `int` specifying the number of output classes for\n",
    "        segmentation. Defaults to 6.\n",
    "    n_filters: An `int` specifying the base number of filters for the first\n",
    "        convolutional block. This value will be multiplied by powers of 2 in the\n",
    "        encoder and decoder paths to increase the number of filters in deeper layers.\n",
    "\n",
    "    Returns:\n",
    "    A `tf.keras.Model` instance representing the enhanced U-Net.\n",
    "    \"\"\"\n",
    "\n",
    "    def _conv_block(x: tf.Tensor, filters: int, dropout_rate: float) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"Applies two convolutional layers with batch normalization, ReLU, and spatial dropout.\n",
    "\n",
    "        This block is a building block for both the encoder and decoder paths. It\n",
    "        applies two 3x3 convolutions, each followed by Batch Normalization and ReLU\n",
    "        activation. Spatial Dropout 2D is applied at the end of the block.\n",
    "\n",
    "        Args:\n",
    "            x: The input `tf.Tensor` to the convolutional block.\n",
    "            filters: An `int` specifying the number of convolutional filters (output\n",
    "            channels) for the layers in this block.\n",
    "            dropout_rate: A `float` specifying the dropout rate for `SpatialDropout2D`.\n",
    "\n",
    "        Returns:\n",
    "            A `tuple` containing two `tf.Tensor` objects:\n",
    "            - The output of the convolutional block.\n",
    "            - The original input `x_skip` to this block, used for skip connections.\n",
    "        \"\"\"\n",
    "        x_skip = x # Store input for potential skip connection in the decoder.\n",
    "\n",
    "        # First convolutional layer\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\", # He initializer for ReLU activation.\n",
    "            kernel_regularizer=l2(1e-4), # L2 regularization to prevent overfitting.\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x) # Normalize activations to improve training speed and stability.\n",
    "        x = Activation(\"relu\")(x) # ReLU activation for non-linearity.\n",
    "\n",
    "        # Second convolutional layer\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Spatial Dropout 2D: drops entire 2D feature maps, effective for convolutional layers.\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x, x_skip\n",
    "\n",
    "\n",
    "    def _decoder_block(x: tf.Tensor, skip_connection: tf.Tensor, filters: int, dropout_rate: float) -> tf.Tensor:\n",
    "        \"\"\"Performs upsampling, concatenates with a skip connection, and applies a conv block.\n",
    "\n",
    "        This block forms the decoding path of the U-Net. It first upsamples the input\n",
    "        using `Conv2DTranspose`, then concatenates it with the corresponding skip\n",
    "        connection from the encoder, and finally applies a convolutional block\n",
    "        (`_conv_block`) with the specified filters and dropout.\n",
    "\n",
    "        Args:\n",
    "            x: The input `tf.Tensor` from the previous decoder stage (low-resolution feature map).\n",
    "            skip_connection: The `tf.Tensor` from the corresponding encoder stage (high-resolution\n",
    "            feature map) used for concatenation.\n",
    "            filters: An `int` specifying the number of convolutional filters for the layers\n",
    "            in the internal conv block.\n",
    "            dropout_rate: A `float` specifying the dropout rate for `SpatialDropout2D`\n",
    "            within the internal conv block.\n",
    "\n",
    "        Returns:\n",
    "            A `tf.Tensor` representing the output of the decoder block.\n",
    "        \"\"\"\n",
    "        # Upsampling using Conv2DTranspose (transposed convolution).\n",
    "        x = Conv2DTranspose(\n",
    "            filters,\n",
    "            (2, 2), # Kernel size for upsampling.\n",
    "            strides=(2, 2), # Stride of 2 for upsampling.\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "\n",
    "        # Concatenate with the skip connection from the encoder path.\n",
    "        x = concatenate([x, skip_connection]) # Combines feature maps across resolutions.\n",
    "\n",
    "        # Apply two convolutional layers with batch norm, ReLU, and spatial dropout.\n",
    "        # Note: This is essentially a _conv_block without returning an x_skip.\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(\n",
    "            filters,\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = SpatialDropout2D(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Define input layer for the model.\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Base number of filters for the first encoder block.\n",
    "    n_filters = 32\n",
    "\n",
    "    # --- Encoder Path ---\n",
    "    # Downsampling blocks. Each block consists of _conv_block followed by MaxPooling.\n",
    "    # Dropout rates are typically lower at shallower layers and increase deeper into the network.\n",
    "    c1, s1 = _conv_block(inputs, n_filters, dropout_rate=0.05) # c1 is output, s1 is skip connection.\n",
    "    p1 = MaxPooling2D((2, 2))(c1) # Halves spatial dimensions.\n",
    "\n",
    "    c2, s2 = _conv_block(p1, n_filters * 2, dropout_rate=0.1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3, s3 = _conv_block(p2, n_filters * 4, dropout_rate=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4, s4 = _conv_block(p3, n_filters * 8, dropout_rate=0.35)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- Bottleneck Layer ---\n",
    "    # The deepest part of the network, typically with the highest filter count and dropout.\n",
    "    c5, _ = _conv_block(p4, n_filters * 16, dropout_rate=0.5)\n",
    "\n",
    "    # --- Decoder Path ---\n",
    "    # Upsampling blocks. Each block consists of `_decoder_block`.\n",
    "    # Dropout rates typically decrease as the resolution increases.\n",
    "    u6 = _decoder_block(c5, s4, n_filters * 8, dropout_rate=0.4)\n",
    "    u7 = _decoder_block(u6, s3, n_filters * 4, dropout_rate=0.3)\n",
    "    u8 = _decoder_block(u7, s2, n_filters * 2, dropout_rate=0.2)\n",
    "    u9 = _decoder_block(u8, s1, n_filters, dropout_rate=0.1)\n",
    "\n",
    "    # Output layer: 1x1 convolution to map feature channels to `num_classes`,\n",
    "    # followed by softmax activation for probability distribution over classes.\n",
    "    # `dtype=\"float32\"` explicitly sets the output dtype, important for mixed precision.\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=\"softmax\", dtype=\"float32\")(u9)\n",
    "\n",
    "    # Create the Keras Model.\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdEbicH3hTacctqMBAkyLk",
   "mount_file_id": "1O8D9sKuR6RRfxuisx8awj21FxGx_wScV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
