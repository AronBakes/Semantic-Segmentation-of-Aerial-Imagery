{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def compute_chip_score(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Computes a 'score' for a given chip to guide selection.\n",
    "    This version is updated to use the 'dist_...' column names correctly.\n",
    "    \"\"\"\n",
    "    # Create a dictionary of all the distribution columns for this row\n",
    "    dist_cols = {col: row[col] for col in row.index if col.startswith('dist_')}\n",
    "\n",
    "    # Dynamically find the correct column name instead of hardcoding indices\n",
    "    def get_col_name(class_name):\n",
    "        # Finds the column like 'dist_4:Car' by searching for the class name\n",
    "        for col in dist_cols:\n",
    "            if class_name in col:\n",
    "                return col\n",
    "        return None\n",
    "\n",
    "    car_col = get_col_name('Car')\n",
    "    bg_col = get_col_name('Background')\n",
    "    water_col = get_col_name('Water')\n",
    "    bldg_col = get_col_name('Building')\n",
    "    veg_col = get_col_name('Vegetation')\n",
    "\n",
    "    # If for some reason a column is not found, return a neutral score\n",
    "    if not all([car_col, bg_col, water_col, bldg_col, veg_col]):\n",
    "        print(\"Warning: Could not find all required columns in row.\")\n",
    "        return 0\n",
    "\n",
    "    car_ratio = row[car_col]\n",
    "    background_ratio = row[bg_col]\n",
    "    water_ratio = row[water_col]\n",
    "\n",
    "    # Rule 1: Always keep chips with cars\n",
    "    if car_ratio > 0:\n",
    "        return -1.0\n",
    "\n",
    "    # Rule 2: Always keep chips with water, unless it's almost pure water\n",
    "    if water_ratio > 0 and water_ratio < 0.95:\n",
    "        return -1.0\n",
    "\n",
    "    # Rule 3: Skip chips dominated by background\n",
    "    if background_ratio >= 0.95:\n",
    "        return float('inf')\n",
    "\n",
    "    # Rule 4: Count how many unique classes exist in the chip\n",
    "    unique_class_count = sum(1 for val in dist_cols.values() if val > 0.001)\n",
    "    if unique_class_count <= 1:\n",
    "        return float('inf')\n",
    "\n",
    "    # Rule 5: Calculate score based on class proportions\n",
    "    score = 0.0\n",
    "    score += 2.5 * (1 - row[bldg_col])\n",
    "    score += 11.0 * (1 - row[water_col])\n",
    "    score += -19.5 * min(0.1 - row[veg_col], 0)\n",
    "\n",
    "    # Rule 6: Reward chips for class diversity\n",
    "    if unique_class_count >= 4:\n",
    "        score -= 6.0\n",
    "    elif unique_class_count == 3:\n",
    "        score -= 3.0\n",
    "    elif unique_class_count == 2:\n",
    "        score -= 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def plot_class_distribution_from_df(dataframe: pd.DataFrame, title: str = \"Class Distribution\"):\n",
    "    \"\"\"\n",
    "    Plots the normalized pixel distribution for each class across a given DataFrame of chips.\n",
    "    \"\"\"\n",
    "    if dataframe.empty:\n",
    "        print(f\"Warning: DataFrame for '{title}' is empty. Cannot plot distribution.\")\n",
    "        return\n",
    "    \n",
    "    # Use the correct `count_` columns for plotting pixel counts\n",
    "    count_cols = [col for col in dataframe.columns if col.startswith('count_')]\n",
    "    if not count_cols:\n",
    "        print(\"Warning: No 'count_' columns found for plotting.\")\n",
    "        return\n",
    "\n",
    "    pixel_sums = dataframe[count_cols].sum()\n",
    "    total_pixels_across_df = pixel_sums.sum()\n",
    "\n",
    "    if total_pixels_across_df == 0:\n",
    "        return\n",
    "\n",
    "    pixel_props = pixel_sums / total_pixels_across_df\n",
    "    class_labels = [c.replace('count_', '') for c in count_cols]\n",
    "    \n",
    "    # Dynamically create colors based on the order of columns\n",
    "    colours = []\n",
    "    for label in class_labels:\n",
    "        class_id_str = label.split(':')[0]\n",
    "        class_id = int(class_id_str)\n",
    "        colours.append(np.array(CLASS_TO_COLOR[class_id]) / 255.0)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(class_labels, pixel_props, color=colours, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Add proportion labels on top of bars\n",
    "    for bar, prop in zip(bars, pixel_props):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f\"{prop:.2%}\",\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Dataframe Loading Functions ---\n",
    "\n",
    "def csv_to_df(split: str, metadata_path: str = os.path.join(base_dir, \"train_metadata.csv\"), subset: float = 1.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads metadata from CSV and filters chips for a specific data split\n",
    "    based on predefined lists of scene names.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metadata_path)\n",
    "\n",
    "    if split == 'train':\n",
    "        scene_list = TRAIN_SCENES\n",
    "    elif split == 'val':\n",
    "        scene_list = VAL_SCENES\n",
    "    elif split == 'test':\n",
    "        scene_list = TEST_SCENES\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid split type: {split}\")\n",
    "\n",
    "    # The correct way to filter: using .isin() on the 'source_file' column\n",
    "    df_split = df[df['source_file'].isin(scene_list)].copy()\n",
    "    \n",
    "    print(f\"Loaded {len(df_split)} chips for the '{split}' split from {len(scene_list)} scenes.\")\n",
    "\n",
    "    if split == 'train':\n",
    "        # Apply scoring logic only to the training set\n",
    "        df_split[\"score\"] = df_split.apply(compute_chip_score, axis=1)\n",
    "\n",
    "        keep_chips = df_split[df_split[\"score\"] == -1.0]\n",
    "        rest = df_split[(df_split['score'] != -1.0) & (df_split['score'] != float('inf'))].sort_values('score')\n",
    "        \n",
    "        num_to_select = int(len(df_split) * subset) - len(keep_chips)\n",
    "        if num_to_select < 0: num_to_select = 0\n",
    "            \n",
    "        final_df = pd.concat([keep_chips, rest.head(num_to_select)])\n",
    "        print(f\"After scoring, returning {len(final_df)} chips for training.\")\n",
    "        plot_class_distribution_from_df(final_df, title=f\"'{split.capitalize()}' Class Distribution\")\n",
    "        return final_df\n",
    "    else:\n",
    "        # For val and test, just return the filtered data\n",
    "        plot_class_distribution_from_df(df_split, title=f\"'{split.capitalize()}' Class Distribution\")\n",
    "        return df_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def csv_to_hard_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads metadata and filters for 'hard' chips, typically used for a second stage of training.\n",
    "    'Hard' chips are defined by specific criteria focusing on mixed classes,\n",
    "    presence of water, building, clutter, and specific thresholds.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing chips selected based on 'hard' criteria.\n",
    "    \"\"\"\n",
    "    metadata_path = \"/content/chipped_data/content/chipped_data/train_metadata.csv\"\n",
    "    df = pd.read_csv(metadata_path)\n",
    "\n",
    "    # Exclude chips that belong to the validation or test sets (for training data)\n",
    "    exclude_files = set(val_files + test_files)\n",
    "    df = df[~df[\"source_file\"].isin(exclude_files)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Define column references for convenience\n",
    "    cols = {\n",
    "        \"building\": \"0: Building\",\n",
    "        \"clutter\": \"1: Clutter\",\n",
    "        \"vegetation\": \"2: Vegetation\",\n",
    "        \"water\": \"3: Water\",\n",
    "        \"background\": \"4: Background\",\n",
    "        \"car\": \"5: Car\"\n",
    "    }\n",
    "\n",
    "    # Helper column to count classes with non-zero pixel counts\n",
    "    df['non_zero_classes'] = df[[*cols.values()]].gt(0).sum(axis=1)\n",
    "\n",
    "    # --- Criteria for 'Hard' Chips ---\n",
    "    # 1. Chips with water present alongside background\n",
    "    water_and_background = df[(df[cols[\"water\"]] > 0) & (df[cols[\"background\"]] > 0)].copy()\n",
    "    # 2. Chips with water present alongside vegetation\n",
    "    water_and_veg = df[(df[cols[\"water\"]] > 0) & (df[cols[\"vegetation\"]] > 0)].copy()\n",
    "    # 3. Chips with water, background, and vegetation all present\n",
    "    water_background_veg = df[\n",
    "        (df[cols[\"water\"]] > 0) &\n",
    "        (df[cols[\"background\"]] > 0) &\n",
    "        (df[cols[\"vegetation\"]] > 0)\n",
    "    ].copy()\n",
    "    # 4. Chips with significant building and background, but building not dominating\n",
    "    building_and_background = df[\n",
    "        (df[cols[\"building\"]] > 0.05) & (df[cols[\"background\"]] > 0.1) &\n",
    "        (df[cols[\"building\"]] < 0.4) # reduce building-dominant chips\n",
    "    ].copy()\n",
    "    # 5. Chips that are almost pure water\n",
    "    pure_water = df[(df[[*cols.values()]].sum(axis=1) > 0) & # Ensure not entirely empty\n",
    "                    (df[cols[\"water\"]] / df[[*cols.values()]].sum(axis=1) > 0.7) \n",
    "                   ].copy()\n",
    "\n",
    "    # 6. A sample of chips that are almost pure building (to ensure building class isn't forgotten)\n",
    "    # Ensure there are enough pure building chips to sample from before trying to sample\n",
    "    potential_pure_building = df[(df[[*cols.values()]].sum(axis=1) > 0) &\n",
    "                                 (df[cols[\"building\"]] / df[[*cols.values()]].sum(axis=1) > 0.7)\n",
    "                                ].copy()\n",
    "    num_pure_building_to_sample = min(100, len(potential_pure_building)) \n",
    "    pure_building = potential_pure_building.sample(n=num_pure_building_to_sample, random_state=42).copy()\n",
    "\n",
    "\n",
    "    # Combine all selected 'hard' chips and remove duplicates\n",
    "    stage2_df = pd.concat([\n",
    "        water_and_background,\n",
    "        water_and_veg,\n",
    "        water_background_veg,\n",
    "        building_and_background,\n",
    "        pure_water,\n",
    "        pure_building,\n",
    "    ]).drop_duplicates().reset_index(drop=True) # Reset index after concat and drop_duplicates\n",
    "\n",
    "    plot_class_distribution_from_df(stage2_df, title=\"Stage 2 Class Distribution\")\n",
    "    print(f\"\\nSelected {len(stage2_df):,} hard chips for Stage 2 training.\")\n",
    "    return stage2_df\n",
    "'''\n",
    "\n",
    "def csv_to_full_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads all entries from the metadata CSV into a DataFrame without any filtering.\n",
    "    This method will include all chips from all source files and will not apply\n",
    "    any background exclusion or score-based filtering.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing all entries from the metadata CSV.\n",
    "    \"\"\"\n",
    "    metadata_path = \"/content/chipped_data/content/chipped_data/train_metadata.csv\"\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    print(f\"Loaded {len(df):,} chips from the CSV, no filters applied.\")\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
