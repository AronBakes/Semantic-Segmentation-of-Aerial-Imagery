{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5Pup5vv_c2R"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Used for confusion matrix plotting (implicitly by ConfusionMatrixDisplay's default style)\n",
    "import random\n",
    "import gc # For garbage collection\n",
    "from PIL import Image # For image manipulation, potentially for reconstruction or debugging\n",
    "from datetime import datetime # For timestamping or time limits\n",
    "\n",
    "# --- TensorFlow and Keras specific imports ---\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import MeanIoU # Explicit import for clarity\n",
    "\n",
    "# --- Scikit-learn metrics ---\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay, # For plotting confusion matrices\n",
    "    precision_recall_fscore_support # For per-class metrics\n",
    ")\n",
    "\n",
    "# --- Progress bar for loops ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Additional Imports ---\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "# Clear Keras session to avoid conflicts from previous model definitions\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "# --- Global Configuration and Constants ---\n",
    "\n",
    "# Number of semantic classes\n",
    "NUM_CLASSES = 6\n",
    "# Names corresponding to each class ID\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "# Mapping from RGB color (as tuple) to integer class ID for labels\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,      # Red: Building\n",
    "    (145, 30, 180): 1,     # Purple: Clutter\n",
    "    (60, 180, 75): 2,      # Green: Vegetation\n",
    "    (245, 130, 48): 3,     # Orange: Water\n",
    "    (255, 255, 255): 4,    # White: Background\n",
    "    (0, 130, 200): 5,      # Blue: Car\n",
    "    (255, 0, 255): 6       # Magenta: Often used as an \"ignore\" or \"padding\" pixel color\n",
    "}\n",
    "\n",
    "# Inverse mapping from integer class ID to RGB color (as tuple)\n",
    "# Excludes class ID 6 (ignore class) from this mapping for normal visualization\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < NUM_CLASSES}\n",
    "IGNORE_COLOR = (255, 0, 255) # The specific RGB color for ignored regions (magenta)\n",
    "\n",
    "# Default output directory for plots and saved models\n",
    "out_dir = \"/content/figs\"\n",
    "\n",
    "# --- Measurement Functions ---\n",
    "\n",
    "def measure_inference_time(\n",
    "    model: tf.keras.Model,\n",
    "    generator: tf.data.Dataset,\n",
    "    num_batches: int = 5\n",
    ") -> None:\n",
    "    \"\"\"Measures inference time of a Keras model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model to evaluate.\n",
    "        generator (tf.data.Dataset): The input dataset for inference.\n",
    "        num_batches (int, optional): Number of batches to use for timing. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import time\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = tf.data.experimental.cardinality(generator).numpy()\n",
    "\n",
    "    for i, (x_batch, _) in enumerate(generator.take(num_batches)):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "        end = time.time()\n",
    "        total_time += (end - start)\n",
    "        total_images += x_batch.shape[0]\n",
    "\n",
    "    print(f\"🧠 Inference time: {total_time:.2f} sec for {total_images} images\")\n",
    "    print(f\"⏱️ Avg inference time per image: {total_time / total_images:.4f} sec\")\n",
    "\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_training_curves(\n",
    "    history: tf.keras.callbacks.History,\n",
    "    out_dir: str\n",
    ") -> None:\n",
    "    \"\"\"Plots and saves training/validation loss and IoU curves.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): History object returned by `model.fit()`.\n",
    "        out_dir (str): Directory path to save the generated plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    history_dict = history.history\n",
    "    required_keys = [\"loss\", \"val_loss\", \"iou_score\", \"val_iou_score\"]\n",
    "\n",
    "    missing_keys = [k for k in required_keys if k not in history_dict]\n",
    "    if missing_keys:\n",
    "        print(f\"⚠️ Missing keys in history: {missing_keys}\")\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    axs[0].plot(history_dict[\"loss\"], label=\"Train Loss\")\n",
    "    axs[0].plot(history_dict[\"val_loss\"], label=\"Val Loss\")\n",
    "    axs[0].set_title(\"Loss over Epochs\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot IoU\n",
    "    axs[1].plot(history_dict[\"iou_score\"], label=\"Train IoU\")\n",
    "    axs[1].plot(history_dict[\"val_iou_score\"], label=\"Val IoU\")\n",
    "    axs[1].set_title(\"Mean IoU over Epochs\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Mean IoU\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(out_dir, \"training_curves.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Saved training curves to: {save_path}\")\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "def visualise_prediction_grid(\n",
    "    rgb_list: List[np.ndarray],\n",
    "    true_mask_list: List[np.ndarray],\n",
    "    pred_mask_list: List[np.ndarray],\n",
    "    tile_id_list: Optional[List[str]] = None,\n",
    "    all_tile_ids: Optional[List[str]] = None,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3\n",
    ") -> None:\n",
    "    \"\"\"Displays a grid of RGB images, ground truth masks, and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (List[np.ndarray]): List of input RGB images (uint8, 0–255).\n",
    "        true_mask_list (List[np.ndarray]): List of one-hot encoded ground truth masks.\n",
    "        pred_mask_list (List[np.ndarray]): List of predicted masks (class ID format).\n",
    "        tile_id_list (Optional[List[str]]): Tile IDs to prioritise for visualisation.\n",
    "        all_tile_ids (Optional[List[str]]): Full list of tile IDs aligned with inputs.\n",
    "        n_rows (int): Number of rows in the grid.\n",
    "        n_cols (int): Number of triplet columns (each triplet is Input, Ground Truth, Prediction).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    indices_to_plot = []\n",
    "\n",
    "    if tile_id_list and all_tile_ids:\n",
    "        tile_id_set = set(tile_id_list)\n",
    "        matched_indices = [i for i, tid in enumerate(all_tile_ids) if tid in tile_id_set]\n",
    "        random.shuffle(matched_indices)\n",
    "        indices_to_plot = matched_indices[:total]\n",
    "\n",
    "        if len(indices_to_plot) < total:\n",
    "            all_indices = list(set(range(len(rgb_list))) - set(indices_to_plot))\n",
    "            random.shuffle(all_indices)\n",
    "            indices_to_plot += all_indices[:total - len(indices_to_plot)]\n",
    "    else:\n",
    "        indices_to_plot = list(range(min(total, len(rgb_list))))\n",
    "\n",
    "    for idx_plot, data_idx in enumerate(indices_to_plot):\n",
    "        rgb = rgb_list[data_idx]\n",
    "        true_mask = np.argmax(true_mask_list[data_idx], axis=-1)\n",
    "        pred_mask = pred_mask_list[data_idx]\n",
    "\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in CLASS_TO_COLOR.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_list[data_idx] == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx_plot // n_cols\n",
    "        col = (idx_plot % n_cols) * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "'''\n",
    "from typing import List, Optional\n",
    "\n",
    "def visualise_prediction_grid(\n",
    "    rgb_list: List[np.ndarray],\n",
    "    true_mask_list: List[np.ndarray],\n",
    "    pred_mask_list: List[np.ndarray],\n",
    "    specific_tile_ids: Optional[List[str]] = None,\n",
    "    all_tile_ids: Optional[List[str]] = None,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3\n",
    ") -> None:\n",
    "    \"\"\"Displays a grid of RGB images, ground truth masks, and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (List[np.ndarray]): List of input RGB images (uint8, 0–255).\n",
    "        true_mask_list (List[np.ndarray]): List of one-hot encoded ground truth masks.\n",
    "        pred_mask_list (List[np.ndarray]): List of predicted masks (class ID format).\n",
    "        specific_tile_ids (Optional[List[str]]): Tile IDs to prioritise for visualisation.\n",
    "        all_tile_ids (Optional[List[str]]): Full list of tile IDs aligned with inputs.\n",
    "        n_rows (int): Number of rows in the grid.\n",
    "        n_cols (int): Number of triplet columns (each triplet is Input, Ground Truth, Prediction).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import random\n",
    "    total = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    random.seed(420)\n",
    "    indices_to_plot = []\n",
    "\n",
    "    if specific_tile_ids and all_tile_ids:\n",
    "        tile_id_set = set(specific_tile_ids)\n",
    "        matched_indices = [i for i, tid in enumerate(all_tile_ids) if tid in tile_id_set]\n",
    "        random.shuffle(matched_indices)\n",
    "        indices_to_plot = matched_indices[:total]\n",
    "\n",
    "        if len(indices_to_plot) < total:\n",
    "            filler = list(set(range(len(rgb_list))) - set(indices_to_plot))\n",
    "            random.shuffle(filler)\n",
    "            indices_to_plot += filler[:total - len(indices_to_plot)]\n",
    "    else:\n",
    "        # Fallback: prioritise chips with water, clutter, or car (class IDs 3, 1, 5)\n",
    "        scores = []\n",
    "        for i, one_hot_mask in enumerate(true_mask_list):\n",
    "            class_ids = np.unique(np.argmax(one_hot_mask, axis=-1))\n",
    "            score = sum(1 for cls in class_ids if cls in {1, 3, 5})  # clutter, water, car\n",
    "            scores.append((i, score))\n",
    "        scores.sort(key=lambda x: -x[1])\n",
    "        indices_to_plot = [i for i, _ in scores[:total]]\n",
    "\n",
    "    for idx_plot, data_idx in enumerate(indices_to_plot):\n",
    "        rgb = rgb_list[data_idx]\n",
    "        true_mask = np.argmax(true_mask_list[data_idx], axis=-1)\n",
    "        pred_mask = pred_mask_list[data_idx]\n",
    "\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, colour in CLASS_TO_COLOR.items():\n",
    "            true_rgb[true_mask == class_id] = colour\n",
    "            pred_rgb[pred_mask == class_id] = colour\n",
    "\n",
    "        ignore_mask = np.all(true_mask_list[data_idx] == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx_plot // n_cols\n",
    "        col = (idx_plot % n_cols) * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "def normalize_confusion_matrix(\n",
    "    cm: Union[np.ndarray, list],\n",
    "    norm: str = 'true'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Normalises a confusion matrix by rows, columns, or entire matrix.\n",
    "\n",
    "    Args:\n",
    "        cm (Union[np.ndarray, list]): Raw confusion matrix.\n",
    "        norm (str): Normalisation method. Options:\n",
    "            - 'true': Normalise by rows (ground truth labels).\n",
    "            - 'pred': Normalise by columns (predicted labels).\n",
    "            - 'all': Normalise entire matrix to sum to 1.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalised confusion matrix.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `norm` is not one of 'true', 'pred', or 'all'.\n",
    "    \"\"\"\n",
    "    cm = np.array(cm, dtype=np.float32)\n",
    "\n",
    "    if norm == 'true':\n",
    "        cm_normalized = cm / cm.sum(axis=1, keepdims=True)\n",
    "    elif norm == 'pred':\n",
    "        cm_normalized = cm / cm.sum(axis=0, keepdims=True)\n",
    "    elif norm == 'all':\n",
    "        cm_normalized = cm / cm.sum()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n",
    "\n",
    "    return cm_normalized\n",
    "\n",
    "\n",
    "# --- Main Evaluation Function ---\n",
    "from typing import Optional, List\n",
    "\n",
    "def evaluate_on_test(\n",
    "    model: tf.keras.Model,\n",
    "    test_gen: tf.data.Dataset,\n",
    "    test_df: pd.DataFrame,\n",
    "    out_dir: str,\n",
    "    image_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3,\n",
    "    specific_tile_ids: Optional[List[str]] = None\n",
    ") -> None:\n",
    "    \"\"\"Evaluates the model on the test set and generates metrics and visualisations.\n",
    "\n",
    "    This includes mean IoU, macro F1, Precision, Recall, a confusion matrix,\n",
    "    and a prediction visualisation grid.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained segmentation model.\n",
    "        test_gen (tf.data.Dataset): Test dataset generator.\n",
    "        test_df (pd.DataFrame): DataFrame with test metadata including tile IDs.\n",
    "        out_dir (str): Directory to save output plots.\n",
    "        image_dir (str): Directory containing RGB images (not used in this function).\n",
    "        label_dir (str): Directory containing label images (not used in this function).\n",
    "        tile_size (int): Size of each tile in pixels (e.g. 256x256).\n",
    "        n_rows (int): Number of rows in the prediction grid.\n",
    "        n_cols (int): Number of columns in the prediction grid.\n",
    "        specific_tile_ids (Optional[List[str]]): Tile IDs to prioritise for visualisation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"🧪 Running evaluation on test set...\")\n",
    "\n",
    "    all_test_preds = []\n",
    "    all_test_trues = []\n",
    "\n",
    "    visual_rgb = []\n",
    "    visual_true = []\n",
    "    visual_pred = []\n",
    "    visual_tile_ids = []\n",
    "    visual_limit = n_rows * n_cols if n_rows and n_cols else 5\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    test_tile_ids = test_df['tile_id'].tolist()\n",
    "    tile_index = 0\n",
    "\n",
    "    for batch_x, batch_y in test_gen.as_numpy_iterator():\n",
    "        if batch_x.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(batch_x, verbose=0)\n",
    "        pred_mask = np.argmax(pred, axis=-1).astype(np.uint8)\n",
    "        true_mask = np.argmax(batch_y, axis=-1).astype(np.uint8)\n",
    "\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            if tile_index >= len(test_tile_ids):\n",
    "                break\n",
    "\n",
    "            tile_id = test_tile_ids[tile_index]\n",
    "            tile_index += 1\n",
    "\n",
    "            if len(visual_rgb) < visual_limit:\n",
    "                rgb_tile = (batch_x[j][:, :, :3] * 255).astype(np.uint8)\n",
    "                visual_rgb.append(rgb_tile)\n",
    "                visual_true.append(batch_y[j])\n",
    "                visual_pred.append(pred_mask[j])\n",
    "                visual_tile_ids.append(tile_id)\n",
    "\n",
    "        all_test_preds.extend(pred_mask.reshape(-1))\n",
    "        all_test_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "        del batch_x, batch_y, pred, pred_mask, true_mask\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds:\n",
    "        print(\"⚠️ No test predictions were collected.\")\n",
    "        return\n",
    "\n",
    "    all_test_preds = np.array(all_test_preds)\n",
    "    all_test_trues = np.array(all_test_trues)\n",
    "\n",
    "    if visual_rgb:\n",
    "\n",
    "        visualise_prediction_grid(\n",
    "            visual_rgb,\n",
    "            visual_true,\n",
    "            visual_pred,\n",
    "            tile_id_list=specific_tile_ids,  # ❌ old name\n",
    "            all_tile_ids=visual_tile_ids,\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        visualise_prediction_grid(\n",
    "            rgb_list=visual_rgb,\n",
    "            true_mask_list=visual_true,\n",
    "            pred_mask_list=visual_pred,\n",
    "            specific_tile_ids=specific_tile_ids,\n",
    "            all_tile_ids=visual_tile_ids,\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols\n",
    "        )'''\n",
    "\n",
    "\n",
    "    mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "    mean_iou_metric.update_state(all_test_trues, all_test_preds)\n",
    "    miou = mean_iou_metric.result().numpy()\n",
    "\n",
    "    macro_f1 = f1_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_precision = precision_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_recall = recall_score(all_test_trues, all_test_preds, average='macro')\n",
    "\n",
    "    print(f\"\\n📊 Macro Metrics:\")\n",
    "    print(f\"  F1 Score     : {macro_f1:.4f}\")\n",
    "    print(f\"  Precision    : {macro_precision:.4f}\")\n",
    "    print(f\"  Recall       : {macro_recall:.4f}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_test_trues, all_test_preds, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"\\n📏 Per-class IoU Scores:\")\n",
    "    class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else float('nan')\n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {CLASS_NAMES[i]:<12} IoU: {iou:.4f}\")\n",
    "\n",
    "    print(f\"\\n📈 Mean IoU (mIoU): {miou:.4f}\")\n",
    "\n",
    "    print(\"\\n🔍 Classification Report:\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_test_trues,\n",
    "        all_test_preds,\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    )\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        print(f\"{name:<12} | F1: {f1[i]:.4f} | Prec: {precision[i]:.4f} | Recall: {recall[i]:.4f}\")\n",
    "\n",
    "    print(\"\\n🌀 Row-Normalised Confusion Matrix:\")\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "        norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_row_norm.png'))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "# --- Reconstruction Utility ---\n",
    "\n",
    "def reconstruct_canvas(\n",
    "    model: tf.keras.Model,\n",
    "    df: pd.DataFrame,\n",
    "    source_file_prefix: str, # The common prefix for all chips of one large image\n",
    "    generator_class: callable, # The function to build the TensorFlow dataset (e.g., `build_tf_dataset`)\n",
    "    img_dir: str,\n",
    "    elev_dir: str,\n",
    "    slope_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file by stitching together its individual chips.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        df (pd.DataFrame): The DataFrame containing metadata for all chips (e.g., test_df).\n",
    "        source_file_prefix (str): The common prefix for all chips belonging to the same large image.\n",
    "                                  (e.g., \"25f1c24f30_EB81FE6E2BOPENPIPELINE\")\n",
    "        generator_class (callable): The function to build the TensorFlow dataset (e.g., `build_tf_dataset`).\n",
    "        img_dir (str): Directory containing RGB images.\n",
    "        elev_dir (str): Directory containing elevation .npy files.\n",
    "        slope_dir (str): Directory containing slope .npy files.\n",
    "        label_dir (str): Directory containing label images.\n",
    "        tile_size (int): The size of individual tiles/chips (e.g., 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the\n",
    "        reconstructed RGB canvas, Ground Truth canvas, and Prediction canvas (all as np.uint8).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no chips are found for the specified source file prefix.\n",
    "    \"\"\"\n",
    "    # Filter for chips belonging to the specific source file prefix\n",
    "    # Assuming 'tile_id' column contains the full ID like 'prefix_x_y'\n",
    "    df_file = df[df['tile_id'].str.startswith(source_file_prefix)].copy()\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file prefix: {source_file_prefix}\")\n",
    "\n",
    "    # Determine the overall canvas shape based on min/max x,y coordinates and tile size\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + tile_size\n",
    "    max_y = df_file['y'].max() + tile_size\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape_rgb = (canvas_h, canvas_w, 3)\n",
    "    canvas_shape_mask = (canvas_h, canvas_w, 3) # For GT/Pred, will be colored RGB\n",
    "\n",
    "    # Initialize canvases with IGNORE_COLOR (magenta) for padding/uncovered areas\n",
    "    rgb_canvas = np.full(canvas_shape_rgb, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Build dataset for just this file's chips, ensuring correct order for stitching\n",
    "    # Use shuffle=False and augment=False for reconstruction, and a 'val' or 'test' split\n",
    "    # to guarantee no augmentation. Batch size can be larger for efficiency during inference.\n",
    "    # Assuming 'generator_class' (e.g., build_tf_dataset) can accept a 'split' argument.\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"val\" # Use 'val' or 'test' to ensure no augments\n",
    "    )\n",
    "\n",
    "    # Iterate through the generated batches, predict, and fill the canvases in order\n",
    "    row_index_in_df = 0 # Tracks position in the filtered df_file to get (x,y) coords\n",
    "    for batch_x, batch_y_onehot in tqdm(gen, desc=f\"Reconstructing {source_file_prefix}\"):\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        preds_softmax = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_ids = tf.argmax(preds_softmax, axis=-1).numpy()\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_ids = tf.argmax(batch_y_onehot, axis=-1).numpy()\n",
    "\n",
    "        batch_size_actual = batch_x.shape[0]\n",
    "        for i in range(batch_size_actual):\n",
    "            if row_index_in_df >= len(df_file): # Safety break if we've processed all chips\n",
    "                break\n",
    "\n",
    "            # Get chip's original (x, y) coordinates from the DataFrame\n",
    "            row_df_entry = df_file.iloc[row_index_in_df]\n",
    "            rel_x = row_df_entry.x - min_x # Relative X coordinate for placing on canvas\n",
    "            rel_y = row_df_entry.y - min_y # Relative Y coordinate for placing on canvas\n",
    "            row_index_in_df += 1\n",
    "\n",
    "            # Extract current chip data (RGB is always first 3 channels)\n",
    "            # Scale from [0,1] to [0,255] and cast to uint8\n",
    "            rgb_chip = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            true_mask_chip = true_mask_ids[i]\n",
    "            pred_mask_chip = pred_mask_ids[i]\n",
    "\n",
    "            # Place RGB chip onto the canvas\n",
    "            rgb_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = rgb_chip\n",
    "\n",
    "            # Color and place Ground Truth mask onto the canvas\n",
    "            gt_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb_chip[true_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            gt_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = gt_rgb_chip\n",
    "\n",
    "            # Color and place Prediction mask onto the canvas\n",
    "            pred_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb_chip[pred_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            pred_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = pred_rgb_chip\n",
    "    \n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "def plot_reconstruction(img: np.ndarray, label: np.ndarray, pred: np.ndarray, source_file_prefix: str):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file prefix.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The reconstructed RGB image canvas (uint8).\n",
    "        label (np.ndarray): The reconstructed ground truth mask canvas (colored, uint8).\n",
    "        pred (np.ndarray): The reconstructed prediction mask canvas (colored, uint8).\n",
    "        source_file_prefix (str): The common prefix of the source file for the title.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\", fontsize=18)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\", fontsize=18)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\", fontsize=18)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file_prefix}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Unused Utility Functions ---\n",
    "\n",
    "def visualise_prediction_grid_by_performance(\n",
    "    rgb_list,\n",
    "    true_mask_list,\n",
    "    pred_mask_list,\n",
    "    miou_list,\n",
    "    class_list,\n",
    "    n_rows=4,\n",
    "    n_cols=3,\n",
    "    class_names=CLASS_NAMES,\n",
    "    class_to_color=CLASS_TO_COLOR\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes a grid of predictions sorted by performance (mIoU),\n",
    "    with an attempt to include specific classes (like Water or Building)\n",
    "    from the lowest performance tier.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (list): List of input RGB images (NumPy arrays).\n",
    "        true_mask_list (list): List of ground truth masks (one-hot encoded NumPy arrays).\n",
    "        pred_mask_list (list): List of predicted masks (integer class ID NumPy arrays).\n",
    "        miou_list (list): List of per-chip mIoU scores.\n",
    "        class_list (list): List where each element is a list of integer class IDs present in that chip.\n",
    "        n_rows (int): Number of rows in the visualization grid.\n",
    "        n_cols (int): Number of columns in the visualization grid.\n",
    "        class_names (list): List of class names.\n",
    "        class_to_color (dict): Mapping from class ID to RGB color tuple.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Step 1: Sort chips by mIoU\n",
    "    chip_data = list(zip(rgb_list, true_mask_list, pred_mask_list, miou_list, class_list))\n",
    "    chip_data.sort(key=lambda x: x[3])  # Sort by mIoU\n",
    "\n",
    "    n_total = n_rows * n_cols\n",
    "    chips_per_group = n_total // 3\n",
    "\n",
    "    bottom_third = chip_data[:chips_per_group]\n",
    "    middle_third = chip_data[chips_per_group:2 * chips_per_group]\n",
    "    top_third = chip_data[2 * chips_per_group:]\n",
    "\n",
    "    # Step 2: Select 4 chips from each group with some class coverage strategy\n",
    "    def select_chips(chips, needed, reserve_class=None):\n",
    "        selected = []\n",
    "        for chip in chips:\n",
    "            if len(selected) >= needed:\n",
    "                break\n",
    "            if reserve_class is not None and reserve_class in chip[4]:\n",
    "                selected.append(chip)\n",
    "                reserve_class = None  # only once\n",
    "            elif reserve_class is None:\n",
    "                selected.append(chip)\n",
    "        return selected\n",
    "\n",
    "    selected_bottom = select_chips(bottom_third, 4, reserve_class=class_names.index(\"Water\"))\n",
    "    selected_bottom = select_chips([c for c in bottom_third if c not in selected_bottom], 4 - len(selected_bottom), reserve_class=class_names.index(\"Building\")) + selected_bottom\n",
    "\n",
    "    selected_middle = middle_third[:4]\n",
    "    selected_top = top_third[:4]\n",
    "\n",
    "    # Combine and assign column index\n",
    "    all_selected = selected_bottom + selected_middle + selected_top\n",
    "    column_assignments = [0] * 4 + [1] * 4 + [2] * 4  # 0: bottom, 1: middle, 2: top\n",
    "\n",
    "    # Step 3: Plotting\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    for idx, (rgb, true_mask_oh, pred_mask, _, _) in enumerate(all_selected):\n",
    "        true_mask = np.argmax(true_mask_oh, axis=-1)\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in class_to_color.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_oh == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx % n_rows\n",
    "        col = column_assignments[idx] * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def apply_crf(rgb, probs, t=5, compat=10, sxy=3, srgb=13):\n",
    "    import pydensecrf.densecrf as dcrf\n",
    "    from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "    import numpy as np\n",
    "\n",
    "    h, w = probs.shape[:2]\n",
    "    num_classes = probs.shape[-1]\n",
    "\n",
    "    d = dcrf.DenseCRF2D(w, h, num_classes)\n",
    "\n",
    "    # 🔧 FIX: reshape to (num_classes, H*W)\n",
    "    unary = unary_from_softmax(probs.transpose(2, 0, 1))\n",
    "    unary = unary.reshape((num_classes, -1)).copy(order='C')\n",
    "\n",
    "    d.setUnaryEnergy(unary)\n",
    "\n",
    "    rgb_float = rgb.astype(np.float32)\n",
    "    if not rgb_float.flags['C_CONTIGUOUS']:\n",
    "        rgb_float = np.ascontiguousarray(rgb_float)\n",
    "\n",
    "    pairwise = create_pairwise_bilateral(sdims=(sxy, sxy), schan=(srgb, srgb, srgb), img=rgb_float, chdim=2)\n",
    "    d.addPairwiseEnergy(pairwise, compat=compat)\n",
    "\n",
    "    Q = d.inference(t)\n",
    "    return np.argmax(Q, axis=0).reshape((h, w))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_with_crf(model, test_gen, test_df, out_dir, image_dir, label_dir, tile_size=256, n_rows=4, n_cols=3):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    rgb_list = []\n",
    "    true_mask_list = []\n",
    "    pred_mask_list = []\n",
    "    present_classes_per_chip = []\n",
    "    chip_ious = []\n",
    "\n",
    "    visual_limit = n_rows * n_cols\n",
    "    tile_index = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(test_gen, desc=\"Evaluating\"):\n",
    "        if tf.size(x_batch).numpy() == 0:\n",
    "            continue\n",
    "\n",
    "        soft_preds = model.predict(x_batch, verbose=0)\n",
    "        true_mask_batch = tf.argmax(y_batch, axis=-1).numpy().astype(np.uint8)\n",
    "\n",
    "        for i in range(x_batch.shape[0]):\n",
    "            if tile_index >= len(test_df):\n",
    "                break\n",
    "\n",
    "            # Fix: Convert tensor to NumPy before applying astype()\n",
    "            rgb_img = (x_batch[i][..., :3].numpy() * 255).astype(np.uint8)\n",
    "            softmax_pred = soft_preds[i]\n",
    "            crf_mask = apply_crf(rgb_img, softmax_pred)\n",
    "\n",
    "            true_mask = true_mask_batch[i]\n",
    "            all_preds.extend(crf_mask.reshape(-1))\n",
    "            all_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "            # Per-chip IoU\n",
    "            cm = confusion_matrix(true_mask.flatten(), crf_mask.flatten(), labels=list(range(NUM_CLASSES)))\n",
    "            ious = []\n",
    "            for j in range(NUM_CLASSES):\n",
    "                intersection = cm[j, j]\n",
    "                union = np.sum(cm[j, :]) + np.sum(cm[:, j]) - intersection\n",
    "                if union > 0:\n",
    "                    iou = intersection / union\n",
    "                    ious.append(iou)\n",
    "            chip_ious.append(np.mean(ious) if ious else 0)\n",
    "\n",
    "            if len(rgb_list) < visual_limit:\n",
    "                rgb_list.append(rgb_img)\n",
    "                true_mask_onehot = y_batch[i].numpy()\n",
    "                true_mask_list.append(true_mask_onehot)\n",
    "                pred_mask_list.append(crf_mask)\n",
    "\n",
    "                present_classes = np.unique(true_mask)\n",
    "                present_classes = [int(c) for c in present_classes if c < NUM_CLASSES]\n",
    "                present_classes_per_chip.append(present_classes)\n",
    "\n",
    "            tile_index += 1\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    visualise_prediction_grid(\n",
    "        rgb_list=rgb_list,\n",
    "        true_mask_list=true_mask_list,\n",
    "        pred_mask_list=pred_mask_list,\n",
    "        n_rows=n_rows,\n",
    "        n_cols=n_cols\n",
    "    )\n",
    "\n",
    "    # --- Metrics ---\n",
    "    f1 = f1_score(all_trues, all_preds, average='macro')\n",
    "    precision = precision_score(all_trues, all_preds, average='macro')\n",
    "    recall = recall_score(all_trues, all_preds, average='macro')\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_trues, all_preds, labels=list(range(NUM_CLASSES)))\n",
    "    per_class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        per_class_ious.append(iou)\n",
    "    miou = np.mean(per_class_ious)\n",
    "\n",
    "    report = classification_report(\n",
    "        all_trues, all_preds, target_names=CLASS_NAMES, digits=4\n",
    "    )\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_crf.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- Per-chip mIoU histogram ---\n",
    "    print(\"\\n📊 Generating per-chip mIoU histogram...\")\n",
    "    bin_edges = np.linspace(0, 1, 21)  # 5% bins\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "    plt.xlabel(\"Per-Chip mIoU\")\n",
    "    plt.ylabel(\"Number of Chips\")\n",
    "    plt.title(\"Distribution of Per-Chip mIoU (CRF Post-Processed)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"per_chip_miou_hist.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"miou\": miou,\n",
    "        \"per_class_ious\": per_class_ious,\n",
    "        \"classification_report\": report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Used for confusion matrix plotting (implicitly by ConfusionMatrixDisplay's default style)\n",
    "import random\n",
    "import gc # For garbage collection\n",
    "from PIL import Image # For image manipulation, potentially for reconstruction or debugging\n",
    "from datetime import datetime # For timestamping or time limits\n",
    "\n",
    "# --- TensorFlow and Keras specific imports ---\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import MeanIoU # Explicit import for clarity\n",
    "\n",
    "# --- Scikit-learn metrics ---\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay, # For plotting confusion matrices\n",
    "    precision_recall_fscore_support # For per-class metrics\n",
    ")\n",
    "\n",
    "# --- Progress bar for loops ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Clear Keras session to avoid conflicts from previous model definitions\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "# --- Global Configuration and Constants ---\n",
    "\n",
    "# Number of semantic classes\n",
    "NUM_CLASSES = 6\n",
    "# Names corresponding to each class ID\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "# Mapping from RGB color (as tuple) to integer class ID for labels\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,      # Red: Building\n",
    "    (145, 30, 180): 1,     # Purple: Clutter\n",
    "    (60, 180, 75): 2,      # Green: Vegetation\n",
    "    (245, 130, 48): 3,     # Orange: Water\n",
    "    (255, 255, 255): 4,    # White: Background\n",
    "    (0, 130, 200): 5,      # Blue: Car\n",
    "    (255, 0, 255): 6       # Magenta: Often used as an \"ignore\" or \"padding\" pixel color\n",
    "}\n",
    "\n",
    "# Inverse mapping from integer class ID to RGB color (as tuple)\n",
    "# Excludes class ID 6 (ignore class) from this mapping for normal visualization\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < NUM_CLASSES}\n",
    "IGNORE_COLOR = (255, 0, 255) # The specific RGB color for ignored regions (magenta)\n",
    "\n",
    "# Default output directory for plots and saved models\n",
    "out_dir = \"/content/figs\"\n",
    "\n",
    "def visualise_prediction_grid_by_performance(\n",
    "    rgb_list: list,\n",
    "    true_mask_list: list,\n",
    "    pred_mask_list: list,\n",
    "    miou_list: list,\n",
    "    class_list: list, # List of lists of present class IDs per chip\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3,\n",
    "    class_names: list = CLASS_NAMES, # Default to global CLASS_NAMES\n",
    "    class_to_color: dict = CLASS_TO_COLOR # Default to global CLASS_TO_COLOR\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes a grid of predictions sorted by performance (mIoU),\n",
    "    with an attempt to include specific classes (like Water or Building)\n",
    "    from the lowest performance tier.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (list): List of input RGB images (NumPy arrays).\n",
    "        true_mask_list (list): List of ground truth masks (one-hot encoded NumPy arrays).\n",
    "        pred_mask_list (list): List of predicted masks (integer class ID NumPy arrays).\n",
    "        miou_list (list): List of per-chip mIoU scores.\n",
    "        class_list (list): List where each element is a list of integer class IDs present in that chip.\n",
    "        n_rows (int): Number of rows in the visualization grid.\n",
    "        n_cols (int): Number of columns in the visualization grid.\n",
    "        class_names (list): List of class names.\n",
    "        class_to_color (dict): Mapping from class ID to RGB color tuple.\n",
    "    \"\"\"\n",
    "    # Step 1: Combine and sort chip data by mIoU\n",
    "    chip_data = list(zip(rgb_list, true_mask_list, pred_mask_list, miou_list, class_list))\n",
    "    chip_data.sort(key=lambda x: x[3])  # Sort by mIoU (index 3)\n",
    "\n",
    "    n_total_plots = n_rows * n_cols\n",
    "    \n",
    "    # Divide chips into performance tiers (bottom, middle, top third by mIoU)\n",
    "    chips_per_group = n_total_plots // 3\n",
    "    \n",
    "    bottom_third_data = chip_data[:chips_per_group]\n",
    "    middle_third_data = chip_data[chips_per_group:2 * chips_per_group]\n",
    "    top_third_data = chip_data[2 * chips_per_group:]\n",
    "\n",
    "    # Step 2: Select a subset of chips from each group, prioritizing certain classes\n",
    "    def select_chips(chips_pool, needed_count, reserve_class_id=None):\n",
    "        \"\"\"Helper to select chips, ensuring a specific class is included if possible.\"\"\"\n",
    "        selected_chips = []\n",
    "        # Try to find a chip with the reserved class first\n",
    "        if reserve_class_id is not None:\n",
    "            for i, chip in enumerate(chips_pool):\n",
    "                if reserve_class_id in chip[4]: # chip[4] is the class_list for this chip\n",
    "                    selected_chips.append(chip)\n",
    "                    # Remove from pool to avoid re-selecting\n",
    "                    chips_pool.pop(i) \n",
    "                    break\n",
    "        \n",
    "        # Fill remaining slots with random chips from the pool\n",
    "        random.shuffle(chips_pool) # Shuffle remaining for randomness\n",
    "        selected_chips.extend(chips_pool[:needed_count - len(selected_chips)])\n",
    "        return selected_chips\n",
    "\n",
    "    # Select chips from each performance group\n",
    "    # Prioritize water and building in the bottom (worst performing) third\n",
    "    selected_bottom = select_chips(bottom_third_data.copy(), 4, reserve_class_id=class_names.index(\"Water\"))\n",
    "    # If not enough, try adding a Building chip too\n",
    "    selected_bottom.extend(select_chips([c for c in bottom_third_data if c not in selected_bottom], \n",
    "                                         4 - len(selected_bottom), \n",
    "                                         reserve_class_id=class_names.index(\"Building\")))\n",
    "    \n",
    "    selected_middle = select_chips(middle_third_data.copy(), 4) # Random 4 from middle\n",
    "    selected_top = select_chips(top_third_data.copy(), 4) # Random 4 from top\n",
    "\n",
    "    # Combine all selected chips (will be up to 12 if n_rows=4, n_cols=3)\n",
    "    all_selected = selected_bottom + selected_middle + selected_top\n",
    "    # Trim to exactly n_total_plots if more were selected than needed (shouldn't happen with exact numbers)\n",
    "    all_selected = all_selected[:n_total_plots]\n",
    "\n",
    "    # Step 3: Plotting\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    # Handle cases where axs might be 1D (e.g., n_rows=1 or n_cols=1)\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axs = np.array([axs]) # Make it 2D (1,3)\n",
    "    elif n_rows == 1:\n",
    "        axs = np.expand_dims(axs, axis=0) # Make first dim 1 for (1, N)\n",
    "    elif n_cols == 1:\n",
    "        axs = np.expand_dims(axs, axis=1) # Make second dim 1 for (N, 1)\n",
    "\n",
    "    for idx_plot, (rgb, true_mask_oh, pred_mask_ids, _, _) in enumerate(all_selected):\n",
    "        # Convert true_mask from one-hot to class IDs for coloring\n",
    "        true_mask_ids = np.argmax(true_mask_oh, axis=-1)\n",
    "        h, w = true_mask_ids.shape\n",
    "\n",
    "        # Initialize RGB versions of masks for display\n",
    "        true_rgb_display = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb_display = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        # Color the true and predicted masks\n",
    "        for class_id, color in class_to_color.items():\n",
    "            true_rgb_display[true_mask_ids == class_id] = np.array(color, dtype=np.uint8)\n",
    "            pred_rgb_display[pred_mask_ids == class_id] = np.array(color, dtype=np.uint8)\n",
    "\n",
    "        # Apply ignore color (magenta) to ignored regions\n",
    "        ignore_mask = np.all(true_mask_oh == 0, axis=-1)\n",
    "        true_rgb_display[ignore_mask] = IGNORE_COLOR\n",
    "        pred_rgb_display[ignore_mask] = IGNORE_COLOR\n",
    "\n",
    "        row = idx_plot // n_cols\n",
    "        col = (idx_plot % n_cols) * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\", fontsize=10)\n",
    "        axs[row, col + 1].imshow(true_rgb_display)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\", fontsize=10)\n",
    "        axs[row, col + 2].imshow(pred_rgb_display)\n",
    "        axs[row, col + 2].set_title(\"Prediction\", fontsize=10)\n",
    "\n",
    "        for i_ax in range(3):\n",
    "            axs[row, col + i_ax].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig) # Explicitly close the figure\n",
    "\n",
    "\n",
    "# --- Conditional Random Field (CRF) Post-processing ---\n",
    "# This block attempts to import pydensecrf. If it's not installed, it defines\n",
    "# dummy functions to prevent NameErrors elsewhere.\n",
    "\n",
    "try:\n",
    "    import pydensecrf.densecrf as dcrf\n",
    "    from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "    def apply_crf(rgb: np.ndarray, probs: np.ndarray, t: int = 5, compat: int = 10, sxy: int = 3, schan: int = 13) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies Dense Conditional Random Field (CRF) post-processing to raw softmax predictions.\n",
    "        CRF refines segmentation boundaries by considering both pixel-wise probabilities\n",
    "        and image appearance (color and spatial proximity).\n",
    "\n",
    "        Args:\n",
    "            rgb (np.ndarray): The input RGB image (H, W, 3) as np.uint8 (0-255).\n",
    "            probs (np.ndarray): Softmax output probabilities from the model (H, W, num_classes).\n",
    "            t (int): Number of CRF inference iterations.\n",
    "            compat (int): Compatibility constant for the pairwise term.\n",
    "            sxy (int): Spatial standard deviation for the pairwise bilateral term.\n",
    "            schan (int): Color standard deviation for the pairwise bilateral term.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The refined segmentation mask (H, W) as integer class IDs.\n",
    "        \"\"\"\n",
    "        h, w = probs.shape[:2]\n",
    "        num_classes = probs.shape[-1]\n",
    "\n",
    "        d = dcrf.DenseCRF2D(w, h, num_classes)\n",
    "\n",
    "        # Reshape unary potentials from (H, W, num_classes) to (num_classes, H*W)\n",
    "        # Ensure it's C-contiguous for pydensecrf\n",
    "        unary = unary_from_softmax(probs.transpose(2, 0, 1)).reshape((num_classes, -1)).copy(order='C')\n",
    "        d.setUnaryEnergy(unary)\n",
    "\n",
    "        # Convert RGB to float32 and ensure C-contiguous for pydensecrf\n",
    "        rgb_float = np.ascontiguousarray(rgb.astype(np.float32))\n",
    "\n",
    "        # Create pairwise bilateral energy term\n",
    "        pairwise = create_pairwise_bilateral(sdims=(sxy, sxy), schan=(schan, schan, schan), img=rgb_float, chdim=2)\n",
    "        d.addPairwiseEnergy(pairwise, compat=compat)\n",
    "\n",
    "        # Perform inference\n",
    "        Q = d.inference(t)\n",
    "        # Return the most likely class ID for each pixel\n",
    "        return np.argmax(Q, axis=0).reshape((h, w))\n",
    "\n",
    "    def evaluate_model_with_crf(\n",
    "        model: tf.keras.Model,\n",
    "        test_gen: tf.data.Dataset,\n",
    "        test_df: pd.DataFrame,\n",
    "        out_dir: str,\n",
    "        image_dir: str, # Not directly used in function, but might be needed by calling code\n",
    "        label_dir: str, # Not directly used in function, but might be needed by calling code\n",
    "        tile_size: int = 256,\n",
    "        n_rows: int = 4,\n",
    "        n_cols: int = 3\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluates the trained model on the test set with CRF post-processing.\n",
    "        Calculates and prints overall and per-class metrics, generates a confusion matrix,\n",
    "        and visualizes sample predictions after CRF.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model): The trained Keras model.\n",
    "            test_gen (tf.data.Dataset): TensorFlow Dataset for the test set.\n",
    "            test_df (pd.DataFrame): DataFrame containing metadata for the test set.\n",
    "            out_dir (str): Directory to save plots.\n",
    "            image_dir (str): Path to the directory containing RGB images (for visualization, not CRF input).\n",
    "            label_dir (str): Path to the directory containing label images (for visualization).\n",
    "            tile_size (int): The size of the tiles (e.g., 256x256).\n",
    "            n_rows (int): Number of rows for the prediction visualization grid.\n",
    "            n_cols (int): Number of columns for the prediction visualization grid.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing various evaluation metrics.\n",
    "        \"\"\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        print(\"🧪 Running evaluation on test set with CRF post-processing...\")\n",
    "        all_preds_flat = [] # Flat list of all predicted class IDs (after CRF)\n",
    "        all_trues_flat = [] # Flat list of all true class IDs\n",
    "\n",
    "        rgb_list_viz = [] # RGB images for visualization\n",
    "        true_mask_list_viz = [] # True masks for visualization (one-hot)\n",
    "        pred_mask_list_viz = [] # Predicted masks for visualization (class IDs after CRF)\n",
    "        chip_ious = [] # Per-chip mIoUs (after CRF)\n",
    "\n",
    "        visual_limit = n_rows * n_cols # Max number of samples to collect for visualization\n",
    "        \n",
    "        test_df_tile_ids = test_df['tile_id'].tolist()\n",
    "        tile_index_in_df = 0 # To track which chip from test_df is being processed\n",
    "\n",
    "        for x_batch, y_batch_onehot in tqdm(test_gen, desc=\"CRF Evaluating\"):\n",
    "            # Skip empty batches\n",
    "            if tf.size(x_batch).numpy() == 0:\n",
    "                continue\n",
    "\n",
    "            # Get model's raw softmax predictions\n",
    "            soft_preds = model.predict(x_batch, verbose=0)\n",
    "\n",
    "            for i in range(x_batch.shape[0]):\n",
    "                if tile_index_in_df >= len(test_df_tile_ids): # Safety break\n",
    "                    break\n",
    "\n",
    "                # Extract RGB image for CRF (needs to be 0-255 uint8)\n",
    "                rgb_img = (x_batch[i][..., :3].numpy() * 255).astype(np.uint8)\n",
    "                softmax_pred_for_crf = soft_preds[i] # Softmax probabilities for current chip\n",
    "\n",
    "                # Apply CRF post-processing\n",
    "                crf_mask = apply_crf(rgb_img, softmax_pred_for_crf) # Returns class IDs (H, W)\n",
    "\n",
    "                # Get true mask as class IDs for metric calculation\n",
    "                true_mask_ids = np.argmax(y_batch_onehot[i], axis=-1).astype(np.uint8)\n",
    "\n",
    "                # Collect flattened predictions and true labels for overall metrics\n",
    "                all_preds_flat.extend(crf_mask.reshape(-1))\n",
    "                all_trues_flat.extend(true_mask_ids.reshape(-1))\n",
    "\n",
    "                # --- Per-chip IoU calculation ---\n",
    "                # This needs to be done here as it uses the CRF-processed mask\n",
    "                cm_chip = confusion_matrix(true_mask_ids.flatten(), crf_mask.flatten(), labels=list(range(NUM_CLASSES)))\n",
    "                ious_chip = []\n",
    "                for j in range(NUM_CLASSES):\n",
    "                    intersection_chip = cm_chip[j, j]\n",
    "                    union_chip = np.sum(cm_chip[j, :]) + np.sum(cm_chip[:, j]) - intersection_chip\n",
    "                    if union_chip > 0:\n",
    "                        iou_chip = intersection_chip / union_chip\n",
    "                        ious_chip.append(iou_chip)\n",
    "                chip_ious.append(np.mean(ious_chip) if ious_chip else 0)\n",
    "\n",
    "\n",
    "                # Collect visuals up to the limit\n",
    "                if len(rgb_list_viz) < visual_limit:\n",
    "                    rgb_list_viz.append(rgb_img)\n",
    "                    true_mask_list_viz.append(y_batch_onehot[i].numpy()) # Keep one-hot for plotting\n",
    "                    pred_mask_list_viz.append(crf_mask) # CRF output (class IDs)\n",
    "                    # You might also want to append the tile_id here if sorting by performance is used\n",
    "\n",
    "                tile_index_in_df += 1 # Move to the next tile in the test_df\n",
    "\n",
    "            gc.collect() # Garbage collection after each batch\n",
    "\n",
    "        # Convert collected lists to NumPy arrays for final metric calculations\n",
    "        all_preds_flat = np.array(all_preds_flat)\n",
    "        all_trues_flat = np.array(all_trues_flat)\n",
    "\n",
    "        if not all_preds_flat.size:\n",
    "            print(\"⚠️ No predictions collected for CRF evaluation. Skipping metrics and plots.\")\n",
    "            return {}\n",
    "\n",
    "        # --- Visualise Grid (using CRF outputs) ---\n",
    "        if rgb_list_viz:\n",
    "            print(f\"\\n🖼️ Visualizing {len(rgb_list_viz)} sample predictions with CRF...\")\n",
    "            visualise_prediction_grid(\n",
    "                rgb_list=rgb_list_viz,\n",
    "                true_mask_list=true_mask_list_viz, # These are one-hot, `visualise_prediction_grid` will convert\n",
    "                pred_mask_list=pred_mask_list_viz,\n",
    "                n_rows=n_rows,\n",
    "                n_cols=n_cols,\n",
    "                # If you want to use the performance-based grid (`visualise_prediction_grid_by_performance`),\n",
    "                # uncomment the line in your `train_unet`'s `evaluate_on_test` call\n",
    "                # and pass the appropriate lists (miou_list, class_list) to it.\n",
    "            )\n",
    "        else:\n",
    "            print(\"No samples collected for CRF visualization grid.\")\n",
    "\n",
    "        # --- Metrics Calculation (using CRF output) ---\n",
    "        \n",
    "        miou_metric_tf = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "        miou_metric_tf.update_state(all_trues_flat, all_preds_flat)\n",
    "        overall_miou = miou_metric_tf.result().numpy()\n",
    "\n",
    "        macro_f1 = f1_score(all_trues_flat, all_preds_flat, average='macro', zero_division=0)\n",
    "        macro_precision = precision_score(all_trues_flat, all_preds_flat, average='macro', zero_division=0)\n",
    "        macro_recall = recall_score(all_trues_flat, all_preds_flat, average='macro', zero_division=0)\n",
    "\n",
    "        conf_matrix_crf = confusion_matrix(all_trues_flat, all_preds_flat, labels=list(range(NUM_CLASSES)))\n",
    "        \n",
    "        # Per-class IoU\n",
    "        per_class_ious_crf = []\n",
    "        for i in range(NUM_CLASSES):\n",
    "            intersection_crf = conf_matrix_crf[i, i]\n",
    "            union_crf = np.sum(conf_matrix_crf[i, :]) + np.sum(conf_matrix_crf[:, i]) - intersection_crf\n",
    "            iou_crf = intersection_crf / union_crf if union_crf > 0 else float('nan') # Use NaN for undefined IoU\n",
    "            per_class_ious_crf.append(iou_crf)\n",
    "        \n",
    "        # Per-class F1, Precision, Recall\n",
    "        precision_crf, recall_crf, f1_crf, _ = precision_recall_fscore_support(\n",
    "            all_trues_flat, all_preds_flat, labels=list(range(NUM_CLASSES)), zero_division=0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📊 CRF Macro Metrics:\")\n",
    "        print(f\"  F1 Score     : {macro_f1:.4f}\")\n",
    "        print(f\"  Precision    : {macro_precision:.4f}\")\n",
    "        print(f\"  Recall       : {macro_recall:.4f}\")\n",
    "        print(f\"\\n📈 CRF Mean IoU (mIoU): {overall_miou:.4f}\")\n",
    "        print(\"\\n📏 CRF Per-class IoU Scores:\")\n",
    "        for i in range(NUM_CLASSES):\n",
    "            print(f\"  {CLASS_NAMES[i]:<12} IoU: {per_class_ious_crf[i]:.4f}\")\n",
    "        print(\"\\n🔍 CRF Per-class Classification Report (F1 | Precision | Recall):\")\n",
    "        for i, name in enumerate(CLASS_NAMES):\n",
    "            print(f\"{name:<12} | F1: {f1_crf[i]:.4f} | Prec: {precision_crf[i]:.4f} | Recall: {recall_crf[i]:.4f}\")\n",
    "\n",
    "        # Confusion Matrix Plot (Row-Normalised) for CRF\n",
    "        print(\"\\n🌀 Generating CRF Row-Normalised Confusion Matrix plot...\")\n",
    "        # Use the normalize_confusion_matrix helper for consistent normalization\n",
    "        norm_conf_crf = normalize_confusion_matrix(conf_matrix_crf, norm='true')\n",
    "\n",
    "        fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "        disp_crf = ConfusionMatrixDisplay(norm_conf_crf, display_labels=CLASS_NAMES)\n",
    "        disp_crf.plot(cmap='viridis', ax=ax_cm, values_format=\".2f\")\n",
    "        ax_cm.set_title(\"CRF Row-Normalised Confusion Matrix (True Label %) - Test Set\")\n",
    "        fig_cm.tight_layout()\n",
    "        cm_crf_save_path = os.path.join(out_dir, 'confusion_matrix_crf_row_norm.png')\n",
    "        fig_cm.savefig(cm_crf_save_path)\n",
    "        plt.show()\n",
    "        plt.close(fig_cm)\n",
    "        print(f\"Saved CRF confusion matrix to: {cm_crf_save_path}\")\n",
    "\n",
    "        # Per-chip mIoU histogram for CRF results\n",
    "        if chip_ious: # This list is populated in this function\n",
    "            print(\"\\n📊 Generating per-chip mIoU histogram (CRF post-processed)...\")\n",
    "            bin_edges = np.linspace(0, 1, 21) # 5% bins (0.0 to 1.0 in 0.05 increments)\n",
    "            fig_hist, ax_hist = plt.subplots(figsize=(10, 6))\n",
    "            ax_hist.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "            ax_hist.set_xlabel(\"Per-Chip mIoU\")\n",
    "            ax_hist.set_ylabel(\"Number of Chips\")\n",
    "            ax_hist.set_title(\"Distribution of Per-Chip mIoU (CRF Post-Processed)\")\n",
    "            ax_hist.grid(True)\n",
    "            fig_hist.tight_layout()\n",
    "            hist_crf_save_path = os.path.join(out_dir, \"per_chip_miou_hist_crf.png\")\n",
    "            fig_hist.savefig(hist_crf_save_path)\n",
    "            plt.show()\n",
    "            plt.close(fig_hist)\n",
    "            print(f\"Saved CRF per-chip mIoU histogram to: {hist_crf_save_path}\")\n",
    "\n",
    "        # Return results if needed by a calling function\n",
    "        return {\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"precision\": macro_precision,\n",
    "            \"recall\": macro_recall,\n",
    "            \"miou\": overall_miou,\n",
    "            \"per_class_ious\": per_class_ious_crf,\n",
    "            \"classification_report_str\": classification_report(\n",
    "                all_trues_flat, all_preds_flat, target_names=CLASS_NAMES, digits=4, zero_division=0\n",
    "            )\n",
    "        }\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nWarning: pydensecrf is not installed. Skipping CRF-related functions (apply_crf, evaluate_model_with_crf).\")\n",
    "    # Define dummy functions if CRF is not available, to avoid NameError elsewhere\n",
    "    def apply_crf(*args, **kwargs):\n",
    "        print(\"CRF post-processing skipped (pydensecrf not installed).\")\n",
    "        return np.zeros(args[0].shape[:2], dtype=np.uint8) # Return a dummy mask\n",
    "\n",
    "    def evaluate_model_with_crf(*args, **kwargs):\n",
    "        print(\"CRF evaluation skipped because pydensecrf is not installed.\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# --- Main Evaluation Function (without CRF) ---\n",
    "\n",
    "def evaluate_on_test(\n",
    "    model: tf.keras.Model,\n",
    "    test_gen: tf.data.Dataset,\n",
    "    test_df: pd.DataFrame,\n",
    "    out_dir: str,\n",
    "    image_dir: str, # Not directly used in this function for loading, but passed to visualise_prediction_grid\n",
    "    label_dir: str, # Not directly used in this function for loading, but passed to visualise_prediction_grid\n",
    "    tile_size: int = 256,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3,\n",
    "    specific_tile_ids: list = None # List of tile IDs to prioritize for visualization\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the test set, calculates various metrics (mIoU, F1, Precision, Recall),\n",
    "    generates a confusion matrix plot, and visualizes sample predictions (without CRF).\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        test_gen (tf.data.Dataset): TensorFlow Dataset for the test set.\n",
    "        test_df (pd.DataFrame): DataFrame containing metadata for the test set.\n",
    "        out_dir (str): Directory to save plots.\n",
    "        image_dir (str): Path to the directory containing RGB images (for visualization).\n",
    "        label_dir (str): Path to the directory containing label images (for visualization).\n",
    "        tile_size (int): The size of the tiles (e.g., 256x256).\n",
    "        n_rows (int): Number of rows for the prediction visualization grid.\n",
    "        n_cols (int): Number of columns for the prediction visualization grid.\n",
    "        specific_tile_ids (list, optional): List of specific tile IDs to prioritize for plotting.\n",
    "                                            Defaults to None (random selection).\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(\"🧪 Running evaluation on test set (without CRF)...\")\n",
    "\n",
    "    all_test_preds_flat = [] # Flat list of all predicted class IDs\n",
    "    all_test_trues_flat = [] # Flat list of all true class IDs\n",
    "\n",
    "    # Data collection for visualization\n",
    "    visual_rgb = []\n",
    "    visual_true = [] # Stores one-hot true masks for plotting\n",
    "    visual_pred = [] # Stores class ID predicted masks for plotting\n",
    "    visual_tile_ids = [] # Stores tile_ids for matching with specific_tile_ids\n",
    "    \n",
    "    # Calculate desired limit for visualization based on grid size\n",
    "    visual_limit = n_rows * n_cols\n",
    "\n",
    "    # Get all tile IDs from the test DataFrame for potential matching\n",
    "    test_df_tile_ids = test_df['tile_id'].tolist()\n",
    "    \n",
    "    tile_index_in_df = 0 # To track which chip from test_df is being processed\n",
    "\n",
    "    # Iterate through the test generator\n",
    "    for batch_x, batch_y_onehot in tqdm(test_gen, desc=\"Evaluating\"):\n",
    "        # Skip empty batches if any\n",
    "        if tf.size(batch_x).numpy() == 0:\n",
    "            continue\n",
    "\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        pred_probs = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_batch = np.argmax(pred_probs, axis=-1).astype(np.uint8)\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_batch_ids = np.argmax(batch_y_onehot, axis=-1).numpy().astype(np.uint8)\n",
    "\n",
    "        # Process each image in the current batch\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            # Stop if we have processed all tiles in test_df (safety break)\n",
    "            if tile_index_in_df >= len(test_df_tile_ids):\n",
    "                break\n",
    "            \n",
    "            current_tile_id = test_df_tile_ids[tile_index_in_df]\n",
    "            \n",
    "            # Collect data for visualization up to the visual_limit\n",
    "            if len(visual_rgb) < visual_limit:\n",
    "                # RGB image (scale from [0,1] to [0,255] and cast to uint8)\n",
    "                # Assumes RGB is always the first 3 channels if it's a multi-channel input\n",
    "                rgb_tile = (batch_x[j][:, :, :3].numpy() * 255).astype(np.uint8)\n",
    "                visual_rgb.append(rgb_tile)\n",
    "                visual_true.append(batch_y_onehot[j].numpy()) # Keep true mask as one-hot for plotting\n",
    "                visual_pred.append(pred_mask_batch[j]) # Predicted mask (class IDs)\n",
    "                visual_tile_ids.append(current_tile_id)\n",
    "\n",
    "            # Collect all true and predicted pixels for overall metric calculation\n",
    "            all_test_preds_flat.extend(pred_mask_batch[j].reshape(-1))\n",
    "            all_test_trues_flat.extend(true_mask_batch_ids[j].reshape(-1)) # Flatten for metric calculation\n",
    "\n",
    "            tile_index_in_df += 1 # Move to the next tile in the test_df\n",
    "\n",
    "        # Explicitly delete batch variables and collect garbage to free memory\n",
    "        del batch_x, batch_y_onehot, pred_probs, pred_mask_batch, true_mask_batch_ids\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds_flat:\n",
    "        print(\"⚠️ No test predictions were collected. Evaluation skipped.\")\n",
    "        return {}\n",
    "\n",
    "    # Convert lists to NumPy arrays for metric calculations\n",
    "    all_test_preds_flat = np.array(all_test_preds_flat)\n",
    "    all_test_trues_flat = np.array(all_test_trues_flat)\n",
    "\n",
    "    # --- Visualise Grid ---\n",
    "    if visual_rgb: # Only plot if there's data to visualize\n",
    "        print(f\"\\n🖼️ Visualizing {len(visual_rgb)} sample predictions (without CRF)...\")\n",
    "        visualise_prediction_grid(\n",
    "            rgb_list=visual_rgb,\n",
    "            true_mask_list=visual_true, # Pass one-hot true masks\n",
    "            pred_mask_list=visual_pred,\n",
    "            tile_id_list=specific_tile_ids, # Pass specific tile IDs to prioritize\n",
    "            all_tile_ids=visual_tile_ids, # Pass the tile IDs collected during evaluation\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols\n",
    "        )\n",
    "    else:\n",
    "        print(\"No samples collected for visualization grid.\")\n",
    "\n",
    "    # --- Overall Mean IoU ---\n",
    "    mean_iou_metric_tf = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "    mean_iou_metric_tf.update_state(all_test_trues_flat, all_test_preds_flat)\n",
    "    miou = mean_iou_metric_tf.result().numpy()\n",
    "    print(f\"\\n📈 Overall Mean IoU (mIoU): {miou:.4f}\")\n",
    "\n",
    "    # --- Macro F1, Precision, Recall ---\n",
    "    # Using sklearn for macro averages\n",
    "    macro_f1 = f1_score(all_test_trues_flat, all_test_preds_flat, average='macro', zero_division=0)\n",
    "    macro_precision = precision_score(all_test_trues_flat, all_test_preds_flat, average='macro', zero_division=0)\n",
    "    macro_recall = recall_score(all_test_trues_flat, all_test_preds_flat, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\n📊 Macro Metrics:\")\n",
    "    print(f\" F1 Score   : {macro_f1:.4f}\")\n",
    "    print(f\" Precision  : {macro_precision:.4f}\")\n",
    "    print(f\" Recall     : {macro_recall:.4f}\")\n",
    "\n",
    "    # --- Confusion Matrix & Per-class IoU ---\n",
    "    conf_matrix = confusion_matrix(all_test_trues_flat, all_test_preds_flat, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"\\n📏 Per-class IoU Scores:\")\n",
    "    class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else float('nan') # Use NaN for undefined IoU\n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {CLASS_NAMES[i]:<12} IoU: {iou:.4f}\")\n",
    "\n",
    "    # --- Per-class F1, Precision, Recall ---\n",
    "    # Using sklearn's precision_recall_fscore_support for per-class metrics\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
    "        all_test_trues_flat, all_test_preds_flat, labels=list(range(NUM_CLASSES)), zero_division=0\n",
    "    )\n",
    "    print(\"\\n🔍 Per-class Classification Report (F1 | Precision | Recall):\")\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        print(f\"{name:<12} | F1: {f1_per_class[i]:.4f} | Prec: {precision_per_class[i]:.4f} | Recall: {recall_per_class[i]:.4f}\")\n",
    "\n",
    "    # --- Confusion Matrix Plot (Row-Normalised) ---\n",
    "    print(\"\\n🌀 Generating Row-Normalised Confusion Matrix plot...\")\n",
    "    norm_conf = normalize_confusion_matrix(conf_matrix, norm='true')\n",
    "\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "    disp_cm = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp_cm.plot(cmap='viridis', ax=ax_cm, values_format=\".2f\")\n",
    "    ax_cm.set_title(\"Row-Normalised Confusion Matrix (True Label %) - Test Set\")\n",
    "    fig_cm.tight_layout()\n",
    "    cm_save_path = os.path.join(out_dir, 'confusion_matrix_row_norm.png')\n",
    "    fig_cm.savefig(cm_save_path)\n",
    "    plt.show()\n",
    "    plt.close(fig_cm)\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    # --- Per-chip mIoU histogram ---\n",
    "    # Note: To enable this, you need to add per-chip IoU calculation in this function's loop.\n",
    "    # Currently, 'chip_ious' is only collected in evaluate_model_with_crf.\n",
    "    # If you want this histogram without CRF, you'd add:\n",
    "    #     cm_chip = confusion_matrix(true_mask_batch_ids[j].flatten(), pred_mask_batch[j].flatten(), labels=list(range(NUM_CLASSES)))\n",
    "    #     # ... calculate ious_chip from cm_chip ...\n",
    "    #     chip_ious.append(np.mean(ious_chip) if ious_chip else 0)\n",
    "    # inside the loop, and then uncomment the histogram plotting.\n",
    "    # For now, it remains commented out.\n",
    "\n",
    "    # Return results if needed by a calling function\n",
    "    return {\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"precision\": macro_precision,\n",
    "        \"recall\": macro_recall,\n",
    "        \"miou\": miou,\n",
    "        \"per_class_ious\": class_ious,\n",
    "        \"classification_report_str\": classification_report(\n",
    "            all_test_trues_flat, all_test_preds_flat, target_names=CLASS_NAMES, digits=4, zero_division=0\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Reconstruction Utility ---\n",
    "\n",
    "def reconstruct_canvas(\n",
    "    model: tf.keras.Model,\n",
    "    df: pd.DataFrame,\n",
    "    source_file_prefix: str, # The common prefix for all chips of one large image\n",
    "    generator_class: callable, # The function to build the TensorFlow dataset (e.g., `build_tf_dataset`)\n",
    "    img_dir: str,\n",
    "    elev_dir: str,\n",
    "    slope_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file by stitching together its individual chips.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        df (pd.DataFrame): The DataFrame containing metadata for all chips (e.g., test_df).\n",
    "        source_file_prefix (str): The common prefix for all chips belonging to the same large image.\n",
    "                                  (e.g., \"25f1c24f30_EB81FE6E2BOPENPIPELINE\")\n",
    "        generator_class (callable): The function to build the TensorFlow dataset (e.g., `build_tf_dataset`).\n",
    "        img_dir (str): Directory containing RGB images.\n",
    "        elev_dir (str): Directory containing elevation .npy files.\n",
    "        slope_dir (str): Directory containing slope .npy files.\n",
    "        label_dir (str): Directory containing label images.\n",
    "        tile_size (int): The size of individual tiles/chips (e.g., 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the\n",
    "        reconstructed RGB canvas, Ground Truth canvas, and Prediction canvas (all as np.uint8).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no chips are found for the specified source file prefix.\n",
    "    \"\"\"\n",
    "    # Filter for chips belonging to the specific source file prefix\n",
    "    # Assuming 'tile_id' column contains the full ID like 'prefix_x_y'\n",
    "    df_file = df[df['tile_id'].str.startswith(source_file_prefix)].copy()\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file prefix: {source_file_prefix}\")\n",
    "\n",
    "    # Determine the overall canvas shape based on min/max x,y coordinates and tile size\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + tile_size\n",
    "    max_y = df_file['y'].max() + tile_size\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape_rgb = (canvas_h, canvas_w, 3)\n",
    "    canvas_shape_mask = (canvas_h, canvas_w, 3) # For GT/Pred, will be colored RGB\n",
    "\n",
    "    # Initialize canvases with IGNORE_COLOR (magenta) for padding/uncovered areas\n",
    "    rgb_canvas = np.full(canvas_shape_rgb, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Build dataset for just this file's chips, ensuring correct order for stitching\n",
    "    # Use shuffle=False and augment=False for reconstruction, and a 'val' or 'test' split\n",
    "    # to guarantee no augmentation. Batch size can be larger for efficiency during inference.\n",
    "    # Assuming 'generator_class' (e.g., build_tf_dataset) can accept a 'split' argument.\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"val\" # Use 'val' or 'test' to ensure no augments\n",
    "    )\n",
    "\n",
    "    # Iterate through the generated batches, predict, and fill the canvases in order\n",
    "    row_index_in_df = 0 # Tracks position in the filtered df_file to get (x,y) coords\n",
    "    for batch_x, batch_y_onehot in tqdm(gen, desc=f\"Reconstructing {source_file_prefix}\"):\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        preds_softmax = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_ids = tf.argmax(preds_softmax, axis=-1).numpy()\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_ids = tf.argmax(batch_y_onehot, axis=-1).numpy()\n",
    "\n",
    "        batch_size_actual = batch_x.shape[0]\n",
    "        for i in range(batch_size_actual):\n",
    "            if row_index_in_df >= len(df_file): # Safety break if we've processed all chips\n",
    "                break\n",
    "\n",
    "            # Get chip's original (x, y) coordinates from the DataFrame\n",
    "            row_df_entry = df_file.iloc[row_index_in_df]\n",
    "            rel_x = row_df_entry.x - min_x # Relative X coordinate for placing on canvas\n",
    "            rel_y = row_df_entry.y - min_y # Relative Y coordinate for placing on canvas\n",
    "            row_index_in_df += 1\n",
    "\n",
    "            # Extract current chip data (RGB is always first 3 channels)\n",
    "            # Scale from [0,1] to [0,255] and cast to uint8\n",
    "            rgb_chip = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            true_mask_chip = true_mask_ids[i]\n",
    "            pred_mask_chip = pred_mask_ids[i]\n",
    "\n",
    "            # Place RGB chip onto the canvas\n",
    "            rgb_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = rgb_chip\n",
    "\n",
    "            # Color and place Ground Truth mask onto the canvas\n",
    "            gt_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb_chip[true_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            gt_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = gt_rgb_chip\n",
    "\n",
    "            # Color and place Prediction mask onto the canvas\n",
    "            pred_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb_chip[pred_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            pred_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = pred_rgb_chip\n",
    "    \n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "def plot_reconstruction(img: np.ndarray, label: np.ndarray, pred: np.ndarray, source_file_prefix: str):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file prefix.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The reconstructed RGB image canvas (uint8).\n",
    "        label (np.ndarray): The reconstructed ground truth mask canvas (colored, uint8).\n",
    "        pred (np.ndarray): The reconstructed prediction mask canvas (colored, uint8).\n",
    "        source_file_prefix (str): The common prefix of the source file for the title.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\", fontsize=18)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\", fontsize=18)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\", fontsize=18)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file_prefix}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def normalize_confusion_matrix(cm: np.ndarray, norm: str = 'true') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        cm (np.ndarray): Confusion matrix to be normalized (integer counts).\n",
    "        norm (str): Type of normalization.\n",
    "                    - 'true': Normalize by true labels (rows sum to 1).\n",
    "                    - 'pred': Normalize by predicted labels (columns sum to 1).\n",
    "                    - 'all': Normalize by total count (matrix sums to 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalized confusion matrix (float, sums to 1 along specified axis/total).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an unknown normalization type is provided.\n",
    "    \"\"\"\n",
    "    cm_normalized = cm.astype(np.float32)\n",
    "\n",
    "    if norm == 'true':\n",
    "        # Normalize each row by its sum\n",
    "        row_sums = cm_normalized.sum(axis=1, keepdims=True)\n",
    "        # Use np.divide with 'where' clause to avoid division by zero\n",
    "        cm_normalized = np.divide(cm_normalized, row_sums, where=row_sums != 0)\n",
    "        # Fill NaN results (where row_sum was 0, meaning no true samples for that class) with 0\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    elif norm == 'pred':\n",
    "        # Normalize each column by its sum\n",
    "        col_sums = cm_normalized.sum(axis=0, keepdims=True)\n",
    "        cm_normalized = np.divide(cm_normalized, col_sums, where=col_sums != 0)\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    elif norm == 'all':\n",
    "        # Normalize by the grand total sum\n",
    "        total_sum = cm_normalized.sum()\n",
    "        cm_normalized = cm_normalized / total_sum if total_sum > 0 else cm_normalized\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n",
    "    \n",
    "    return cm_normalized\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import segmentation_models as sm\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras import mixed_precision # Required for LossScaleOptimizer\n",
    "import gc\n",
    "from PIL import Image # Used for Image.fromarray in some visualization tasks (though not directly here)\n",
    "from datetime import datetime # Often used for timestamps in model saving\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import random\n",
    "# from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral # Imports for CRF, often within function\n",
    "# import pydensecrf.densecrf as dcrf # Imports for CRF, often within function\n",
    "\n",
    "# Clear Keras session to avoid conflicts with previous models\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# --- Global Configuration and Constants ---\n",
    "\n",
    "# Number of semantic classes\n",
    "NUM_CLASSES = 6\n",
    "# Names corresponding to each class ID\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "# Mapping from RGB color (as tuple) to integer class ID\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,      # Building\n",
    "    (145, 30, 180): 1,     # Clutter\n",
    "    (60, 180, 75): 2,      # Vegetation\n",
    "    (245, 130, 48): 3,     # Water\n",
    "    (255, 255, 255): 4,    # Background\n",
    "    (0, 130, 200): 5,      # Car\n",
    "    (255, 0, 255): 6       # Often used as an \"ignore\" or \"padding\" pixel color\n",
    "}\n",
    "\n",
    "# Inverse mapping from integer class ID to RGB color (as tuple)\n",
    "# Excludes the ignore class (ID 6) for visualization purposes\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < NUM_CLASSES}\n",
    "IGNORE_COLOR = (255, 0, 255) # The specific color for ignored regions (magenta)\n",
    "\n",
    "# Output directory for plots and saved models\n",
    "out_dir = \"/content/figs\"\n",
    "\n",
    "# Configuration for different input types (RGB only or RGB + Elevation)\n",
    "INPUT_TYPE_CONFIG = {\n",
    "    \"rgb\": {\"description\": \"RGB only\", \"channels\": 3},\n",
    "    \"rgb_elev\": {\"description\": \"RGB + elevation + slope\", \"channels\": 5} # RGB (3) + Elev (1) + Slope (1)\n",
    "}\n",
    "\n",
    "\n",
    "# List of specific tile IDs to select for detailed visualization (e.g., hard examples)\n",
    "# These are the full tile_id strings including x_y coordinates\n",
    "specific_tile_ids = [\n",
    "    # Group 1 (Example source file: 25f1c24f30_EB81FE6E2BOPENPIPELINE)\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE_3456_1280\", \"25f1c24f30_EB81FE6E2BOPENPIPELINE_3584_8320\",\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE_896_2816\", \"25f1c24f30_EB81FE6E2BOPENPIPELINE_3840_4736\",\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE_3968_384\", \"25f1c24f30_EB81FE6E2BOPENPIPELINE_4736_512\",\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE_4736_768\", \"25f1c24f30_EB81FE6E2BOPENPIPELINE_1024_5888\",\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE_896_5888\", \"25f1c24f30_EB81FE6E2BOPENPIPELINE_1024_6016\",\n",
    "\n",
    "    # Group 2 (Example source file: 1d4fbe33f3_F1BE1D4184INSPIRE)\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_2560_4864\", \"1d4fbe33f3_F1BE1D4184INSPIRE_896_3584\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_768_3584\", \"1d4fbe33f3_F1BE1D4184INSPIRE_896_3712\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_1280_2432\", \"1d4fbe33f3_F1BE1D4184INSPIRE_1536_4608\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_1152_2432\", \"1d4fbe33f3_F1BE1D4184INSPIRE_1664_4864\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_1664_4736\", \"1d4fbe33f3_F1BE1D4184INSPIRE_1408_1280\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_1152_4864\", \"1d4fbe33f3_F1BE1D4184INSPIRE_1280_2432\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_1408_1408\", \"1d4fbe33f3_F1BE1D4184INSPIRE_1536_4736\",\n",
    "    \"1d4fbe33f3_F1BE1D4184INSPIRE_384_1152\",\n",
    "\n",
    "    # Group 3 (Example source file: 15efe45820_D95DF0B1F4INSPIRE)\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_4736_9472\", \"15efe45820_D95DF0B1F4INSPIRE_9600_6016\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_5888_6272\", \"15efe45820_D95DF0B1F4INSPIRE_7168_7936\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_6016_6272\", \"15efe45820_D95DF0B1F4INSPIRE_8704_1024\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_7040_6912\", \"15efe45820_D95DF0B1F4INSPIRE_8064_3968\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_2688_2048\", \"15efe45820_D95DF0B1F4INSPIRE_7680_1920\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_6272_10624\", \"15efe45820_D95DF0B1F4INSPIRE_6784_6784\",\n",
    "    \"15efe45820_D95DF0B1F4INSPIRE_6528_8576\",\n",
    "\n",
    "    # Group 4 (Example source file: c6d131e346_536DE05ED2OPENPIPELINE)\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_128_896\", \"c6d131e346_536DE05ED2OPENPIPELINE_256_768\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_256_896\", \"c6d131e346_536DE05ED2OPENPIPELINE_1792_512\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_1792_640\", \"c6d131e346_536DE05ED2OPENPIPELINE_256_640\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_128_640\", \"c6d131e346_536DE05ED2OPENPIPELINE_128_128\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_256_128\", \"c6d131e346_536DE05ED2OPENPIPELINE_256_512\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2688_2176\", \"c6d131e346_536DE05ED2OPENPIPELINE_2560_2176\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2688_2048\", \"c6d131e346_536DE05ED2OPENPIPELINE_2560_2048\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2688_2304\", \"c6d131e346_536DE05ED2OPENPIPELINE_2560_2304\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2816_2176\", \"c6d131e346_536DE05ED2OPENPIPELINE_2816_2048\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2816_2304\", \"c6d131e346_536DE05ED2OPENPIPELINE_2304_2560\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2304_2688\", \"c6d131e346_536DE05ED2OPENPIPELINE_2432_2688\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2432_2560\", \"c6d131e346_536DE05ED2OPENPIPELINE_2176_2560\",\n",
    "    \"c6d131e346_536DE05ED2OPENPIPELINE_2176_2688\",\n",
    "\n",
    "    # Group 5 (Example source file: 12fa5e614f_53197F206FOPENPIPELINE)\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_384_3072\", \"12fa5e614f_53197F206FOPENPIPELINE_512_3072\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_256_3200\", \"12fa5e614f_53197F206FOPENPIPELINE_1024_3712\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_384_3200\", \"12fa5e614f_53197F206FOPENPIPELINE_640_3072\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_256_3328\", \"12fa5e614f_53197F206FOPENPIPELINE_256_3072\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_3200_1152\", \"12fa5e614f_53197F206FOPENPIPELINE_1152_2688\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_1536_2432\", \"12fa5e614f_53197F206FOPENPIPELINE_1280_2560\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_1536_2048\", \"12fa5e614f_53197F206FOPENPIPELINE_512_3840\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_512_3712\", \"12fa5e614f_53197F206FOPENPIPELINE_1664_2304\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_384_3456\", \"12fa5e614f_53197F206FOPENPIPELINE_384_3328\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_1280_3584\", \"12fa5e614f_53197F206FOPENPIPELINE_384_3584\",\n",
    "    \"12fa5e614f_53197F206FOPENPIPELINE_3072_1152\", \"12fa5e614f_53197F206FOPENPIPELINE_3456_1024\",\n",
    "\n",
    "    # Group 6 (Example source file: 5fa39d6378_DB9FF730D9OPENPIPELINE)\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_3072_2688\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1024_6784\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_3712_2816\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_3200_2688\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_2944_2816\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_4224_3072\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_3328_4992\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1024_6528\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_3840_5888\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_2816_4224\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_5760_1920\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_3328_2816\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4352_4864\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_3072_6912\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4096_3328\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_2816_3968\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_5888_1920\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1280_2432\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_3584_2560\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1280_5632\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_1280_5504\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1408_5504\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_1408_5632\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_4608_4480\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4608_4352\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_4736_4480\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_2816_6400\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_2944_6400\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_1280_5760\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_2816_6528\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_2944_6528\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1408_5760\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4608_4608\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_4480_4352\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4736_4608\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_4480_4480\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_1280_5376\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1408_5376\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_4736_4352\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_2816_6272\",\n",
    "    \"5fa39d6378_DB9FF730D9OPENPIPELINE_2944_6272\", \"5fa39d6378_DB9FF730D9OPENPIPELINE_1152_5760\"\n",
    "]\n",
    "\n",
    "# --- Custom Callbacks (Placeholders - assuming their full definitions are available elsewhere) ---\n",
    "\n",
    "class TimeLimitCallback(Callback):\n",
    "    \"\"\"\n",
    "    Keras Callback to stop training after a specified number of minutes.\n",
    "    Assumes `datetime` from `datetime` module is imported.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_minutes):\n",
    "        super().__init__()\n",
    "        self.max_minutes = max_minutes\n",
    "        self.start_time = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = datetime.now()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.start_time is None: # Should not happen if on_train_begin is called\n",
    "            return\n",
    "        elapsed_minutes = (datetime.now() - self.start_time).total_seconds() / 60\n",
    "        if elapsed_minutes > self.max_minutes:\n",
    "            print(f\"\\nTime limit of {self.max_minutes} minutes reached. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "class StepTimer(Callback):\n",
    "    \"\"\"\n",
    "    Keras Callback to print the time taken per step (batch).\n",
    "    Assumes `time` module is imported.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.timetaken = tf.Variable(0., dtype=tf.float32)\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs={}):\n",
    "        self.timetaken.assign(tf.timestamp())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "        batch_time = tf.timestamp() - self.timetaken\n",
    "        self.times.append(batch_time.numpy())\n",
    "        if batch % 100 == 0: # Print every 100 batches\n",
    "            print(f\"Batch {batch}: {batch_time.numpy():.4f} seconds/step\")\n",
    "\n",
    "# --- Custom Learning Rate Schedule ---\n",
    "\n",
    "class TransformerLRSchedule(LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Custom learning rate schedule inspired by the Transformer model.\n",
    "    The learning rate increases linearly for the first `warmup_steps`\n",
    "    and then decreases proportionally to the inverse square root of the step number.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: float, warmup_steps: int = 4000):\n",
    "        \"\"\"\n",
    "        Initializes the Transformer learning rate schedule.\n",
    "\n",
    "        Args:\n",
    "            d_model (float): The dimensionality of the model's embeddings.\n",
    "            warmup_steps (int): The number of warm-up steps during which the learning rate increases.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "\n",
    "    def __call__(self, step: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the learning rate for a given training step.\n",
    "\n",
    "        Args:\n",
    "            step (tf.Tensor): The current global training step (scalar).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The calculated learning rate.\n",
    "        \"\"\"\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        # Inverse square root of step (decay part)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        # Linear warmup part\n",
    "        arg2 = step * tf.pow(self.warmup_steps, -1.5)\n",
    "        \n",
    "        # Combine the two parts: min(linear_warmup, inverse_sqrt_decay)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns the configuration of the learning rate schedule for serialization.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the configuration parameters.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"d_model\": self.d_model.numpy(),  # convert back to Python float\n",
    "            \"warmup_steps\": self.warmup_steps.numpy()\n",
    "        }\n",
    "\n",
    "# --- Dynamic Class Weight Updater Callback ---\n",
    "\n",
    "class DynamicClassWeightUpdater(Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to dynamically update class weights during training based on\n",
    "    per-class F1-score or IoU on the validation set. Weights are updated every `update_every`\n",
    "    epochs, typically set inversely proportional to the metric (1/metric).\n",
    "    \"\"\"\n",
    "    def __init__(self, val_data: tf.data.Dataset, update_every: int = 5, \n",
    "                 target: str = 'f1', ignore_class: int = None):\n",
    "        \"\"\"\n",
    "        Initializes the DynamicClassWeightUpdater callback.\n",
    "\n",
    "        Args:\n",
    "            val_data (tf.data.Dataset): The TensorFlow Dataset to use for validation metrics.\n",
    "            update_every (int): How often (in epochs) to update the class weights.\n",
    "            target (str): The metric to target for weighting ('f1' or 'iou').\n",
    "            ignore_class (int, optional): Class ID to ignore (set its weight to 0.0). Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.val_data = val_data\n",
    "        self.update_every = update_every\n",
    "        self.target = target\n",
    "        self.ignore_class = ignore_class\n",
    "        # Ensure class_weights is a tf.Variable, expected to be passed from the model compile scope\n",
    "        # self.class_weights will be assigned in on_train_begin if using tf.Variable for loss.\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Method called at the end of each epoch. Updates weights if `epoch + 1` is a multiple\n",
    "        of `update_every`.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number.\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if (epoch + 1) % self.update_every != 0:\n",
    "            return\n",
    "\n",
    "        # Ensure the `class_weights` variable from the model's loss is accessible and trainable\n",
    "        # This assumes `class_weights` is a tf.Variable in your loss function's scope.\n",
    "        # A more robust way might involve passing the tf.Variable reference directly in __init__\n",
    "        # or having the loss function itself be a Keras Layer that exposes the variable.\n",
    "        # For this setup, we assume `class_weights` is a global tf.Variable that the loss uses.\n",
    "        global class_weights # Access the global tf.Variable class_weights\n",
    "\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "        # Predict on validation data to compute per-class metrics\n",
    "        print(f\"\\n📊 Epoch {epoch+1}: Computing per-class metrics for dynamic weight update...\")\n",
    "        for x_batch, y_batch in self.val_data:\n",
    "            # Predict with verbose=0 to suppress per-batch output\n",
    "            preds = self.model.predict(x_batch, verbose=0) \n",
    "            # Convert one-hot to class IDs and flatten for metric calculation\n",
    "            y_true = tf.argmax(y_batch, axis=-1).numpy().flatten()\n",
    "            y_pred = tf.argmax(preds, axis=-1).numpy().flatten()\n",
    "\n",
    "            y_true_all.extend(y_true)\n",
    "            y_pred_all.extend(y_pred)\n",
    "\n",
    "        y_true_all = np.array(y_true_all)\n",
    "        y_pred_all = np.array(y_pred_all)\n",
    "\n",
    "        new_weights = []\n",
    "\n",
    "        for i in range(NUM_CLASSES):\n",
    "            if self.ignore_class is not None and i == self.ignore_class:\n",
    "                new_weights.append(0.0) # Set weight to 0 for ignored class\n",
    "                continue\n",
    "\n",
    "            if self.target == 'f1':\n",
    "                # f1_score from sklearn.metrics\n",
    "                # zero_division=0 means F1 is 0 if no true samples for class\n",
    "                f1 = f1_score(y_true_all == i, y_pred_all == i, zero_division=0)\n",
    "                weight = 1.0 if f1 == 0 else 1.0 / f1\n",
    "            else: # target == 'iou'\n",
    "                # Manual IoU calculation for the class\n",
    "                intersection = np.logical_and(y_true_all == i, y_pred_all == i).sum()\n",
    "                union = (y_true_all == i).sum() + (y_pred_all == i).sum() - intersection\n",
    "                iou = intersection / union if union > 0 else 0.0\n",
    "                weight = 1.0 if iou == 0 else 1.0 / iou\n",
    "\n",
    "            new_weights.append(weight)\n",
    "\n",
    "        # Normalize weights to prevent extremely large values and maintain scale\n",
    "        new_weights = np.array(new_weights, dtype=np.float32)\n",
    "        new_weights = new_weights / new_weights.max() # normalise by max value\n",
    "\n",
    "        # Update the TensorFlow Variable\n",
    "        class_weights.assign(new_weights)\n",
    "        print(f\"\\n📈 Epoch {epoch+1}: Updated class weights: {new_weights}\\n\")\n",
    "\n",
    "# --- Custom Metric for Mean IoU ---\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" # Ensure Segmentation Models uses TensorFlow/Keras backend\n",
    "\n",
    "class MeanIoUMetric(tf.keras.metrics.MeanIoU):\n",
    "    \"\"\"\n",
    "    Custom Mean IoU metric for Keras, handling one-hot encoded true labels and\n",
    "    softmax predictions by taking argmax before calculation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int, name: str = \"mean_iou\", dtype=None):\n",
    "        \"\"\"\n",
    "        Initializes the MeanIoUMetric.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): The total number of classes.\n",
    "            name (str): The name of the metric instance.\n",
    "            dtype: The data type of the metric's state variables.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true: tf.Tensor, y_pred: tf.Tensor, sample_weight: tf.Tensor = None):\n",
    "        \"\"\"\n",
    "        Updates the metric's state variables.\n",
    "\n",
    "        Args:\n",
    "            y_true (tf.Tensor): Ground truth labels (one-hot encoded).\n",
    "            y_pred (tf.Tensor): Model predictions (softmax probabilities).\n",
    "            sample_weight (tf.Tensor, optional): Optional weighting of samples. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Convert one-hot true labels to class IDs\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        # Convert softmax predictions to class IDs\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        return super().update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "\n",
    "# --- Loss Function Helpers ---\n",
    "\n",
    "def apply_label_smoothing(y_true: tf.Tensor, smoothing: float = 0.1) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Applies label smoothing to one-hot encoded ground truth labels.\n",
    "    This helps prevent the model from becoming overconfident and can improve generalization.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): True labels (one-hot encoded).\n",
    "        smoothing (float): The smoothing factor (0.0 for no smoothing, 1.0 for uniform distribution).\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Smoothed true labels.\n",
    "    \"\"\"\n",
    "    num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "    # y_true * (1 - smoothing) distributes (1-smoothing) probability to the true class\n",
    "    # (smoothing / num_classes) distributes 'smoothing' probability uniformly across all classes\n",
    "    return y_true * (1.0 - smoothing) + (smoothing / num_classes)\n",
    "\n",
    "def apply_ignore_class_mask(y_true: tf.Tensor, y_pred: tf.Tensor, \n",
    "                            ignore_class: int = 4, loss_fn: callable = None) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Applies a mask to a pixel-wise loss function to ignore contributions from a specific class (e.g., Background).\n",
    "    This function expects `loss_fn` to return a pixel-wise loss (not a scalar sum).\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Ground truth labels (one-hot encoded, or 2D class IDs if passed to loss_fn).\n",
    "        y_pred (tf.Tensor): Model predictions (softmax probabilities).\n",
    "        ignore_class (int): The class ID to ignore in loss calculation.\n",
    "        loss_fn (callable): The base loss function (e.g., CCE, Dice, Focal) that calculates\n",
    "                            loss per pixel/element. This function should accept y_true and y_pred.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The masked and reduced loss. Returns scalar if original loss_fn is scalar,\n",
    "                   otherwise sums and normalizes the masked pixel-wise loss.\n",
    "    \"\"\"\n",
    "    # y_true, y_pred shape: (batch, h, w, num_classes)\n",
    "    class_ids = tf.argmax(y_true, axis=-1)  # shape: (batch, h, w)\n",
    "    mask = tf.not_equal(class_ids, ignore_class)  # Boolean mask: shape (batch, h, w)\n",
    "\n",
    "    mask = tf.cast(mask, tf.float32)  # Convert mask to float32: same shape as class_ids\n",
    "    mask = tf.expand_dims(mask, axis=-1)  # Expand to (batch, h, w, 1) for broadcasting\n",
    "\n",
    "    # Apply base loss function\n",
    "    loss = loss_fn(y_true, y_pred)  # shape: (batch, h, w, 1) or scalar if loss_fn is already averaged\n",
    "\n",
    "    # If the loss_fn returns a scalar (already averaged), we cannot apply pixel-wise masking.\n",
    "    # In such a case, the ignore_class logic would need to be integrated directly into the\n",
    "    # definition of the base loss function (e.g., custom DiceLoss).\n",
    "    if len(loss.shape) < 4:\n",
    "        tf.print(\"Warning: apply_ignore_class_mask received a scalar loss. Pixel-wise masking may not apply correctly.\")\n",
    "        return loss # Cannot apply pixel-wise mask if loss is already aggregated.\n",
    "\n",
    "    masked_loss = loss * mask # Apply the mask element-wise\n",
    "    # Return the sum of masked loss divided by the sum of the mask (to average only over non-ignored pixels)\n",
    "    # Add a small epsilon to the denominator to prevent division by zero if mask is all zeros.\n",
    "    return tf.reduce_sum(masked_loss) / (tf.reduce_sum(mask) + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "# --- Image Decoding (Similar to data_pipeline, ensuring consistency) ---\n",
    "\n",
    "# Note: This function is slightly different from decode_coloured_label in data_pipeline\n",
    "# as it iterates through pixels, which is slower in graph mode.\n",
    "# If decode_coloured_label from data_pipeline is used, this might be redundant.\n",
    "def decode_label_image(label_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Decodes an RGB label image (NumPy array) into a 2D integer class map.\n",
    "    This function is primarily for NumPy arrays (e.g., for direct image processing).\n",
    "    For TensorFlow graph operations, `decode_coloured_label` from the data pipeline is preferred.\n",
    "\n",
    "    Args:\n",
    "        label_img (np.ndarray): A 3-channel RGB label image (H, W, 3) as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array (H, W) where each element is an integer class ID.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an unknown label color is encountered.\n",
    "    \"\"\"\n",
    "    # Using COLOR_LOOKUP which maps tuple(RGB) to class ID\n",
    "    COLOR_LOOKUP = {tuple(c): i for c, i in COLOR_TO_CLASS.items()}\n",
    "\n",
    "    h, w, _ = label_img.shape\n",
    "    label_map = np.zeros((h, w), dtype=np.uint8)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            pixel = tuple(label_img[y, x])\n",
    "            if pixel not in COLOR_LOOKUP:\n",
    "                raise ValueError(f\"Unknown label colour {pixel} at ({y}, {x})\")\n",
    "            label_map[y, x] = COLOR_LOOKUP[pixel]\n",
    "    return label_map\n",
    "\n",
    "\n",
    "# --- Utility Functions for File Filtering ---\n",
    "\n",
    "def filter_tile_ids_by_substring(image_dir: str, base_names: list) -> list:\n",
    "    \"\"\"\n",
    "    Filters a list of tile IDs in a directory based on whether their base name\n",
    "    (without the '-ortho.png' suffix) contains any of the specified base names.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): The directory containing image files.\n",
    "        base_names (list): A list of base names (e.g., source file prefixes) to filter by.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of filtered tile IDs (without the suffix).\n",
    "    \"\"\"\n",
    "    return [f.replace('-ortho.png', '') for f in os.listdir(image_dir) if any(base in f for base in base_names)]\n",
    "\n",
    "\n",
    "# --- Visualization of Prediction Grids ---\n",
    "\n",
    "def plot_colored_mask(mask_2d: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a 2D integer class mask into a 3-channel RGB image using CLASS_TO_COLOR mapping.\n",
    "\n",
    "    Args:\n",
    "        mask_2d (np.ndarray): A 2D numpy array where each element is an integer class ID (H, W).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 3-channel numpy array (H, W, 3) representing the colored mask.\n",
    "    \"\"\"\n",
    "    colored_mask = np.zeros((mask_2d.shape[0], mask_2d.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, color_rgb in CLASS_TO_COLOR.items():\n",
    "        colored_mask[mask_2d == class_id] = color_rgb\n",
    "    return colored_mask\n",
    "\n",
    "\n",
    "def visualise_prediction_grid(\n",
    "    rgb_list: list,\n",
    "    true_mask_list: list,\n",
    "    pred_mask_list: list,\n",
    "    tile_id_list: list = None,\n",
    "    all_tile_ids: list = None,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes a grid of input RGB images, their ground truth masks, and model predictions.\n",
    "    Optionally prioritizes specific tile IDs for display.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (list): List of input RGB images (NumPy arrays).\n",
    "        true_mask_list (list): List of ground truth masks (one-hot encoded NumPy arrays).\n",
    "        pred_mask_list (list): List of predicted masks (integer class ID NumPy arrays).\n",
    "        tile_id_list (list, optional): A list of specific tile IDs to prioritize for plotting.\n",
    "                                       If None, random chips are selected.\n",
    "        all_tile_ids (list, optional): A list of all tile IDs corresponding to `rgb_list`, etc.\n",
    "                                       Required if `tile_id_list` is provided.\n",
    "        n_rows (int): Number of rows in the visualization grid.\n",
    "        n_cols (int): Number of columns in the visualization grid.\n",
    "    \"\"\"\n",
    "    total_plots = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    indices_to_plot = []\n",
    "\n",
    "    if tile_id_list and all_tile_ids:\n",
    "        # Prioritize specific tile IDs if requested\n",
    "        tile_id_set = set(tile_id_list)\n",
    "        matched_indices = [i for i, tid in enumerate(all_tile_ids) if tid in tile_id_set]\n",
    "        random.shuffle(matched_indices)\n",
    "        indices_to_plot = matched_indices[:total_plots] # Take up to total_plots\n",
    "\n",
    "        # Fill remaining slots with random other chips if not enough specific ones\n",
    "        if len(indices_to_plot) < total_plots:\n",
    "            # Get indices of chips NOT in specific_tile_ids\n",
    "            other_indices = list(set(range(len(rgb_list))) - set(indices_to_plot))\n",
    "            random.shuffle(other_indices)\n",
    "            indices_to_plot.extend(other_indices[:total_plots - len(indices_to_plot)])\n",
    "    else:\n",
    "        # If no specific IDs, just take random 'total_plots' number of indices\n",
    "        indices_to_plot = list(range(min(total_plots, len(rgb_list))))\n",
    "        random.shuffle(indices_to_plot) # Shuffle to get random samples\n",
    "\n",
    "    # Ensure we plot exactly `total_plots` or as many as available\n",
    "    indices_to_plot = indices_to_plot[:total_plots]\n",
    "\n",
    "    for idx_plot, data_idx in enumerate(indices_to_plot):\n",
    "        rgb = rgb_list[data_idx]\n",
    "        true_mask_onehot = true_mask_list[data_idx] # This is one-hot\n",
    "        true_mask = np.argmax(true_mask_onehot, axis=-1) # Convert to class IDs\n",
    "        pred_mask = pred_mask_list[data_idx]\n",
    "\n",
    "        h, w = true_mask.shape\n",
    "        # Initialize RGB versions of masks\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        # Color the true and predicted masks based on CLASS_TO_COLOR\n",
    "        for class_id, color in CLASS_TO_COLOR.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        # Apply ignore color (magenta) to ignored regions in ground truth and prediction\n",
    "        # The ignore mask is based on y_true being all zeros (no class assigned)\n",
    "        ignore_mask = np.all(true_mask_onehot == 0, axis=-1) # Assuming 0-vec in one-hot means ignored\n",
    "        true_rgb[ignore_mask] = IGNORE_COLOR\n",
    "        pred_rgb[ignore_mask] = IGNORE_COLOR\n",
    "\n",
    "        row = idx_plot // n_cols\n",
    "        col = (idx_plot % n_cols) * 3 # Each group (RGB, GT, Pred) takes 3 columns\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\", fontsize=10)\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\", fontsize=10)\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\", fontsize=10)\n",
    "\n",
    "        for i_ax in range(3):\n",
    "            axs[row, col + i_ax].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# --- Evaluation and Metrics ---\n",
    "\n",
    "def measure_inference_time(model: tf.keras.Model, generator: tf.data.Dataset, num_batches: int = 5):\n",
    "    \"\"\"\n",
    "    Measures the inference time of a Keras model on a given TensorFlow dataset generator.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        generator (tf.data.Dataset): The TensorFlow dataset generator for inference.\n",
    "        num_batches (int): Number of batches to run inference on for measurement.\n",
    "                           If None, tries to get cardinality of the generator.\n",
    "    \"\"\"\n",
    "    import time # Import time locally as it's only used here.\n",
    "\n",
    "    total_time = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        try:\n",
    "            # tf.data.experimental.cardinality returns UNKNOWN for some datasets, so handle it\n",
    "            cardinality = tf.data.experimental.cardinality(generator).numpy()\n",
    "            if cardinality == tf.data.experimental.INFINITE_CARDINALITY:\n",
    "                print(\"Warning: Generator has infinite cardinality. Measuring on first 5 batches.\")\n",
    "                num_batches = 5\n",
    "            else:\n",
    "                num_batches = cardinality\n",
    "        except Exception:\n",
    "            print(\"Warning: Could not determine generator cardinality. Measuring on first 5 batches.\")\n",
    "            num_batches = 5 # Default to 5 batches if cardinality is unknown\n",
    "\n",
    "    print(f\"\\n⏱️ Measuring inference time over {num_batches} batches...\")\n",
    "    for i, (x_batch, _) in enumerate(generator.take(num_batches)):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0) # verbose=0 suppresses progress bar\n",
    "        end = time.time()\n",
    "        total_time += (end - start)\n",
    "        total_images += x_batch.shape[0]\n",
    "\n",
    "    if total_images > 0:\n",
    "        print(f\"🧠 Inference time: {total_time:.2f} sec for {total_images} images\")\n",
    "        print(f\"⏱️ Avg inference time per image: {total_time / total_images:.4f} sec\")\n",
    "    else:\n",
    "        print(\"No images processed for inference time measurement.\")\n",
    "\n",
    "\n",
    "def plot_training_curves(history: tf.keras.callbacks.History, out_dir: str):\n",
    "    \"\"\"\n",
    "    Plots and saves the training and validation loss, and IoU scores over epochs.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): The History object returned by model.fit().\n",
    "        out_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    history_dict = history.history\n",
    "    # Define required keys, ensuring they match actual metric names in history\n",
    "    required_keys = [\"loss\", \"val_loss\", \"iou_score\", \"val_iou_score\"]\n",
    "\n",
    "    missing_keys = [k for k in required_keys if k not in history_dict]\n",
    "    if missing_keys:\n",
    "        print(f\"⚠️ Missing keys in history: {missing_keys}. Cannot plot all curves.\")\n",
    "        # Attempt to plot what's available\n",
    "        pass \n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss if available\n",
    "    if \"loss\" in history_dict and \"val_loss\" in history_dict:\n",
    "        axs[0].plot(history_dict[\"loss\"], label=\"Train Loss\")\n",
    "        axs[0].plot(history_dict[\"val_loss\"], label=\"Val Loss\")\n",
    "        axs[0].set_title(\"Loss over Epochs\")\n",
    "        axs[0].set_xlabel(\"Epoch\")\n",
    "        axs[0].set_ylabel(\"Loss\")\n",
    "        axs[0].legend()\n",
    "    else:\n",
    "        axs[0].set_title(\"Loss Data Not Available\")\n",
    "        axs[0].axis('off')\n",
    "\n",
    "    # Plot IoU if available\n",
    "    if \"iou_score\" in history_dict and \"val_iou_score\" in history_dict:\n",
    "        axs[1].plot(history_dict[\"iou_score\"], label=\"Train IoU\")\n",
    "        axs[1].plot(history_dict[\"val_iou_score\"], label=\"Val IoU\")\n",
    "        axs[1].set_title(\"Mean IoU over Epochs\")\n",
    "        axs[1].set_xlabel(\"Epoch\")\n",
    "        axs[1].set_ylabel(\"Mean IoU\")\n",
    "        axs[1].legend()\n",
    "    else:\n",
    "        axs[1].set_title(\"IoU Data Not Available\")\n",
    "        axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(out_dir, \"training_curves.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close(fig) # Use close(fig) to explicitly close the figure\n",
    "    print(f\"Saved training curves to: {save_path}\")\n",
    "\n",
    "\n",
    "def evaluate_on_test(\n",
    "    model: tf.keras.Model,\n",
    "    test_gen: tf.data.Dataset,\n",
    "    test_df: pd.DataFrame,\n",
    "    out_dir: str,\n",
    "    image_dir: str, # Required for reconstruction if 'yummy' is true and not handled by generator\n",
    "    label_dir: str, # Required for reconstruction if 'yummy' is true and not handled by generator\n",
    "    tile_size: int = 256,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3,\n",
    "    specific_tile_ids: list = None # List of tile IDs to prioritize for visualization\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the test set, calculates various metrics (mIoU, F1, Precision, Recall),\n",
    "    generates a confusion matrix plot, and visualizes sample predictions.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        test_gen (tf.data.Dataset): TensorFlow Dataset for the test set.\n",
    "        test_df (pd.DataFrame): DataFrame containing metadata for the test set.\n",
    "        out_dir (str): Directory to save plots.\n",
    "        image_dir (str): Path to the directory containing RGB images (for visualization/reconstruction).\n",
    "        label_dir (str): Path to the directory containing label images (for visualization/reconstruction).\n",
    "        tile_size (int): The size of the tiles (e.g., 256x256).\n",
    "        n_rows (int): Number of rows for the prediction visualization grid.\n",
    "        n_cols (int): Number of columns for the prediction visualization grid.\n",
    "        specific_tile_ids (list, optional): List of specific tile IDs to prioritize for plotting.\n",
    "                                            Defaults to None (random selection).\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(\"🧪 Running evaluation on test set...\")\n",
    "\n",
    "    all_test_preds = []\n",
    "    all_test_trues = []\n",
    "\n",
    "    visual_rgb = [] # To store RGB images for plotting\n",
    "    visual_true = [] # To store ground truth masks for plotting\n",
    "    visual_pred = [] # To store predicted masks for plotting\n",
    "    visual_tile_ids = [] # To store tile_ids for plotting, useful for specific_tile_ids matching\n",
    "    \n",
    "    # Calculate desired limit for visualization based on grid size\n",
    "    visual_limit = n_rows * n_cols\n",
    "\n",
    "    # Get all tile IDs from the test DataFrame for potential matching\n",
    "    test_df_tile_ids = test_df['tile_id'].tolist()\n",
    "    \n",
    "    tile_index_in_df = 0 # To track which chip from test_df is being processed\n",
    "\n",
    "    # Iterate through the test generator\n",
    "    for batch_x, batch_y in tqdm(test_gen, desc=\"Evaluating\"):\n",
    "        # Skip empty batches if any\n",
    "        if tf.size(batch_x).numpy() == 0:\n",
    "            continue\n",
    "\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        pred_probs = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_batch = np.argmax(pred_probs, axis=-1).astype(np.uint8)\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_batch = np.argmax(batch_y, axis=-1).numpy().astype(np.uint8)\n",
    "\n",
    "        # Process each image in the current batch\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            # Stop if we have processed all tiles in test_df (safety break)\n",
    "            if tile_index_in_df >= len(test_df_tile_ids):\n",
    "                break\n",
    "            \n",
    "            current_tile_id = test_df_tile_ids[tile_index_in_df]\n",
    "            \n",
    "            # Collect data for visualization up to the visual_limit\n",
    "            if len(visual_rgb) < visual_limit:\n",
    "                # RGB image (scale from [0,1] to [0,255] and cast to uint8)\n",
    "                # Assumes RGB is always the first 3 channels if it's a multi-channel input\n",
    "                rgb_tile = (batch_x[j][:, :, :3].numpy() * 255).astype(np.uint8)\n",
    "                visual_rgb.append(rgb_tile)\n",
    "                visual_true.append(batch_y[j].numpy()) # Keep true mask as one-hot for plotting\n",
    "                visual_pred.append(pred_mask_batch[j]) # Predicted mask (class IDs)\n",
    "                visual_tile_ids.append(current_tile_id)\n",
    "\n",
    "            # Collect all true and predicted pixels for overall metric calculation\n",
    "            all_test_preds.extend(pred_mask_batch[j].reshape(-1))\n",
    "            all_test_trues.extend(true_mask_batch[j].reshape(-1)) # Flatten for metric calculation\n",
    "\n",
    "            tile_index_in_df += 1 # Move to the next tile in the test_df\n",
    "\n",
    "        # Explicitly delete batch variables and collect garbage to free memory\n",
    "        del batch_x, batch_y, pred_probs, pred_mask_batch, true_mask_batch\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds:\n",
    "        print(\"⚠️ No test predictions were collected. Evaluation skipped.\")\n",
    "        return\n",
    "\n",
    "    # Convert lists to NumPy arrays for metric calculations\n",
    "    all_test_preds = np.array(all_test_preds)\n",
    "    all_test_trues = np.array(all_test_trues)\n",
    "\n",
    "    # --- Visualise Grid ---\n",
    "    if visual_rgb: # Only plot if there's data to visualize\n",
    "        print(f\"\\nVisualizing {len(visual_rgb)} sample predictions...\")\n",
    "        visualise_prediction_grid(\n",
    "            rgb_list=visual_rgb,\n",
    "            true_mask_list=visual_true, # Pass one-hot true masks\n",
    "            pred_mask_list=visual_pred,\n",
    "            tile_id_list=specific_tile_ids, # Pass specific tile IDs to prioritize\n",
    "            all_tile_ids=visual_tile_ids, # Pass the tile IDs collected during evaluation\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols\n",
    "        )\n",
    "    else:\n",
    "        print(\"No samples collected for visualization grid.\")\n",
    "\n",
    "    # --- Overall Mean IoU ---\n",
    "    # Using tf.keras.metrics.MeanIoU directly as it's robust and standard\n",
    "    mean_iou_metric_tf = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "    mean_iou_metric_tf.update_state(all_test_trues, all_test_preds)\n",
    "    miou = mean_iou_metric_tf.result().numpy()\n",
    "    print(f\"\\n📈 Overall Mean IoU (mIoU): {miou:.4f}\")\n",
    "\n",
    "    # --- Macro F1, Precision, Recall ---\n",
    "    # Using sklearn for macro averages\n",
    "    macro_f1 = f1_score(all_test_trues, all_test_preds, average='macro', zero_division=0)\n",
    "    macro_precision = precision_score(all_test_trues, all_test_preds, average='macro', zero_division=0)\n",
    "    macro_recall = recall_score(all_test_trues, all_test_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\n📊 Macro Metrics:\")\n",
    "    print(f\"    F1 Score    : {macro_f1:.4f}\")\n",
    "    print(f\"    Precision   : {macro_precision:.4f}\")\n",
    "    print(f\"    Recall      : {macro_recall:.4f}\")\n",
    "\n",
    "    # --- Per-class IoU ---\n",
    "    # Using sklearn's confusion matrix to calculate per-class IoU\n",
    "    conf_matrix = confusion_matrix(all_test_trues, all_test_preds, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"\\n📏 Per-class IoU Scores:\")\n",
    "    class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else float('nan') # Use NaN for undefined IoU\n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {CLASS_NAMES[i]:<12} IoU: {iou:.4f}\")\n",
    "\n",
    "    # --- Per-class F1, Precision, Recall ---\n",
    "    # Using sklearn's precision_recall_fscore_support for per-class metrics\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
    "        all_test_trues, all_test_preds, labels=list(range(NUM_CLASSES)), zero_division=0\n",
    "    )\n",
    "    print(\"\\n🔍 Per-class Classification Report (F1 | Precision | Recall):\")\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        print(f\"{name:<12} | F1: {f1_per_class[i]:.4f} | Prec: {precision_per_class[i]:.4f} | Recall: {recall_per_class[i]:.4f}\")\n",
    "\n",
    "    # --- Confusion Matrix Plot (Row-Normalised) ---\n",
    "    print(\"\\n🌀 Generating Row-Normalised Confusion Matrix plot...\")\n",
    "    with np.errstate(divide='ignore', invalid='ignore'): # Suppress division by zero warnings\n",
    "        row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "        # Normalize by true labels sum (row-wise)\n",
    "        norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    ax.set_title(\"Row-Normalised Confusion Matrix (True Label %) - Test Set\")\n",
    "    fig.tight_layout()\n",
    "    cm_save_path = os.path.join(out_dir, 'confusion_matrix_row_norm.png')\n",
    "    fig.savefig(cm_save_path)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    # --- Per-chip mIoU histogram ---\n",
    "    # To enable this, ensure 'chip_ious' is collected in evaluate_on_test.\n",
    "    # Currently, 'chip_ious' is collected in evaluate_model_with_crf.\n",
    "    # If you want it here, you'd need to re-add the per-chip IoU calculation loop.\n",
    "    # For now, I'll add a placeholder if you decide to add it.\n",
    "    \n",
    "    # Example if you collect chip_ious:\n",
    "    # if chip_ious: # assuming chip_ious is populated\n",
    "    #     print(\"\\n📊 Generating per-chip mIoU histogram...\")\n",
    "    #     bin_edges = np.linspace(0, 1, 21) # 5% bins\n",
    "    #     plt.figure(figsize=(10, 6))\n",
    "    #     plt.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "    #     plt.xlabel(\"Per-Chip mIoU\")\n",
    "    #     plt.ylabel(\"Number of Chips\")\n",
    "    #     plt.title(\"Distribution of Per-Chip mIoU\")\n",
    "    #     plt.grid(True)\n",
    "    #     plt.tight_layout()\n",
    "    #     hist_save_path = os.path.join(out_dir, \"per_chip_miou_hist.png\")\n",
    "    #     plt.savefig(hist_save_path)\n",
    "    #     plt.show()\n",
    "    #     plt.close()\n",
    "    #     print(f\"Saved per-chip mIoU histogram to: {hist_save_path}\")\n",
    "\n",
    "\n",
    "# --- Reconstruction Functions ---\n",
    "\n",
    "def reconstruct_canvas(\n",
    "    model: tf.keras.Model,\n",
    "    df: pd.DataFrame,\n",
    "    source_file_prefix: str, # Changed from source_file to source_file_prefix for clarity\n",
    "    generator_class: callable, # e.g., build_tf_dataset\n",
    "    img_dir: str,\n",
    "    elev_dir: str,\n",
    "    slope_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file by stitching together its individual chips.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        df (pd.DataFrame): The DataFrame containing metadata for all chips (e.g., test_df).\n",
    "        source_file_prefix (str): The common prefix for all chips belonging to the same large image.\n",
    "                                  (e.g., \"25f1c24f30_EB81FE6E2BOPENPIPELINE\")\n",
    "        generator_class (callable): The function to build the TensorFlow dataset (e.g., `build_tf_dataset`).\n",
    "        img_dir (str): Directory containing RGB images.\n",
    "        elev_dir (str): Directory containing elevation .npy files.\n",
    "        slope_dir (str): Directory containing slope .npy files.\n",
    "        label_dir (str): Directory containing label images.\n",
    "        tile_size (int): The size of individual tiles/chips (e.g., 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the\n",
    "        reconstructed RGB canvas, Ground Truth canvas, and Prediction canvas (all as np.uint8).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no chips are found for the specified source file prefix.\n",
    "    \"\"\"\n",
    "    # Filter for chips belonging to the specific source file\n",
    "    df_file = df[df['tile_id'].str.startswith(source_file_prefix)].copy() # Use str.startswith\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file prefix: {source_file_prefix}\")\n",
    "\n",
    "    # Determine the overall canvas shape\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + tile_size\n",
    "    max_y = df_file['y'].max() + tile_size\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape_rgb = (canvas_h, canvas_w, 3)\n",
    "    canvas_shape_mask = (canvas_h, canvas_w, 3) # For GT/Pred, will be colored RGB\n",
    "\n",
    "    # Initialize canvases with IGNORE_COLOR (magenta) for padding/uncovered areas\n",
    "    rgb_canvas = np.full(canvas_shape_rgb, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Build dataset for just this file's chips, ensuring correct order for stitching\n",
    "    # Use shuffle=False and augment=False for reconstruction\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"val\" # Use 'val' or 'test' split to ensure no augments\n",
    "    )\n",
    "\n",
    "    # Iterate through the generated batches, predict, and fill the canvases\n",
    "    row_index_in_df = 0 # Tracks position in the filtered df_file\n",
    "    for batch_x, batch_y_onehot in gen:\n",
    "        preds_softmax = model.predict(batch_x, verbose=0)\n",
    "        pred_mask_ids = tf.argmax(preds_softmax, axis=-1).numpy() # Predicted class IDs\n",
    "        true_mask_ids = tf.argmax(batch_y_onehot, axis=-1).numpy() # Ground truth class IDs\n",
    "\n",
    "        batch_size_actual = batch_x.shape[0]\n",
    "        for i in range(batch_size_actual):\n",
    "            if row_index_in_df >= len(df_file): # Safety break\n",
    "                break\n",
    "\n",
    "            # Get chip's original (x, y) coordinates from the DataFrame\n",
    "            row_df_entry = df_file.iloc[row_index_in_df]\n",
    "            rel_x = row_df_entry.x - min_x\n",
    "            rel_y = row_df_entry.y - min_y\n",
    "            row_index_in_df += 1\n",
    "\n",
    "            # Extract current chip data\n",
    "            rgb_chip = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            true_mask_chip = true_mask_ids[i]\n",
    "            pred_mask_chip = pred_mask_ids[i]\n",
    "\n",
    "            # Place RGB chip onto the canvas\n",
    "            rgb_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = rgb_chip\n",
    "\n",
    "            # Color and place Ground Truth mask onto the canvas\n",
    "            gt_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb_chip[true_mask_chip == cid] = colour\n",
    "            gt_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = gt_rgb_chip\n",
    "\n",
    "            # Color and place Prediction mask onto the canvas\n",
    "            pred_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb_chip[pred_mask_chip == cid] = colour\n",
    "            pred_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = pred_rgb_chip\n",
    "    \n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "def plot_reconstruction(img: np.ndarray, label: np.ndarray, pred: np.ndarray, source_file_prefix: str):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The reconstructed RGB image canvas.\n",
    "        label (np.ndarray): The reconstructed ground truth mask canvas (colored).\n",
    "        pred (np.ndarray): The reconstructed prediction mask canvas (colored).\n",
    "        source_file_prefix (str): The common prefix of the source file for the title.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file_prefix}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def normalize_confusion_matrix(cm: np.ndarray, norm: str = 'true') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        cm (np.ndarray): Confusion matrix to be normalized.\n",
    "        norm (str): Type of normalization.\n",
    "                    - 'true': Normalize by true labels (rows sum to 1).\n",
    "                    - 'pred': Normalize by predicted labels (columns sum to 1).\n",
    "                    - 'all': Normalize by total count (matrix sums to 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalized confusion matrix.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an unknown normalization type is provided.\n",
    "    \"\"\"\n",
    "    cm_normalized = cm.astype(np.float32)\n",
    "\n",
    "    if norm == 'true':\n",
    "        # Normalize each row by its sum\n",
    "        row_sums = cm_normalized.sum(axis=1, keepdims=True)\n",
    "        # Avoid division by zero by replacing 0 sums with NaN or 1 (depending on desired behavior for empty rows)\n",
    "        # Using np.divide with 'where' clause for safer division\n",
    "        cm_normalized = np.divide(cm_normalized, row_sums, where=row_sums != 0)\n",
    "        # Fill NaN results (where row_sum was 0) with 0\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    elif norm == 'pred':\n",
    "        # Normalize each column by its sum\n",
    "        col_sums = cm_normalized.sum(axis=0, keepdims=True)\n",
    "        cm_normalized = np.divide(cm_normalized, col_sums, where=col_sums != 0)\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    elif norm == 'all':\n",
    "        # Normalize by the grand total sum\n",
    "        total_sum = cm_normalized.sum()\n",
    "        cm_normalized = cm_normalized / total_sum if total_sum > 0 else cm_normalized\n",
    "        cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n",
    "    \n",
    "    return cm_normalized\n",
    "\n",
    "\n",
    "# --- Optional: CRF post-processing (if pydensecrf is installed) ---\n",
    "# Ensure pydensecrf is installed (pip install pydensecrf)\n",
    "# This function is used in evaluate_model_with_crf (commented out in your original code)\n",
    "\n",
    "try:\n",
    "    import pydensecrf.densecrf as dcrf\n",
    "    from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "    def apply_crf(rgb: np.ndarray, probs: np.ndarray, t: int = 5, compat: int = 10, sxy: int = 3, srgb: int = 13) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies Dense Conditional Random Field (CRF) post-processing to raw softmax predictions.\n",
    "        CRF refines segmentation boundaries by considering both pixel-wise probabilities\n",
    "        and image appearance (color and spatial proximity).\n",
    "\n",
    "        Args:\n",
    "            rgb (np.ndarray): The input RGB image (H, W, 3) as np.uint8.\n",
    "            probs (np.ndarray): Softmax output probabilities from the model (H, W, num_classes).\n",
    "            t (int): Number of CRF inference iterations.\n",
    "            compat (int): Compatibility constant for the pairwise term.\n",
    "            sxy (int): Spatial standard deviation for the pairwise bilateral term.\n",
    "            srgb (int): Color standard deviation for the pairwise bilateral term.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The refined segmentation mask (H, W) as integer class IDs.\n",
    "        \"\"\"\n",
    "        h, w = probs.shape[:2]\n",
    "        num_classes = probs.shape[-1]\n",
    "\n",
    "        d = dcrf.DenseCRF2D(w, h, num_classes)\n",
    "\n",
    "        # Reshape unary potentials from (H, W, num_classes) to (num_classes, H*W)\n",
    "        unary = unary_from_softmax(probs.transpose(2, 0, 1))\n",
    "        unary = unary.reshape((num_classes, -1)).copy(order='C') # Ensure C-contiguous memory layout\n",
    "\n",
    "        d.setUnaryEnergy(unary)\n",
    "\n",
    "        # Convert RGB to float32 and ensure C-contiguous for pydensecrf\n",
    "        rgb_float = rgb.astype(np.float32)\n",
    "        if not rgb_float.flags['C_CONTIGUOUS']:\n",
    "            rgb_float = np.ascontiguousarray(rgb_float)\n",
    "\n",
    "        # Create pairwise bilateral energy term\n",
    "        pairwise = create_pairwise_bilateral(sdims=(sxy, sxy), schan=(srgb, srgb, srgb), img=rgb_float, chdim=2)\n",
    "        d.addPairwiseEnergy(pairwise, compat=compat)\n",
    "\n",
    "        # Perform inference\n",
    "        Q = d.inference(t)\n",
    "        # Return the most likely class ID for each pixel\n",
    "        return np.argmax(Q, axis=0).reshape((h, w))\n",
    "\n",
    "    def evaluate_model_with_crf(model, test_gen, test_df, out_dir, image_dir, label_dir, tile_size=256, n_rows=4, n_cols=3):\n",
    "        \"\"\"\n",
    "        Evaluates the trained model on the test set with CRF post-processing,\n",
    "        calculates metrics, and visualizes samples.\n",
    "        Note: This function is similar to `evaluate_on_test` but explicitly includes CRF.\n",
    "        It collects per-chip IoUs which is useful for histogram plotting.\n",
    "        \"\"\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        print(\"🧪 Running evaluation on test set with CRF post-processing...\")\n",
    "        all_preds = []\n",
    "        all_trues = []\n",
    "\n",
    "        rgb_list_viz = [] # RGB images for visualization\n",
    "        true_mask_list_viz = [] # True masks for visualization (one-hot)\n",
    "        pred_mask_list_viz = [] # Predicted masks for visualization (class IDs after CRF)\n",
    "        present_classes_per_chip = [] # For analyse_prediction_grid_by_performance if re-enabled\n",
    "        chip_ious = [] # Per-chip mIoUs\n",
    "\n",
    "        visual_limit = n_rows * n_cols # Max number of samples to collect for visualization\n",
    "        \n",
    "        test_df_tile_ids = test_df['tile_id'].tolist()\n",
    "        tile_index_in_df = 0 # To track which chip from test_df is being processed\n",
    "\n",
    "        for x_batch, y_batch in tqdm(test_gen, desc=\"CRF Evaluating\"):\n",
    "            if tf.size(x_batch).numpy() == 0:\n",
    "                continue\n",
    "\n",
    "            # Get model's raw softmax predictions\n",
    "            soft_preds = model.predict(x_batch, verbose=0)\n",
    "            true_mask_batch_onehot = y_batch.numpy() # Keep as one-hot for direct comparison if needed\n",
    "\n",
    "            for i in range(x_batch.shape[0]):\n",
    "                if tile_index_in_df >= len(test_df_tile_ids): # Safety break\n",
    "                    break\n",
    "\n",
    "                # Extract RGB image for CRF (needs to be 0-255 uint8)\n",
    "                rgb_img = (x_batch[i][..., :3].numpy() * 255).astype(np.uint8)\n",
    "                softmax_pred_for_crf = soft_preds[i] # Softmax probabilities for current chip\n",
    "\n",
    "                # Apply CRF post-processing\n",
    "                crf_mask = apply_crf(rgb_img, softmax_pred_for_crf) # Returns class IDs\n",
    "\n",
    "                # Get true mask as class IDs for metric calculation\n",
    "                true_mask_ids = np.argmax(true_mask_batch_onehot[i], axis=-1).astype(np.uint8)\n",
    "\n",
    "                # Collect flattened predictions and true labels for overall metrics\n",
    "                all_preds.extend(crf_mask.reshape(-1))\n",
    "                all_trues.extend(true_mask_ids.reshape(-1))\n",
    "\n",
    "                # --- Per-chip IoU calculation (if needed for histogram/sorting) ---\n",
    "                # This needs to be done here as it uses the CRF-processed mask\n",
    "                cm_chip = confusion_matrix(true_mask_ids.flatten(), crf_mask.flatten(), labels=list(range(NUM_CLASSES)))\n",
    "                ious_chip = []\n",
    "                for j in range(NUM_CLASSES):\n",
    "                    intersection_chip = cm_chip[j, j]\n",
    "                    union_chip = np.sum(cm_chip[j, :]) + np.sum(cm_chip[:, j]) - intersection_chip\n",
    "                    if union_chip > 0:\n",
    "                        iou_chip = intersection_chip / union_chip\n",
    "                        ious_chip.append(iou_chip)\n",
    "                chip_ious.append(np.mean(ious_chip) if ious_chip else 0)\n",
    "\n",
    "\n",
    "                # Collect visuals up to the limit\n",
    "                if len(rgb_list_viz) < visual_limit:\n",
    "                    rgb_list_viz.append(rgb_img)\n",
    "                    true_mask_list_viz.append(true_mask_batch_onehot[i]) # Keep one-hot for plotting\n",
    "                    pred_mask_list_viz.append(crf_mask) # CRF output (class IDs)\n",
    "                    # You might also want to append the tile_id here if sorting by performance is used\n",
    "\n",
    "                tile_index_in_df += 1 # Move to the next tile in the test_df\n",
    "\n",
    "            gc.collect() # Garbage collection after each batch\n",
    "\n",
    "        # Convert collected lists to NumPy arrays for final metric calculations\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_trues = np.array(all_trues)\n",
    "\n",
    "        # --- Visualise Grid (using CRF outputs) ---\n",
    "        if rgb_list_viz:\n",
    "            print(f\"\\n🖼️ Visualizing {len(rgb_list_viz)} sample predictions with CRF...\")\n",
    "            visualise_prediction_grid(\n",
    "                rgb_list=rgb_list_viz,\n",
    "                true_mask_list=true_mask_list_viz, # These are one-hot, visualise_prediction_grid will convert\n",
    "                pred_mask_list=pred_mask_list_viz,\n",
    "                n_rows=n_rows,\n",
    "                n_cols=n_cols,\n",
    "                # If you want to use the performance-based grid, uncomment the old function call\n",
    "                # and pass the appropriate lists (miou_list, class_list) to it.\n",
    "            )\n",
    "        else:\n",
    "            print(\"No samples collected for CRF visualization grid.\")\n",
    "\n",
    "        # --- Metrics Calculation (using CRF output) ---\n",
    "        # Note: These are identical to evaluate_on_test's metric calculations,\n",
    "        # but they operate on the CRF-processed predictions.\n",
    "        \n",
    "        miou = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "        miou.update_state(all_trues, all_preds)\n",
    "        overall_miou = miou.result().numpy()\n",
    "\n",
    "        macro_f1 = f1_score(all_trues, all_preds, average='macro', zero_division=0)\n",
    "        macro_precision = precision_score(all_trues, all_preds, average='macro', zero_division=0)\n",
    "        macro_recall = recall_score(all_trues, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        conf_matrix_crf = confusion_matrix(all_trues, all_preds, labels=list(range(NUM_CLASSES)))\n",
    "        per_class_ious_crf = []\n",
    "        for i in range(NUM_CLASSES):\n",
    "            intersection_crf = conf_matrix_crf[i, i]\n",
    "            union_crf = np.sum(conf_matrix_crf[i, :]) + np.sum(conf_matrix_crf[:, i]) - intersection_crf\n",
    "            iou_crf = intersection_crf / union_crf if union_crf > 0 else float('nan')\n",
    "            per_class_ious_crf.append(iou_crf)\n",
    "        \n",
    "        # Per-class F1, Precision, Recall\n",
    "        precision_crf, recall_crf, f1_crf, _ = precision_recall_fscore_support(\n",
    "            all_trues, all_preds, labels=list(range(NUM_CLASSES)), zero_division=0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n📊 CRF Macro Metrics:\")\n",
    "        print(f\"  F1 Score     : {macro_f1:.4f}\")\n",
    "        print(f\"  Precision    : {macro_precision:.4f}\")\n",
    "        print(f\"  Recall       : {macro_recall:.4f}\")\n",
    "        print(f\"\\n📈 CRF Mean IoU (mIoU): {overall_miou:.4f}\")\n",
    "        print(\"\\n📏 CRF Per-class IoU Scores:\")\n",
    "        for i in range(NUM_CLASSES):\n",
    "            print(f\"  {CLASS_NAMES[i]:<12} IoU: {per_class_ious_crf[i]:.4f}\")\n",
    "        print(\"\\n🔍 CRF Per-class Classification Report (F1 | Precision | Recall):\")\n",
    "        for i, name in enumerate(CLASS_NAMES):\n",
    "            print(f\"{name:<12} | F1: {f1_crf[i]:.4f} | Prec: {precision_crf[i]:.4f} | Recall: {recall_crf[i]:.4f}\")\n",
    "\n",
    "        # Confusion Matrix Plot (Row-Normalised) for CRF\n",
    "        print(\"\\n🌀 Generating CRF Row-Normalised Confusion Matrix plot...\")\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            row_sums_crf = conf_matrix_crf.sum(axis=1, keepdims=True)\n",
    "            norm_conf_crf = np.divide(conf_matrix_crf.astype(np.float32), row_sums_crf, where=row_sums_crf != 0)\n",
    "\n",
    "        fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "        disp_crf = ConfusionMatrixDisplay(norm_conf_crf, display_labels=CLASS_NAMES)\n",
    "        disp_crf.plot(cmap='viridis', ax=ax_cm, values_format=\".2f\")\n",
    "        ax_cm.set_title(\"CRF Row-Normalised Confusion Matrix (True Label %) - Test Set\")\n",
    "        fig_cm.tight_layout()\n",
    "        cm_crf_save_path = os.path.join(out_dir, 'confusion_matrix_crf_row_norm.png')\n",
    "        fig_cm.savefig(cm_crf_save_path)\n",
    "        plt.show()\n",
    "        plt.close(fig_cm)\n",
    "        print(f\"Saved CRF confusion matrix to: {cm_crf_save_path}\")\n",
    "\n",
    "        # Per-chip mIoU histogram for CRF results\n",
    "        if chip_ious:\n",
    "            print(\"\\n📊 Generating per-chip mIoU histogram (CRF post-processed)...\")\n",
    "            bin_edges = np.linspace(0, 1, 21) # 5% bins\n",
    "            fig_hist, ax_hist = plt.subplots(figsize=(10, 6))\n",
    "            ax_hist.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "            ax_hist.set_xlabel(\"Per-Chip mIoU\")\n",
    "            ax_hist.set_ylabel(\"Number of Chips\")\n",
    "            ax_hist.set_title(\"Distribution of Per-Chip mIoU (CRF Post-Processed)\")\n",
    "            ax_hist.grid(True)\n",
    "            fig_hist.tight_layout()\n",
    "            hist_crf_save_path = os.path.join(out_dir, \"per_chip_miou_hist_crf.png\")\n",
    "            fig_hist.savefig(hist_crf_save_path)\n",
    "            plt.show()\n",
    "            plt.close(fig_hist)\n",
    "            print(f\"Saved CRF per-chip mIoU histogram to: {hist_crf_save_path}\")\n",
    "\n",
    "\n",
    "        # Return results if needed by a calling function\n",
    "        return {\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"precision\": macro_precision,\n",
    "            \"recall\": macro_recall,\n",
    "            \"miou\": overall_miou,\n",
    "            \"per_class_ious\": per_class_ious_crf,\n",
    "            \"classification_report_str\": classification_report(\n",
    "                all_trues, all_preds, target_names=CLASS_NAMES, digits=4, zero_division=0\n",
    "            )\n",
    "        }\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Warning: pydensecrf not installed. Skipping CRF-related functions.\")\n",
    "    # Define a dummy function if CRF is not available, to avoid NameError\n",
    "    def evaluate_model_with_crf(*args, **kwargs):\n",
    "        print(\"CRF evaluation skipped because pydensecrf is not installed.\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# --- Reconstruction Functions ---\n",
    "\n",
    "def reconstruct_canvas(\n",
    "    model: tf.keras.Model,\n",
    "    df: pd.DataFrame,\n",
    "    source_file_prefix: str,\n",
    "    generator_class: callable,\n",
    "    img_dir: str,\n",
    "    elev_dir: str,\n",
    "    slope_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file by stitching together its individual chips.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        df (pd.DataFrame): The DataFrame containing metadata for all chips (e.g., test_df).\n",
    "        source_file_prefix (str): The common prefix for all chips belonging to the same large image.\n",
    "                                  (e.g., \"25f1c24f30_EB81FE6E2BOPENPIPELINE\")\n",
    "        generator_class (callable): The function to build the TensorFlow dataset (e.g., `build_tf_dataset`).\n",
    "        img_dir (str): Directory containing RGB images.\n",
    "        elev_dir (str): Directory containing elevation .npy files.\n",
    "        slope_dir (str): Directory containing slope .npy files.\n",
    "        label_dir (str): Directory containing label images.\n",
    "        tile_size (int): The size of individual tiles/chips (e.g., 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the\n",
    "        reconstructed RGB canvas, Ground Truth canvas, and Prediction canvas (all as np.uint8).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no chips are found for the specified source file prefix.\n",
    "    \"\"\"\n",
    "    # Filter for chips belonging to the specific source file prefix\n",
    "    df_file = df[df['tile_id'].str.startswith(source_file_prefix)].copy()\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file prefix: {source_file_prefix}\")\n",
    "\n",
    "    # Determine the overall canvas shape based on min/max x,y coordinates and tile size\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + tile_size\n",
    "    max_y = df_file['y'].max() + tile_size\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape_rgb = (canvas_h, canvas_w, 3)\n",
    "    canvas_shape_mask = (canvas_h, canvas_w, 3) # For GT/Pred, will be colored RGB\n",
    "\n",
    "    # Initialize canvases with IGNORE_COLOR (magenta) for padding/uncovered areas\n",
    "    rgb_canvas = np.full(canvas_shape_rgb, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Build dataset for just this file's chips, ensuring correct order for stitching\n",
    "    # Use shuffle=False and augment=False for reconstruction, and a 'val' or 'test' split\n",
    "    # to guarantee no augmentation. Batch size can be larger for efficiency during inference.\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"val\" \n",
    "    )\n",
    "\n",
    "    # Iterate through the generated batches, predict, and fill the canvases in order\n",
    "    row_index_in_df = 0 # Tracks position in the filtered df_file to get (x,y) coords\n",
    "    for batch_x, batch_y_onehot in tqdm(gen, desc=f\"Reconstructing {source_file_prefix}\"):\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        preds_softmax = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_ids = tf.argmax(preds_softmax, axis=-1).numpy()\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_ids = tf.argmax(batch_y_onehot, axis=-1).numpy()\n",
    "\n",
    "        batch_size_actual = batch_x.shape[0]\n",
    "        for i in range(batch_size_actual):\n",
    "            if row_index_in_df >= len(df_file): # Safety break if we've processed all chips\n",
    "                break\n",
    "\n",
    "            # Get chip's original (x, y) coordinates from the DataFrame\n",
    "            row_df_entry = df_file.iloc[row_index_in_df]\n",
    "            rel_x = row_df_entry.x - min_x # Relative X coordinate for placing on canvas\n",
    "            rel_y = row_df_entry.y - min_y # Relative Y coordinate for placing on canvas\n",
    "            row_index_in_df += 1\n",
    "\n",
    "            # Extract current chip data (RGB is always first 3 channels)\n",
    "            rgb_chip = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            true_mask_chip = true_mask_ids[i]\n",
    "            pred_mask_chip = pred_mask_ids[i]\n",
    "\n",
    "            # Place RGB chip onto the canvas\n",
    "            rgb_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = rgb_chip\n",
    "\n",
    "            # Color and place Ground Truth mask onto the canvas\n",
    "            gt_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb_chip[true_mask_chip == cid] = colour\n",
    "            gt_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = gt_rgb_chip\n",
    "\n",
    "            # Color and place Prediction mask onto the canvas\n",
    "            pred_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb_chip[pred_mask_chip == cid] = colour\n",
    "            pred_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = pred_rgb_chip\n",
    "    \n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "def plot_reconstruction(img: np.ndarray, label: np.ndarray, pred: np.ndarray, source_file_prefix: str):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file prefix.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The reconstructed RGB image canvas.\n",
    "        label (np.ndarray): The reconstructed ground truth mask canvas (colored).\n",
    "        pred (np.ndarray): The reconstructed prediction mask canvas (colored).\n",
    "        source_file_prefix (str): The common prefix of the source file for the title.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\", fontsize=18)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\", fontsize=18)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\", fontsize=18)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file_prefix}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
