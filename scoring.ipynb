{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5Pup5vv_c2R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import trange\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import gc\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "out_dir=\"/content/figs\"\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < 6} # Exclude ignore color\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "NUM_CLASSES = 6\n",
    "IGNORE_COLOR = (255, 0, 255)\n",
    "\n",
    "\n",
    "def measure_inference_time(model, generator, num_batches=5):\n",
    "    import time\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = tf.data.experimental.cardinality(generator).numpy()\n",
    "\n",
    "    for i, (x_batch, _) in enumerate(generator.take(num_batches)):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "        end = time.time()\n",
    "        total_time += (end - start)\n",
    "        total_images += x_batch.shape[0]\n",
    "\n",
    "    print(f\"ðŸ§  Inference time: {total_time:.2f} sec for {total_images} images\")\n",
    "    print(f\"â±ï¸ Avg inference time per image: {total_time / total_images:.4f} sec\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_training_curves(history, out_dir):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    history_dict = history.history\n",
    "    required_keys = [\"loss\", \"val_loss\", \"iou_score\", \"val_iou_score\"]\n",
    "\n",
    "    missing_keys = [k for k in required_keys if k not in history_dict]\n",
    "    if missing_keys:\n",
    "        print(f\"âš ï¸ Missing keys in history: {missing_keys}\")\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    axs[0].plot(history_dict[\"loss\"], label=\"Train Loss\")\n",
    "    axs[0].plot(history_dict[\"val_loss\"], label=\"Val Loss\")\n",
    "    axs[0].set_title(\"Loss over Epochs\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # IoU\n",
    "    axs[1].plot(history_dict[\"iou_score\"], label=\"Train IoU\")\n",
    "    axs[1].plot(history_dict[\"val_iou_score\"], label=\"Val IoU\")\n",
    "    axs[1].set_title(\"Mean IoU over Epochs\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Mean IoU\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(out_dir, \"training_curves.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Saved training curves to: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Re-import necessary packages after kernel reset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "# Constants\n",
    "NUM_CLASSES = 6\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,\n",
    "    (145, 30, 180): 1,\n",
    "    (60, 180, 75): 2,\n",
    "    (245, 130, 48): 3,\n",
    "    (255, 255, 255): 4,\n",
    "    (0, 130, 200): 5,\n",
    "    (255, 0, 255): 6\n",
    "}\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < 6}\n",
    "\n",
    "\n",
    "def visualise_prediction_grid_by_performance(\n",
    "    rgb_list,\n",
    "    true_mask_list,\n",
    "    pred_mask_list,\n",
    "    miou_list,\n",
    "    class_list,\n",
    "    n_rows=4,\n",
    "    n_cols=3,\n",
    "    class_names=CLASS_NAMES,\n",
    "    class_to_color=CLASS_TO_COLOR\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Step 1: Sort chips by mIoU\n",
    "    chip_data = list(zip(rgb_list, true_mask_list, pred_mask_list, miou_list, class_list))\n",
    "    chip_data.sort(key=lambda x: x[3])  # Sort by mIoU\n",
    "\n",
    "    n_total = n_rows * n_cols\n",
    "    chips_per_group = n_total // 3\n",
    "\n",
    "    bottom_third = chip_data[:chips_per_group]\n",
    "    middle_third = chip_data[chips_per_group:2 * chips_per_group]\n",
    "    top_third = chip_data[2 * chips_per_group:]\n",
    "\n",
    "    # Step 2: Select 4 chips from each group with some class coverage strategy\n",
    "    def select_chips(chips, needed, reserve_class=None):\n",
    "        selected = []\n",
    "        for chip in chips:\n",
    "            if len(selected) >= needed:\n",
    "                break\n",
    "            if reserve_class is not None and reserve_class in chip[4]:\n",
    "                selected.append(chip)\n",
    "                reserve_class = None  # only once\n",
    "            elif reserve_class is None:\n",
    "                selected.append(chip)\n",
    "        return selected\n",
    "\n",
    "    selected_bottom = select_chips(bottom_third, 4, reserve_class=class_names.index(\"Water\"))\n",
    "    selected_bottom = select_chips([c for c in bottom_third if c not in selected_bottom], 4 - len(selected_bottom), reserve_class=class_names.index(\"Building\")) + selected_bottom\n",
    "\n",
    "    selected_middle = middle_third[:4]\n",
    "    selected_top = top_third[:4]\n",
    "\n",
    "    # Combine and assign column index\n",
    "    all_selected = selected_bottom + selected_middle + selected_top\n",
    "    column_assignments = [0] * 4 + [1] * 4 + [2] * 4  # 0: bottom, 1: middle, 2: top\n",
    "\n",
    "    # Step 3: Plotting\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    for idx, (rgb, true_mask_oh, pred_mask, _, _) in enumerate(all_selected):\n",
    "        true_mask = np.argmax(true_mask_oh, axis=-1)\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in class_to_color.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_oh == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx % n_rows\n",
    "        col = column_assignments[idx] * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_crf(rgb, probs, t=5, compat=10, sxy=3, srgb=13):\n",
    "    h, w = probs.shape[1:3]\n",
    "    d = dcrf.DenseCRF2D(w, h, NUM_CLASSES)\n",
    "    unary = unary_from_softmax(probs.transpose(2, 0, 1))\n",
    "    d.setUnaryEnergy(unary)\n",
    "    pairwise = create_pairwise_bilateral(sdims=(sxy, sxy), schan=(srgb, srgb, srgb), img=rgb, chdim=2)\n",
    "    d.addPairwiseEnergy(pairwise, compat=compat)\n",
    "    Q = d.inference(t)\n",
    "    return np.argmax(np.array(Q), axis=0).reshape((h, w))\n",
    "\n",
    "\n",
    "def evaluate_model_with_crf(model, test_gen, test_df, out_dir, image_dir, label_dir, tile_size=256, n_rows=4, n_cols=3):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    rgb_list = []\n",
    "    true_mask_list = []\n",
    "    pred_mask_list = []\n",
    "    present_classes_per_chip = []\n",
    "    chip_ious = []\n",
    "\n",
    "    visual_limit = n_rows * n_cols\n",
    "    test_tile_ids = test_df['tile_id'].tolist()\n",
    "    tile_index = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(test_gen, desc=\"Evaluating\"):\n",
    "        if tf.size(x_batch).numpy() == 0:\n",
    "            continue\n",
    "\n",
    "        soft_preds = model.predict(x_batch, verbose=0)\n",
    "        true_mask_batch = tf.argmax(y_batch, axis=-1).numpy().astype(np.uint8)\n",
    "\n",
    "        for i in range(x_batch.shape[0]):\n",
    "            if tile_index >= len(test_df):\n",
    "                break\n",
    "\n",
    "            rgb_img = (x_batch[i][..., :3] * 255).astype(np.uint8)\n",
    "            softmax_pred = soft_preds[i]\n",
    "            crf_mask = apply_crf(rgb_img, softmax_pred)\n",
    "\n",
    "            true_mask = true_mask_batch[i]\n",
    "            all_preds.extend(crf_mask.reshape(-1))\n",
    "            all_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "            # Per-chip IoU\n",
    "            cm = confusion_matrix(true_mask.flatten(), crf_mask.flatten(), labels=list(range(NUM_CLASSES)))\n",
    "            ious = []\n",
    "            for j in range(NUM_CLASSES):\n",
    "                intersection = cm[j, j]\n",
    "                union = np.sum(cm[j, :]) + np.sum(cm[:, j]) - intersection\n",
    "                if union > 0:\n",
    "                    iou = intersection / union\n",
    "                    ious.append(iou)\n",
    "            chip_ious.append(np.mean(ious) if ious else 0)\n",
    "\n",
    "            if len(rgb_list) < visual_limit:\n",
    "                rgb_list.append(rgb_img)\n",
    "                true_mask_onehot = y_batch[i].numpy()\n",
    "                true_mask_list.append(true_mask_onehot)\n",
    "                pred_mask_list.append(crf_mask)\n",
    "\n",
    "                present_classes = np.unique(true_mask)\n",
    "                present_classes = [int(c) for c in present_classes if c < NUM_CLASSES]\n",
    "                present_classes_per_chip.append(present_classes)\n",
    "\n",
    "            tile_index += 1\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # Visualise grid using tiered performance layout\n",
    "    visualise_prediction_grid_by_performance(\n",
    "        rgb_list=rgb_list,\n",
    "        true_mask_list=true_mask_list,\n",
    "        pred_mask_list=pred_mask_list,\n",
    "        miou_list=chip_ious[:len(rgb_list)],\n",
    "        class_list=present_classes_per_chip,\n",
    "        n_rows=n_rows,\n",
    "        n_cols=n_cols,\n",
    "    )\n",
    "\n",
    "    # --- Metrics ---\n",
    "    f1 = f1_score(all_trues, all_preds, average='macro')\n",
    "    precision = precision_score(all_trues, all_preds, average='macro')\n",
    "    recall = recall_score(all_trues, all_preds, average='macro')\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_trues, all_preds, labels=list(range(NUM_CLASSES)))\n",
    "    per_class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        per_class_ious.append(iou)\n",
    "    miou = np.mean(per_class_ious)\n",
    "\n",
    "    report = classification_report(\n",
    "        all_trues, all_preds, target_names=CLASS_NAMES, digits=4\n",
    "    )\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_crf.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- Per-chip mIoU histogram ---\n",
    "    print(\"\\nðŸ“Š Generating per-chip mIoU histogram...\")\n",
    "    bin_edges = np.linspace(0, 1, 21)  # 5% bins\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "    plt.xlabel(\"Per-Chip mIoU\")\n",
    "    plt.ylabel(\"Number of Chips\")\n",
    "    plt.title(\"Distribution of Per-Chip mIoU (CRF Post-Processed)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"per_chip_miou_hist.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"miou\": miou,\n",
    "        \"per_class_ious\": per_class_ious,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualise_prediction_grid(rgb_list, true_mask_list, pred_mask_list, n_rows, n_cols):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    total = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    for idx in range(total):\n",
    "        rgb = rgb_list[idx]\n",
    "        true_mask = np.argmax(true_mask_list[idx], axis=-1)\n",
    "        pred_mask = pred_mask_list[idx]\n",
    "\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in CLASS_TO_COLOR.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_list[idx] == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx // n_cols\n",
    "        col = (idx % n_cols) * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reconstruct_canvas(model, df, source_file, generator_class, img_dir, elev_dir, slope_dir, label_dir):\n",
    "    \"\"\"\n",
    "    Reconstruct RGB, GT and prediction canvas for a single base file.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of RGB canvas, GT canvas, Pred canvas (np.uint8)\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "\n",
    "    # 1. Filter for the specific source file\n",
    "    df_file = df[df['source_file'] == source_file].copy()\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file: {source_file}\")\n",
    "\n",
    "    # 2. Determine canvas shape\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + 256\n",
    "    max_y = df_file['y'].max() + 256\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape = (canvas_h, canvas_w, 3)\n",
    "    rgb_canvas = np.full(canvas_shape, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # 3. Build dataset for just this file\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"custom\"\n",
    "    )\n",
    "\n",
    "    # 4. Predict and fill canvas in order\n",
    "    row_index = 0\n",
    "    for batch_x, batch_y in gen:\n",
    "        preds = model.predict(batch_x, verbose=0)\n",
    "        pred_mask = tf.argmax(preds, axis=-1).numpy()\n",
    "        true_mask = tf.argmax(batch_y, axis=-1).numpy()\n",
    "\n",
    "        batch_size = batch_x.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            if row_index >= len(df_file):\n",
    "                break\n",
    "\n",
    "            row = df_file.iloc[row_index]\n",
    "            rel_x = row.x - min_x\n",
    "            rel_y = row.y - min_y\n",
    "            row_index += 1\n",
    "\n",
    "            # RGB image (scale and cast)\n",
    "            rgb = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            rgb_canvas[rel_y:rel_y+256, rel_x:rel_x+256] = rgb\n",
    "\n",
    "            # GT mask\n",
    "            gt_rgb = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb[true_mask[i] == cid] = colour\n",
    "            gt_canvas[rel_y:rel_y+256, rel_x:rel_x+256] = gt_rgb\n",
    "\n",
    "            # Prediction mask\n",
    "            pred_rgb = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb[pred_mask[i] == cid] = colour\n",
    "            pred_canvas[rel_y:rel_y+256, rel_x:rel_x+256] = pred_rgb\n",
    "\n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "\n",
    "def plot_reconstruction(img, label, pred, source_file):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))  # Adjust size as needed\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # Big title for the whole figure\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])  # Leave space for the suptitle\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_on_test(model, test_gen, test_df, out_dir, image_dir, label_dir, tile_size=256, n_rows=2, n_cols=3):\n",
    "    import os\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from PIL import Image\n",
    "\n",
    "    print(\"ðŸ§ª Running evaluation on test set...\")\n",
    "\n",
    "    all_test_preds = []\n",
    "    all_test_trues = []\n",
    "\n",
    "    visual_rgb = []\n",
    "    visual_true = []\n",
    "    visual_pred = []\n",
    "    visual_limit = n_rows * n_cols if n_rows and n_cols else 5\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    test_tile_ids = test_df['tile_id'].tolist()\n",
    "    tile_index = 0\n",
    "\n",
    "    for batch_x, batch_y in test_gen.as_numpy_iterator():\n",
    "        if batch_x.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(batch_x, verbose=0)\n",
    "        pred_mask = np.argmax(pred, axis=-1).astype(np.uint8)\n",
    "        true_mask = np.argmax(batch_y, axis=-1).astype(np.uint8)\n",
    "\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            if tile_index >= len(test_tile_ids):\n",
    "                break\n",
    "            tile_id = test_tile_ids[tile_index]\n",
    "            tile_index += 1\n",
    "\n",
    "            # Collect visuals\n",
    "            if len(visual_rgb) < visual_limit:\n",
    "                rgb_tile = (batch_x[j][:, :, :3] * 255).astype(np.uint8)\n",
    "                visual_rgb.append(rgb_tile)\n",
    "                visual_true.append(batch_y[j])\n",
    "                visual_pred.append(pred_mask[j])\n",
    "\n",
    "        all_test_preds.extend(pred_mask.reshape(-1))\n",
    "        all_test_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "        del batch_x, batch_y, pred, pred_mask, true_mask\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds:\n",
    "        print(\"âš ï¸ No test predictions were collected.\")\n",
    "        return\n",
    "\n",
    "    all_test_preds = np.array(all_test_preds)\n",
    "    all_test_trues = np.array(all_test_trues)\n",
    "\n",
    "    # Visualise Grid\n",
    "    if visual_rgb:\n",
    "        visualise_prediction_grid(visual_rgb, visual_true, visual_pred, n_rows, n_cols)\n",
    "\n",
    "    # --- Mean IoU ---\n",
    "    mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "    mean_iou_metric.update_state(all_test_trues, all_test_preds)\n",
    "    miou = mean_iou_metric.result().numpy()\n",
    "\n",
    "    # --- F1, Precision, Recall (Macro) ---\n",
    "    macro_f1 = f1_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_precision = precision_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_recall = recall_score(all_test_trues, all_test_preds, average='macro')\n",
    "\n",
    "    print(f\"\\nðŸ“Š Macro Metrics:\")\n",
    "    print(f\"  F1 Score     : {macro_f1:.4f}\")\n",
    "    print(f\"  Precision    : {macro_precision:.4f}\")\n",
    "    print(f\"  Recall       : {macro_recall:.4f}\")\n",
    "\n",
    "    # --- Confusion Matrix & Per-class IoU ---\n",
    "    conf_matrix = confusion_matrix(all_test_trues, all_test_preds, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"\\nðŸ“ Per-class IoU Scores:\")\n",
    "    class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else float('nan')\n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {CLASS_NAMES[i]:<12} IoU: {iou:.4f}\")\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ Mean IoU (mIoU): {miou:.4f}\")\n",
    "\n",
    "    # --- Classification Report ---\n",
    "    print(\"\\nðŸ” Classification Report:\")\n",
    "    print(classification_report(\n",
    "        all_test_trues,\n",
    "        all_test_preds,\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        target_names=CLASS_NAMES,\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "    # --- Confusion Matrix Plot (Row-Normalised using sklearn) ---\n",
    "    print(\"\\nðŸŒ€ Row-Normalised Confusion Matrix:\")\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "        norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    #plt.title('Row-Normalised Confusion Matrix')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_row_norm.png'))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_confusion_matrix(cm, norm='true'):\n",
    "    \"\"\"\n",
    "    Normalize a confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    cm (array-like): Confusion matrix to be normalized.\n",
    "    norm (str): Type of normalization ('true', 'pred', 'all').\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Normalized confusion matrix.\n",
    "    \"\"\"\n",
    "    if norm == 'true':\n",
    "        cm_normalized = cm.astype(np.float32) / cm.sum(axis=1)[:, np.newaxis]\n",
    "    elif norm == 'pred':\n",
    "        cm_normalized = cm.astype(np.float32) / cm.sum(axis=0)[np.newaxis, :]\n",
    "    elif norm == 'all':\n",
    "        cm_normalized = cm.astype(np.float32) / cm.sum()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n",
    "    \n",
    "    return cm_normalized\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
