{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5Pup5vv_c2R"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Used for confusion matrix plotting (implicitly by ConfusionMatrixDisplay's default style)\n",
    "import random\n",
    "import gc # For garbage collection\n",
    "from PIL import Image # For image manipulation, potentially for reconstruction or debugging\n",
    "from datetime import datetime # For timestamping or time limits\n",
    "\n",
    "# --- TensorFlow and Keras specific imports ---\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import MeanIoU # Explicit import for clarity\n",
    "\n",
    "# --- Scikit-learn metrics ---\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay, # For plotting confusion matrices\n",
    "    precision_recall_fscore_support # For per-class metrics\n",
    ")\n",
    "\n",
    "# --- Progress bar for loops ---\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Additional Imports ---\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "# Clear Keras session to avoid conflicts from previous model definitions\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "# --- Measurement Functions ---\n",
    "\n",
    "def measure_inference_time(\n",
    "    model: tf.keras.Model,\n",
    "    generator: tf.data.Dataset,\n",
    "    num_batches: int = 5\n",
    ") -> None:\n",
    "    \"\"\"Measures inference time of a Keras model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model to evaluate.\n",
    "        generator (tf.data.Dataset): The input dataset for inference.\n",
    "        num_batches (int, optional): Number of batches to use for timing. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import time\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = tf.data.experimental.cardinality(generator).numpy()\n",
    "\n",
    "    for i, (x_batch, _) in enumerate(generator.take(num_batches)):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "        end = time.time()\n",
    "        total_time += (end - start)\n",
    "        total_images += x_batch.shape[0]\n",
    "\n",
    "    print(f\"Inference time: {total_time:.2f} sec for {total_images} images\")\n",
    "    print(f\"Avg inference time per image: {total_time / total_images:.4f} sec\")\n",
    "\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_training_curves(\n",
    "    history: tf.keras.callbacks.History,\n",
    "    out_dir: str\n",
    ") -> None:\n",
    "    \"\"\"Plots and saves training/validation loss and IoU curves.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): History object returned by `model.fit()`.\n",
    "        out_dir (str): Directory path to save the generated plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    history_dict = history.history\n",
    "    required_keys = [\"loss\", \"val_loss\", \"iou_score\", \"val_iou_score\"]\n",
    "\n",
    "    missing_keys = [k for k in required_keys if k not in history_dict]\n",
    "    if missing_keys:\n",
    "        print(f\"Missing keys in history: {missing_keys}\")\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    axs[0].plot(history_dict[\"loss\"], label=\"Train Loss\")\n",
    "    axs[0].plot(history_dict[\"val_loss\"], label=\"Val Loss\")\n",
    "    axs[0].set_title(\"Loss over Epochs\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot IoU\n",
    "    axs[1].plot(history_dict[\"iou_score\"], label=\"Train IoU\")\n",
    "    axs[1].plot(history_dict[\"val_iou_score\"], label=\"Val IoU\")\n",
    "    axs[1].set_title(\"Mean IoU over Epochs\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Mean IoU\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(out_dir, \"training_curves.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved training curves to: {save_path}\")\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "def visualise_prediction_grid(\n",
    "    rgb_list: List[np.ndarray],\n",
    "    true_mask_list: List[np.ndarray],\n",
    "    pred_mask_list: List[np.ndarray],\n",
    "    tile_id_list: Optional[List[str]] = None,\n",
    "    all_tile_ids: Optional[List[str]] = None,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3\n",
    ") -> None:\n",
    "    \"\"\"Displays a grid of RGB images, ground truth masks, and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (List[np.ndarray]): List of input RGB images (uint8, 0-255).\n",
    "        true_mask_list (List[np.ndarray]): List of one-hot encoded ground truth masks.\n",
    "        pred_mask_list (List[np.ndarray]): List of predicted masks (class ID format).\n",
    "        tile_id_list (Optional[List[str]]): Tile IDs to prioritise for visualisation.\n",
    "        all_tile_ids (Optional[List[str]]): Full list of tile IDs aligned with inputs.\n",
    "        n_rows (int): Number of rows in the grid.\n",
    "        n_cols (int): Number of triplet columns (each triplet is Input, Ground Truth, Prediction).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    indices_to_plot = []\n",
    "\n",
    "    if tile_id_list and all_tile_ids:\n",
    "        tile_id_set = set(tile_id_list)\n",
    "        matched_indices = [i for i, tid in enumerate(all_tile_ids) if tid in tile_id_set]\n",
    "        random.shuffle(matched_indices)\n",
    "        indices_to_plot = matched_indices[:total]\n",
    "\n",
    "        if len(indices_to_plot) < total:\n",
    "            all_indices = list(set(range(len(rgb_list))) - set(indices_to_plot))\n",
    "            random.shuffle(all_indices)\n",
    "            indices_to_plot += all_indices[:total - len(indices_to_plot)]\n",
    "    else:\n",
    "        indices_to_plot = list(range(min(total, len(rgb_list))))\n",
    "\n",
    "    for idx_plot, data_idx in enumerate(indices_to_plot):\n",
    "        rgb = rgb_list[data_idx]\n",
    "        true_mask = np.argmax(true_mask_list[data_idx], axis=-1)\n",
    "        pred_mask = pred_mask_list[data_idx]\n",
    "\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in CLASS_TO_COLOR.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_list[data_idx] == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx_plot // n_cols\n",
    "        col = (idx_plot % n_cols) * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "def normalize_confusion_matrix(\n",
    "    cm: Union[np.ndarray, list],\n",
    "    norm: str = 'true'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Normalises a confusion matrix by rows, columns, or entire matrix.\n",
    "\n",
    "    Args:\n",
    "        cm (Union[np.ndarray, list]): Raw confusion matrix.\n",
    "        norm (str): Normalisation method. Options:\n",
    "            - 'true': Normalise by rows (ground truth labels).\n",
    "            - 'pred': Normalise by columns (predicted labels).\n",
    "            - 'all': Normalise entire matrix to sum to 1.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalised confusion matrix.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `norm` is not one of 'true', 'pred', or 'all'.\n",
    "    \"\"\"\n",
    "    cm = np.array(cm, dtype=np.float32)\n",
    "\n",
    "    if norm == 'true':\n",
    "        cm_normalized = cm / cm.sum(axis=1, keepdims=True)\n",
    "    elif norm == 'pred':\n",
    "        cm_normalized = cm / cm.sum(axis=0, keepdims=True)\n",
    "    elif norm == 'all':\n",
    "        cm_normalized = cm / cm.sum()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n",
    "\n",
    "    return cm_normalized\n",
    "\n",
    "\n",
    "# --- Main Evaluation Function ---\n",
    "from typing import Optional, List\n",
    "\n",
    "def evaluate_on_test(\n",
    "    model: tf.keras.Model,\n",
    "    test_gen: tf.data.Dataset,\n",
    "    test_df: pd.DataFrame,\n",
    "    out_dir: str,\n",
    "    image_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256,\n",
    "    n_rows: int = 4,\n",
    "    n_cols: int = 3,\n",
    "    specific_tile_ids: Optional[List[str]] = None\n",
    ") -> None:\n",
    "    \"\"\"Evaluates the model on the test set and generates metrics and visualisations.\n",
    "\n",
    "    This includes mean IoU, macro F1, Precision, Recall, a confusion matrix,\n",
    "    and a prediction visualisation grid.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained segmentation model.\n",
    "        test_gen (tf.data.Dataset): Test dataset generator.\n",
    "        test_df (pd.DataFrame): DataFrame with test metadata including tile IDs.\n",
    "        out_dir (str): Directory to save output plots.\n",
    "        image_dir (str): Directory containing RGB images (not used in this function).\n",
    "        label_dir (str): Directory containing label images (not used in this function).\n",
    "        tile_size (int): Size of each tile in pixels (e.g. 256x256).\n",
    "        n_rows (int): Number of rows in the prediction grid.\n",
    "        n_cols (int): Number of columns in the prediction grid.\n",
    "        specific_tile_ids (Optional[List[str]]): Tile IDs to prioritise for visualisation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"Running evaluation on test set...\")\n",
    "\n",
    "    all_test_preds = []\n",
    "    all_test_trues = []\n",
    "\n",
    "    visual_rgb = []\n",
    "    visual_true = []\n",
    "    visual_pred = []\n",
    "    visual_tile_ids = []\n",
    "    visual_limit = n_rows * n_cols if n_rows and n_cols else 5\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    test_tile_ids = test_df['tile_id'].tolist()\n",
    "    tile_index = 0\n",
    "\n",
    "    for batch_x, batch_y in test_gen.as_numpy_iterator():\n",
    "        if batch_x.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(batch_x, verbose=0)\n",
    "        pred_mask = np.argmax(pred, axis=-1).astype(np.uint8)\n",
    "        true_mask = np.argmax(batch_y, axis=-1).astype(np.uint8)\n",
    "\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            if tile_index >= len(test_tile_ids):\n",
    "                break\n",
    "\n",
    "            tile_id = test_tile_ids[tile_index]\n",
    "            tile_index += 1\n",
    "\n",
    "            if len(visual_rgb) < visual_limit:\n",
    "                rgb_tile = (batch_x[j][:, :, :3] * 255).astype(np.uint8)\n",
    "                visual_rgb.append(rgb_tile)\n",
    "                visual_true.append(batch_y[j])\n",
    "                visual_pred.append(pred_mask[j])\n",
    "                visual_tile_ids.append(tile_id)\n",
    "\n",
    "        all_test_preds.extend(pred_mask.reshape(-1))\n",
    "        all_test_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "        del batch_x, batch_y, pred, pred_mask, true_mask\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds:\n",
    "        print(\"No test predictions were collected.\")\n",
    "        return\n",
    "\n",
    "    all_test_preds = np.array(all_test_preds)\n",
    "    all_test_trues = np.array(all_test_trues)\n",
    "\n",
    "    if visual_rgb:\n",
    "\n",
    "        visualise_prediction_grid(\n",
    "            visual_rgb,\n",
    "            visual_true,\n",
    "            visual_pred,\n",
    "            tile_id_list=specific_tile_ids, # If provided, prioritise these tiles\n",
    "            all_tile_ids=visual_tile_ids,\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "    mean_iou_metric.update_state(all_test_trues, all_test_preds)\n",
    "    miou = mean_iou_metric.result().numpy()\n",
    "\n",
    "    macro_f1 = f1_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_precision = precision_score(all_test_trues, all_test_preds, average='macro')\n",
    "    macro_recall = recall_score(all_test_trues, all_test_preds, average='macro')\n",
    "\n",
    "    print(f\"\\nðŸ“Š Macro Metrics:\")\n",
    "    print(f\"  F1 Score     : {macro_f1:.4f}\")\n",
    "    print(f\"  Precision    : {macro_precision:.4f}\")\n",
    "    print(f\"  Recall       : {macro_recall:.4f}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_test_trues, all_test_preds, labels=list(range(NUM_CLASSES)))\n",
    "    print(\"\\nðŸ“ Per-class IoU Scores:\")\n",
    "    class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else float('nan')\n",
    "        class_ious.append(iou)\n",
    "        print(f\"  {CLASS_NAMES[i]:<12} IoU: {iou:.4f}\")\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ Mean IoU (mIoU): {miou:.4f}\")\n",
    "\n",
    "    print(\"\\nðŸ” Classification Report:\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_test_trues,\n",
    "        all_test_preds,\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    )\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        print(f\"{name:<12} | F1: {f1[i]:.4f} | Prec: {precision[i]:.4f} | Recall: {recall[i]:.4f}\")\n",
    "\n",
    "    print(\"\\nðŸŒ€ Row-Normalised Confusion Matrix:\")\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "        norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_row_norm.png'))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "# --- Reconstruction Utility ---\n",
    "\n",
    "def reconstruct_canvas(\n",
    "    model: tf.keras.Model,\n",
    "    df: pd.DataFrame,\n",
    "    source_file_prefix: str, # The common prefix for all chips of one large image\n",
    "    generator_class: callable, # The function to build the TensorFlow dataset (e.g., `build_tf_dataset`)\n",
    "    img_dir: str,\n",
    "    elev_dir: str,\n",
    "    slope_dir: str,\n",
    "    label_dir: str,\n",
    "    tile_size: int = 256\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file by stitching together its individual chips.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        df (pd.DataFrame): The DataFrame containing metadata for all chips (e.g., test_df).\n",
    "        source_file_prefix (str): The common prefix for all chips belonging to the same large image.\n",
    "                                  (e.g., \"25f1c24f30_EB81FE6E2BOPENPIPELINE\")\n",
    "        generator_class (callable): The function to build the TensorFlow dataset (e.g., `build_tf_dataset`).\n",
    "        img_dir (str): Directory containing RGB images.\n",
    "        elev_dir (str): Directory containing elevation .npy files.\n",
    "        slope_dir (str): Directory containing slope .npy files.\n",
    "        label_dir (str): Directory containing label images.\n",
    "        tile_size (int): The size of individual tiles/chips (e.g., 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the\n",
    "        reconstructed RGB canvas, Ground Truth canvas, and Prediction canvas (all as np.uint8).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no chips are found for the specified source file prefix.\n",
    "    \"\"\"\n",
    "    # Filter for chips belonging to the specific source file prefix\n",
    "    # Assuming 'tile_id' column contains the full ID like 'prefix_x_y'\n",
    "    df_file = df[df['tile_id'].str.startswith(source_file_prefix)].copy()\n",
    "    if df_file.empty:\n",
    "        raise ValueError(f\"No chips found for source file prefix: {source_file_prefix}\")\n",
    "\n",
    "    # Determine the overall canvas shape based on min/max x,y coordinates and tile size\n",
    "    min_x = df_file['x'].min()\n",
    "    min_y = df_file['y'].min()\n",
    "    max_x = df_file['x'].max() + tile_size\n",
    "    max_y = df_file['y'].max() + tile_size\n",
    "\n",
    "    canvas_w = max_x - min_x\n",
    "    canvas_h = max_y - min_y\n",
    "\n",
    "    canvas_shape_rgb = (canvas_h, canvas_w, 3)\n",
    "    canvas_shape_mask = (canvas_h, canvas_w, 3) # For GT/Pred, will be colored RGB\n",
    "\n",
    "    # Initialize canvases with IGNORE_COLOR (magenta) for padding/uncovered areas\n",
    "    rgb_canvas = np.full(canvas_shape_rgb, IGNORE_COLOR, dtype=np.uint8)\n",
    "    gt_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape_mask, IGNORE_COLOR, dtype=np.uint8)\n",
    "\n",
    "    # Build dataset for just this file's chips, ensuring correct order for stitching\n",
    "    # Use shuffle=False and augment=False for reconstruction, and a 'val' or 'test' split\n",
    "    # to guarantee no augmentation. Batch size can be larger for efficiency during inference.\n",
    "    # Assuming 'generator_class' (e.g., build_tf_dataset) can accept a 'split' argument.\n",
    "    gen = generator_class(\n",
    "        df_file, img_dir, elev_dir, slope_dir, label_dir,\n",
    "        batch_size=64, shuffle=False, augment=False, split=\"val\" # Use 'val' or 'test' to ensure no augments\n",
    "    )\n",
    "\n",
    "    # Iterate through the generated batches, predict, and fill the canvases in order\n",
    "    row_index_in_df = 0 # Tracks position in the filtered df_file to get (x,y) coords\n",
    "    for batch_x, batch_y_onehot in tqdm(gen, desc=f\"Reconstructing {source_file_prefix}\"):\n",
    "        # Get model predictions (softmax probabilities)\n",
    "        preds_softmax = model.predict(batch_x, verbose=0)\n",
    "        # Convert probabilities to class IDs (predicted masks)\n",
    "        pred_mask_ids = tf.argmax(preds_softmax, axis=-1).numpy()\n",
    "        # Convert one-hot true labels to class IDs (ground truth masks)\n",
    "        true_mask_ids = tf.argmax(batch_y_onehot, axis=-1).numpy()\n",
    "\n",
    "        batch_size_actual = batch_x.shape[0]\n",
    "        for i in range(batch_size_actual):\n",
    "            if row_index_in_df >= len(df_file): # Safety break if we've processed all chips\n",
    "                break\n",
    "\n",
    "            # Get chip's original (x, y) coordinates from the DataFrame\n",
    "            row_df_entry = df_file.iloc[row_index_in_df]\n",
    "            rel_x = row_df_entry.x - min_x # Relative X coordinate for placing on canvas\n",
    "            rel_y = row_df_entry.y - min_y # Relative Y coordinate for placing on canvas\n",
    "            row_index_in_df += 1\n",
    "\n",
    "            # Extract current chip data (RGB is always first 3 channels)\n",
    "            # Scale from [0,1] to [0,255] and cast to uint8\n",
    "            rgb_chip = tf.cast(batch_x[i][..., :3] * 255.0, tf.uint8).numpy()\n",
    "            true_mask_chip = true_mask_ids[i]\n",
    "            pred_mask_chip = pred_mask_ids[i]\n",
    "\n",
    "            # Place RGB chip onto the canvas\n",
    "            rgb_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = rgb_chip\n",
    "\n",
    "            # Color and place Ground Truth mask onto the canvas\n",
    "            gt_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                gt_rgb_chip[true_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            gt_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = gt_rgb_chip\n",
    "\n",
    "            # Color and place Prediction mask onto the canvas\n",
    "            pred_rgb_chip = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "            for cid, colour in CLASS_TO_COLOR.items():\n",
    "                pred_rgb_chip[pred_mask_chip == cid] = np.array(colour, dtype=np.uint8)\n",
    "            pred_canvas[rel_y : rel_y + tile_size, rel_x : rel_x + tile_size] = pred_rgb_chip\n",
    "    \n",
    "    return rgb_canvas, gt_canvas, pred_canvas\n",
    "\n",
    "\n",
    "def plot_reconstruction(img: np.ndarray, label: np.ndarray, pred: np.ndarray, source_file_prefix: str):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed full RGB image, ground truth mask, and model prediction mask\n",
    "    for a given source file prefix.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The reconstructed RGB image canvas (uint8).\n",
    "        label (np.ndarray): The reconstructed ground truth mask canvas (colored, uint8).\n",
    "        pred (np.ndarray): The reconstructed prediction mask canvas (colored, uint8).\n",
    "        source_file_prefix (str): The common prefix of the source file for the title.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(26.5, 13))\n",
    "\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"RGB Image\", fontsize=18)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(label)\n",
    "    axs[1].set_title(\"Ground Truth\", fontsize=18)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred)\n",
    "    axs[2].set_title(\"Model Prediction\", fontsize=18)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction for: {source_file_prefix}\", fontsize=24, y=0.95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Unused Utility Functions ---\n",
    "\n",
    "def visualise_prediction_grid_by_performance(\n",
    "    rgb_list,\n",
    "    true_mask_list,\n",
    "    pred_mask_list,\n",
    "    miou_list,\n",
    "    class_list,\n",
    "    n_rows=4,\n",
    "    n_cols=3,\n",
    "    class_names=CLASS_NAMES,\n",
    "    class_to_color=CLASS_TO_COLOR\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes a grid of predictions sorted by performance (mIoU),\n",
    "    with an attempt to include specific classes (like Water or Building)\n",
    "    from the lowest performance tier.\n",
    "\n",
    "    Args:\n",
    "        rgb_list (list): List of input RGB images (NumPy arrays).\n",
    "        true_mask_list (list): List of ground truth masks (one-hot encoded NumPy arrays).\n",
    "        pred_mask_list (list): List of predicted masks (integer class ID NumPy arrays).\n",
    "        miou_list (list): List of per-chip mIoU scores.\n",
    "        class_list (list): List where each element is a list of integer class IDs present in that chip.\n",
    "        n_rows (int): Number of rows in the visualization grid.\n",
    "        n_cols (int): Number of columns in the visualization grid.\n",
    "        class_names (list): List of class names.\n",
    "        class_to_color (dict): Mapping from class ID to RGB color tuple.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Step 1: Sort chips by mIoU\n",
    "    chip_data = list(zip(rgb_list, true_mask_list, pred_mask_list, miou_list, class_list))\n",
    "    chip_data.sort(key=lambda x: x[3])  # Sort by mIoU\n",
    "\n",
    "    n_total = n_rows * n_cols\n",
    "    chips_per_group = n_total // 3\n",
    "\n",
    "    bottom_third = chip_data[:chips_per_group]\n",
    "    middle_third = chip_data[chips_per_group:2 * chips_per_group]\n",
    "    top_third = chip_data[2 * chips_per_group:]\n",
    "\n",
    "    # Step 2: Select 4 chips from each group with some class coverage strategy\n",
    "    def select_chips(chips, needed, reserve_class=None):\n",
    "        selected = []\n",
    "        for chip in chips:\n",
    "            if len(selected) >= needed:\n",
    "                break\n",
    "            if reserve_class is not None and reserve_class in chip[4]:\n",
    "                selected.append(chip)\n",
    "                reserve_class = None  # only once\n",
    "            elif reserve_class is None:\n",
    "                selected.append(chip)\n",
    "        return selected\n",
    "\n",
    "    selected_bottom = select_chips(bottom_third, 4, reserve_class=class_names.index(\"Water\"))\n",
    "    selected_bottom = select_chips([c for c in bottom_third if c not in selected_bottom], 4 - len(selected_bottom), reserve_class=class_names.index(\"Building\")) + selected_bottom\n",
    "\n",
    "    selected_middle = middle_third[:4]\n",
    "    selected_top = top_third[:4]\n",
    "\n",
    "    # Combine and assign column index\n",
    "    all_selected = selected_bottom + selected_middle + selected_top\n",
    "    column_assignments = [0] * 4 + [1] * 4 + [2] * 4  # 0: bottom, 1: middle, 2: top\n",
    "\n",
    "    # Step 3: Plotting\n",
    "    fig, axs = plt.subplots(n_rows, n_cols * 3, figsize=(n_cols * 6.6, n_rows * 2.6))\n",
    "\n",
    "    for idx, (rgb, true_mask_oh, pred_mask, _, _) in enumerate(all_selected):\n",
    "        true_mask = np.argmax(true_mask_oh, axis=-1)\n",
    "        h, w = true_mask.shape\n",
    "        true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_id, color in class_to_color.items():\n",
    "            true_rgb[true_mask == class_id] = color\n",
    "            pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "        ignore_mask = np.all(true_mask_oh == 0, axis=-1)\n",
    "        true_rgb[ignore_mask] = (255, 0, 255)\n",
    "        pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "        row = idx % n_rows\n",
    "        col = column_assignments[idx] * 3\n",
    "\n",
    "        axs[row, col + 0].imshow(rgb)\n",
    "        axs[row, col + 0].set_title(\"Input\")\n",
    "        axs[row, col + 1].imshow(true_rgb)\n",
    "        axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "        axs[row, col + 2].imshow(pred_rgb)\n",
    "        axs[row, col + 2].set_title(\"Prediction\")\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[row, col + i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def apply_crf(rgb, probs, t=5, compat=10, sxy=3, srgb=13):\n",
    "    import pydensecrf.densecrf as dcrf\n",
    "    from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "    import numpy as np\n",
    "\n",
    "    h, w = probs.shape[:2]\n",
    "    num_classes = probs.shape[-1]\n",
    "\n",
    "    d = dcrf.DenseCRF2D(w, h, num_classes)\n",
    "\n",
    "    # ðŸ”§ FIX: reshape to (num_classes, H*W)\n",
    "    unary = unary_from_softmax(probs.transpose(2, 0, 1))\n",
    "    unary = unary.reshape((num_classes, -1)).copy(order='C')\n",
    "\n",
    "    d.setUnaryEnergy(unary)\n",
    "\n",
    "    rgb_float = rgb.astype(np.float32)\n",
    "    if not rgb_float.flags['C_CONTIGUOUS']:\n",
    "        rgb_float = np.ascontiguousarray(rgb_float)\n",
    "\n",
    "    pairwise = create_pairwise_bilateral(sdims=(sxy, sxy), schan=(srgb, srgb, srgb), img=rgb_float, chdim=2)\n",
    "    d.addPairwiseEnergy(pairwise, compat=compat)\n",
    "\n",
    "    Q = d.inference(t)\n",
    "    return np.argmax(Q, axis=0).reshape((h, w))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_with_crf(model, test_gen, test_df, out_dir, image_dir, label_dir, tile_size=256, n_rows=4, n_cols=3):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    rgb_list = []\n",
    "    true_mask_list = []\n",
    "    pred_mask_list = []\n",
    "    present_classes_per_chip = []\n",
    "    chip_ious = []\n",
    "\n",
    "    visual_limit = n_rows * n_cols\n",
    "    tile_index = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(test_gen, desc=\"Evaluating\"):\n",
    "        if tf.size(x_batch).numpy() == 0:\n",
    "            continue\n",
    "\n",
    "        soft_preds = model.predict(x_batch, verbose=0)\n",
    "        true_mask_batch = tf.argmax(y_batch, axis=-1).numpy().astype(np.uint8)\n",
    "\n",
    "        for i in range(x_batch.shape[0]):\n",
    "            if tile_index >= len(test_df):\n",
    "                break\n",
    "\n",
    "            # Fix: Convert tensor to NumPy before applying astype()\n",
    "            rgb_img = (x_batch[i][..., :3].numpy() * 255).astype(np.uint8)\n",
    "            softmax_pred = soft_preds[i]\n",
    "            crf_mask = apply_crf(rgb_img, softmax_pred)\n",
    "\n",
    "            true_mask = true_mask_batch[i]\n",
    "            all_preds.extend(crf_mask.reshape(-1))\n",
    "            all_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "            # Per-chip IoU\n",
    "            cm = confusion_matrix(true_mask.flatten(), crf_mask.flatten(), labels=list(range(NUM_CLASSES)))\n",
    "            ious = []\n",
    "            for j in range(NUM_CLASSES):\n",
    "                intersection = cm[j, j]\n",
    "                union = np.sum(cm[j, :]) + np.sum(cm[:, j]) - intersection\n",
    "                if union > 0:\n",
    "                    iou = intersection / union\n",
    "                    ious.append(iou)\n",
    "            chip_ious.append(np.mean(ious) if ious else 0)\n",
    "\n",
    "            if len(rgb_list) < visual_limit:\n",
    "                rgb_list.append(rgb_img)\n",
    "                true_mask_onehot = y_batch[i].numpy()\n",
    "                true_mask_list.append(true_mask_onehot)\n",
    "                pred_mask_list.append(crf_mask)\n",
    "\n",
    "                present_classes = np.unique(true_mask)\n",
    "                present_classes = [int(c) for c in present_classes if c < NUM_CLASSES]\n",
    "                present_classes_per_chip.append(present_classes)\n",
    "\n",
    "            tile_index += 1\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    visualise_prediction_grid(\n",
    "        rgb_list=rgb_list,\n",
    "        true_mask_list=true_mask_list,\n",
    "        pred_mask_list=pred_mask_list,\n",
    "        n_rows=n_rows,\n",
    "        n_cols=n_cols\n",
    "    )\n",
    "\n",
    "    # --- Metrics ---\n",
    "    f1 = f1_score(all_trues, all_preds, average='macro')\n",
    "    precision = precision_score(all_trues, all_preds, average='macro')\n",
    "    recall = recall_score(all_trues, all_preds, average='macro')\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_trues, all_preds, labels=list(range(NUM_CLASSES)))\n",
    "    per_class_ious = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = conf_matrix[i, i]\n",
    "        union = np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - intersection\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        per_class_ious.append(iou)\n",
    "    miou = np.mean(per_class_ious)\n",
    "\n",
    "    report = classification_report(\n",
    "        all_trues, all_preds, target_names=CLASS_NAMES, digits=4\n",
    "    )\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_conf = np.divide(conf_matrix.astype(np.float32), row_sums, where=row_sums != 0)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(norm_conf, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='viridis', ax=ax, values_format=\".2f\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, 'confusion_matrix_crf.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- Per-chip mIoU histogram ---\n",
    "    print(\"\\nðŸ“Š Generating per-chip mIoU histogram...\")\n",
    "    bin_edges = np.linspace(0, 1, 21)  # 5% bins\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(chip_ious, bins=bin_edges, edgecolor='black')\n",
    "    plt.xlabel(\"Per-Chip mIoU\")\n",
    "    plt.ylabel(\"Number of Chips\")\n",
    "    plt.title(\"Distribution of Per-Chip mIoU (CRF Post-Processed)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"per_chip_miou_hist.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"miou\": miou,\n",
    "        \"per_class_ious\": per_class_ious,\n",
    "        \"classification_report\": report\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
