{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5Pup5vv_c2R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "out_dir=\"/content/figs\"\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items() if v < 6} # Exclude ignore color\n",
    "\n",
    "\n",
    "def visualise_prediction(rgb, true_mask_onehot, pred_mask):\n",
    "    true_mask = np.argmax(true_mask_onehot, axis=-1)\n",
    "\n",
    "    h, w = true_mask.shape\n",
    "    true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in CLASS_TO_COLOR.items():\n",
    "        true_rgb[true_mask == class_id] = color\n",
    "        pred_rgb[pred_mask == class_id] = color\n",
    "\n",
    "    ignore_mask = np.all(true_mask_onehot == 0, axis=-1)\n",
    "    true_rgb[ignore_mask] = (255, 0, 255)\n",
    "    pred_rgb[ignore_mask] = (255, 0, 255)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    axs[0].imshow(rgb)\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(true_rgb)\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(pred_rgb)\n",
    "    axs[2].set_title(\"Prediction\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_predictions(pred_mask, true_mask, num_classes=6):\n",
    "    print(\"üîé Evaluating predictions...\")\n",
    "\n",
    "    pred_flat = np.asarray(pred_mask).flatten()\n",
    "    true_flat = np.asarray(true_mask).flatten()\n",
    "\n",
    "    # Remove ignored pixels (label == 6)\n",
    "    valid_indices = true_flat != 6\n",
    "    pred_flat = pred_flat[valid_indices]\n",
    "    true_flat = true_flat[valid_indices]\n",
    "\n",
    "    if pred_flat.shape != true_flat.shape:\n",
    "        raise ValueError(f\"Prediction and ground truth shapes don't match: {pred_flat.shape} vs {true_flat.shape}\")\n",
    "\n",
    "    print(\"üìà Classification Report:\")\n",
    "    print(classification_report(\n",
    "        true_flat,\n",
    "        pred_flat,\n",
    "        labels=np.arange(num_classes),\n",
    "        zero_division=0,\n",
    "        digits=3\n",
    "    ))\n",
    "\n",
    "    class_names = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "    print(\"\\nüåÄ Confusion Matrix:\")\n",
    "    cm = confusion_matrix(true_flat, pred_flat, labels=np.arange(num_classes))\n",
    "    cm_normalised = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_normalised, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Normalised Confusion Matrix\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"conf_matrix.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüìä IoU per Class:\")\n",
    "    intersection = np.diag(cm)\n",
    "    ground_truth_set = cm.sum(axis=1)\n",
    "    predicted_set = cm.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "\n",
    "    iou_per_class = intersection / np.maximum(union, 1)\n",
    "\n",
    "    for i, iou in enumerate(iou_per_class):\n",
    "        name = class_names[i]\n",
    "        print(f\"  Class {i} ({name}): {iou:.4f}\")\n",
    "\n",
    "    mean_iou = np.mean(iou_per_class)\n",
    "    print(f\"\\nüìà Mean IoU: {mean_iou:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_on_test(model, test_gen, test_df, pred_out_dir, image_dir, label_dir, tile_size=256, n_vis=10):\n",
    "    print(\"üß™ Running evaluation on test set...\")\n",
    "\n",
    "    all_test_preds = []\n",
    "    all_test_trues = []\n",
    "    shown_ids = set()\n",
    "    os.makedirs(pred_out_dir, exist_ok=True)\n",
    "\n",
    "    test_tile_ids = test_df['tile_id'].tolist()\n",
    "    tile_index = 0\n",
    "\n",
    "    for batch_x, batch_y in test_gen.as_numpy_iterator():\n",
    "        if batch_x.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(batch_x, verbose=0)\n",
    "        pred_mask = np.argmax(pred, axis=-1).astype(np.uint8)\n",
    "        true_mask = np.argmax(batch_y, axis=-1).astype(np.uint8)\n",
    "\n",
    "        for j in range(batch_x.shape[0]):\n",
    "            if tile_index >= len(test_tile_ids):\n",
    "                break  # safety stop\n",
    "            tile_id = test_tile_ids[tile_index]\n",
    "            tile_index += 1\n",
    "\n",
    "            # üíæ Save prediction\n",
    "            pred_rgb = np.zeros((*pred_mask[j].shape, 3), dtype=np.uint8)\n",
    "            for class_id, color in CLASS_TO_COLOR.items():\n",
    "                pred_rgb[pred_mask[j] == class_id] = color\n",
    "            Image.fromarray(pred_rgb).save(os.path.join(pred_out_dir, tile_id + \".png\"))\n",
    "\n",
    "            # üëÅÔ∏è Visualise\n",
    "            if len(shown_ids) < n_vis:\n",
    "                rgb_tile = (batch_x[j][:, :, :3] * 255).astype(np.uint8)\n",
    "                visualise_prediction(rgb_tile, batch_y[j], pred_mask[j])\n",
    "                shown_ids.add(tile_id)\n",
    "\n",
    "        all_test_preds.extend(pred_mask.reshape(-1))\n",
    "        all_test_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "        del batch_x, batch_y, pred, pred_mask, true_mask\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_test_preds:\n",
    "        print(\"‚ö†Ô∏è No test predictions were collected.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüìä Test Set Evaluation Results:\")\n",
    "    evaluate_predictions(np.array(all_test_preds), np.array(all_test_trues))\n",
    "    '''\n",
    "    # üß© Reconstruct each base file and save outputs\n",
    "    os.makedirs(\"/content/figs\", exist_ok=True)\n",
    "    os.makedirs(\"/content/drive/MyDrive/figs\", exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_files = test_df['tile_id'].str.extract(r\"(^[^_]+_[^_]+_[^_]+)\")[0].unique()\n",
    "\n",
    "    for base in base_files:\n",
    "        base_df = test_df[test_df['tile_id'].str.startswith(base)]\n",
    "        img_canvas, label_canvas, pred_canvas = reconstruct_prediction_canvas(\n",
    "            df=base_df,\n",
    "            tile_size=tile_size,\n",
    "            image_dir=image_dir,\n",
    "            label_dir=label_dir,\n",
    "            pred_dir=pred_out_dir\n",
    "        )\n",
    "\n",
    "        for name, canvas in zip(['img', 'label', 'pred'], [img_canvas, label_canvas, pred_canvas]):\n",
    "            filename = f\"{timestamp}_{name}_{base}.png\"\n",
    "            for target_dir in [\"/content/figs\", \"/content/drive/MyDrive/figs\"]:\n",
    "                Image.fromarray(canvas).save(os.path.join(target_dir, filename))\n",
    "\n",
    "        gc.collect()'''\n",
    "\n",
    "    print(\"‚úÖ Reconstruction and saving complete.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reconstruct_prediction_canvas(df, tile_size, image_dir, label_dir, pred_dir):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import os\n",
    "\n",
    "    # Determine canvas size from tile coordinates\n",
    "    x_coords = df['x'].values\n",
    "    y_coords = df['y'].values\n",
    "    max_x = x_coords.max() + tile_size\n",
    "    max_y = y_coords.max() + tile_size\n",
    "    min_x = x_coords.min()\n",
    "    min_y = y_coords.min()\n",
    "\n",
    "    canvas_shape = (max_y - min_y, max_x - min_x, 3)\n",
    "    img_canvas = np.full(canvas_shape, (255, 0, 255), dtype=np.uint8)  # Magenta default\n",
    "    label_canvas = np.full(canvas_shape, (255, 0, 255), dtype=np.uint8)\n",
    "    pred_canvas = np.full(canvas_shape, (255, 0, 255), dtype=np.uint8)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tile_id = row['tile_id']\n",
    "        x, y = row['x'], row['y']\n",
    "        x_offset = x - min_x\n",
    "        y_offset = y - min_y\n",
    "\n",
    "        try:\n",
    "            img_path = os.path.join(image_dir, tile_id + '-ortho.png')\n",
    "            label_path = os.path.join(label_dir, tile_id + '-label.png')\n",
    "            pred_path = os.path.join(pred_dir, tile_id + '.png')\n",
    "\n",
    "            if os.path.exists(img_path):\n",
    "                rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "                img_canvas[y_offset:y_offset+tile_size, x_offset:x_offset+tile_size] = rgb\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                label_rgb = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
    "                label_canvas[y_offset:y_offset+tile_size, x_offset:x_offset+tile_size] = label_rgb\n",
    "\n",
    "            if os.path.exists(pred_path):\n",
    "                pred_rgb = cv2.cvtColor(cv2.imread(pred_path), cv2.COLOR_BGR2RGB)\n",
    "                pred_canvas[y_offset:y_offset+tile_size, x_offset:x_offset+tile_size] = pred_rgb\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load tile {tile_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return img_canvas, label_canvas, pred_canvas\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIvhFb8l65g0rsyWayDedf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
