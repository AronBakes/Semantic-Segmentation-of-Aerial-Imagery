{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105789fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "import math\n",
    "\n",
    "class Attention(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        sr_ratio,\n",
    "        qkv_bias=False,\n",
    "        attn_drop=0.0,\n",
    "        proj_drop=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = self.dim // self.num_heads\n",
    "\n",
    "        self.units = self.num_heads * self.head_dim\n",
    "        self.sqrt_of_units = math.sqrt(self.head_dim)\n",
    "\n",
    "        self.q = keras.layers.Dense(self.units)\n",
    "        self.k = keras.layers.Dense(self.units)\n",
    "        self.v = keras.layers.Dense(self.units)\n",
    "\n",
    "        self.attn_drop = keras.layers.Dropout(attn_drop)\n",
    "\n",
    "        self.sr_ratio = sr_ratio\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = keras.layers.Conv2D(\n",
    "                filters=dim, kernel_size=sr_ratio, strides=sr_ratio, name='sr',\n",
    "            )\n",
    "            self.norm = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "           \n",
    "        self.proj = keras.layers.Dense(dim)\n",
    "        self.proj_drop = keras.layers.Dropout(proj_drop)\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        x,\n",
    "        H,\n",
    "        W,\n",
    "    ):\n",
    "        get_shape = ops.shape(x)\n",
    "        B = get_shape[0]\n",
    "        C = get_shape[2]\n",
    "\n",
    "        q = self.q(x)\n",
    "        q = ops.reshape(\n",
    "            q, (ops.shape(q)[0], -1, self.num_heads, self.head_dim)\n",
    "        )\n",
    "        q = ops.transpose(q, axes=[0, 2, 1, 3])\n",
    "\n",
    "        if self.sr_ratio > 1:\n",
    "            x = ops.reshape(x, (B, H, W, C))\n",
    "            x = self.sr(x)\n",
    "            x = ops.reshape(x, (B, -1, C))\n",
    "            x = self.norm(x)\n",
    "\n",
    "        k = self.k(x)\n",
    "        k = ops.reshape(\n",
    "            k, (ops.shape(k)[0], -1, self.num_heads, self.head_dim)\n",
    "        )\n",
    "        k = ops.transpose(k, axes=[0, 2, 1, 3])\n",
    "\n",
    "        v = self.v(x)\n",
    "        v = ops.reshape(\n",
    "            v, (ops.shape(v)[0], -1, self.num_heads, self.head_dim)\n",
    "        )\n",
    "        v = ops.transpose(v, axes=[0, 2, 1, 3])\n",
    "\n",
    "        attn = ops.matmul(q, ops.transpose(k, axes=[0, 1, 3, 2]))\n",
    "        scale = ops.cast(self.sqrt_of_units, dtype=attn.dtype)\n",
    "        attn = ops.divide(attn, scale)\n",
    "\n",
    "        attn = ops.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = ops.matmul(attn, v)\n",
    "        x = ops.transpose(x, axes=[0, 2, 1, 3])\n",
    "        x = ops.reshape(x, (B, -1, self.units))\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "class MLP(keras.layers.Layer):\n",
    "    def __init__(self, decode_dim):\n",
    "        super().__init__()\n",
    "        self.proj = keras.layers.Dense(decode_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(keras.layers.Layer):\n",
    "    def __init__(self, decode_dim):\n",
    "        super().__init__()\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            filters=decode_dim, kernel_size=1, use_bias=False\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9)\n",
    "        self.activate = keras.layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SegFormerHead(keras.layers.Layer):\n",
    "    def __init__(self, num_mlp_layers=4, decode_dim=768, num_classes=19):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_mlp_layers):\n",
    "            self.linear_layers.append(MLP(decode_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(decode_dim)\n",
    "        self.dropout = keras.layers.Dropout(0.1)\n",
    "        self.linear_pred = keras.layers.Conv2D(num_classes, kernel_size=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        H = ops.shape(inputs[0])[1]\n",
    "        W = ops.shape(inputs[0])[2]\n",
    "        outputs = []\n",
    "\n",
    "        for x, mlps in zip(inputs, self.linear_layers):\n",
    "            x = mlps(x)\n",
    "            x = ops.image.resize(x, size=(H, W), interpolation=\"bilinear\")\n",
    "            outputs.append(x)\n",
    "\n",
    "        x = self.linear_fuse(ops.concatenate(outputs[::-1], axis=3))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_pred(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "\n",
    "class DWConv(keras.layers.Layer):\n",
    "    def __init__(self, filters=768, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dwconv = keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            groups=filters,\n",
    "        )\n",
    "\n",
    "    def call(self, x, H, W):\n",
    "        get_shape_1 = ops.shape(x)\n",
    "        x = ops.reshape(x, (get_shape_1[0], H, W, get_shape_1[-1]))\n",
    "        x = self.dwconv(x)\n",
    "        get_shape_2 = ops.shape(x)\n",
    "        x = ops.reshape(\n",
    "            x, (get_shape_2[0], get_shape_2[1] * get_shape_2[2], get_shape_2[3])\n",
    "        )\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mlp(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features=None,\n",
    "        out_features=None,\n",
    "        drop=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = keras.layers.Dense(hidden_features)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = keras.layers.Activation(\"gelu\")\n",
    "        self.fc2 = keras.layers.Dense(out_features)\n",
    "        self.drop = keras.layers.Dropout(drop)\n",
    "\n",
    "    def call(self, x, H, W):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x, H=H, W=W)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=False,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        sr_ratio=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "        self.attn = Attention(\n",
    "            dim,\n",
    "            num_heads,\n",
    "            sr_ratio,\n",
    "            qkv_bias=qkv_bias,\n",
    "            attn_drop=attn_drop,\n",
    "            proj_drop=drop,\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim,\n",
    "            hidden_features=mlp_hidden_dim,\n",
    "            drop=drop,\n",
    "        )\n",
    "\n",
    "    def call(self, x, H, W):\n",
    "        # Apply LayerNormalization and Attention layer\n",
    "        attn_output_norm = self.norm1(x)\n",
    "        attn_output = self.attn(attn_output_norm, H=H, W=W)\n",
    "        attn_output_with_drop = self.drop_path(attn_output)\n",
    "        x = x + attn_output_with_drop\n",
    "\n",
    "        # Apply LayerNormalization and MLP layer\n",
    "        mlp_output_norm = self.norm2(x)\n",
    "        mlp_output = self.mlp(mlp_output_norm, H=H, W=W)\n",
    "        mlp_output_with_drop = self.drop_path(mlp_output)\n",
    "        x = x + mlp_output_with_drop\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class OverlapPatchEmbed(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, img_size=224, patch_size=7, stride=4, filters=768, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pad = keras.layers.ZeroPadding2D(padding=patch_size // 2)\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=patch_size,\n",
    "            strides=stride,\n",
    "            padding=\"VALID\",\n",
    "            name='proj',\n",
    "        )\n",
    "        self.norm = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(self.pad(x))\n",
    "        get_shapes = ops.shape(x)\n",
    "        H = get_shapes[1]\n",
    "        W = get_shapes[2]\n",
    "        C = get_shapes[3]\n",
    "        x = ops.reshape(x, (-1, H * W, C))\n",
    "        x = self.norm(x)\n",
    "        return x, H, W\n",
    "\n",
    "\n",
    "class MixVisionTransformer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size=224,\n",
    "        embed_dims=[64, 128, 256, 512],\n",
    "        num_heads=[1, 2, 4, 8],\n",
    "        mlp_ratios=[4, 4, 4, 4],\n",
    "        qkv_bias=False,\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        drop_path_rate=0.0,\n",
    "        depths=[3, 4, 6, 3],\n",
    "        sr_ratios=[8, 4, 2, 1],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        # patch_embed\n",
    "        self.patch_embed1 = OverlapPatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=7,\n",
    "            stride=4,\n",
    "            filters=embed_dims[0],\n",
    "        )\n",
    "        self.patch_embed2 = OverlapPatchEmbed(\n",
    "            img_size=img_size // 4,\n",
    "            patch_size=3,\n",
    "            stride=2,\n",
    "            filters=embed_dims[1],\n",
    "        )\n",
    "        self.patch_embed3 = OverlapPatchEmbed(\n",
    "            img_size=img_size // 8,\n",
    "            patch_size=3,\n",
    "            stride=2,\n",
    "            filters=embed_dims[2],\n",
    "        )\n",
    "        self.patch_embed4 = OverlapPatchEmbed(\n",
    "            img_size=img_size // 16,\n",
    "            patch_size=3,\n",
    "            stride=2,\n",
    "            filters=embed_dims[3],\n",
    "        )\n",
    "\n",
    "        dpr = [x for x in ops.linspace(0.0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        self.block1 = [\n",
    "            Block(\n",
    "                dim=embed_dims[0],\n",
    "                num_heads=num_heads[0],\n",
    "                mlp_ratio=mlp_ratios[0],\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[cur + i],\n",
    "                sr_ratio=sr_ratios[0],\n",
    "            )\n",
    "            for i in range(depths[0])\n",
    "        ]\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "\n",
    "        cur += depths[0]\n",
    "        self.block2 = [\n",
    "            Block(\n",
    "                dim=embed_dims[1],\n",
    "                num_heads=num_heads[1],\n",
    "                mlp_ratio=mlp_ratios[1],\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[cur + i],\n",
    "                sr_ratio=sr_ratios[1],\n",
    "            )\n",
    "            for i in range(depths[1])\n",
    "        ]\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "\n",
    "        cur += depths[1]\n",
    "        self.block3 = [\n",
    "            Block(\n",
    "                dim=embed_dims[2],\n",
    "                num_heads=num_heads[2],\n",
    "                mlp_ratio=mlp_ratios[2],\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[cur + i],\n",
    "                sr_ratio=sr_ratios[2],\n",
    "            )\n",
    "            for i in range(depths[2])\n",
    "        ]\n",
    "        self.norm3 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "\n",
    "        cur += depths[2]\n",
    "        self.block4 = [\n",
    "            Block(\n",
    "                dim=embed_dims[3],\n",
    "                num_heads=num_heads[3],\n",
    "                mlp_ratio=mlp_ratios[3],\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[cur + i],\n",
    "                sr_ratio=sr_ratios[3],\n",
    "            )\n",
    "            for i in range(depths[3])\n",
    "        ]\n",
    "        self.norm4 = keras.layers.LayerNormalization(epsilon=1e-05)\n",
    "\n",
    "    def call_features(self, x):\n",
    "        B = ops.shape(x)[0]\n",
    "        outs = []\n",
    "\n",
    "        # stage 1\n",
    "        x, H, W = self.patch_embed1(x)\n",
    "        for i, blk in enumerate(self.block1):\n",
    "            x = blk(x, H=H, W=W)\n",
    "        x = self.norm1(x)\n",
    "        x = ops.reshape(x, (B, H, W, ops.shape(x)[-1]))\n",
    "        outs.append(x)\n",
    "\n",
    "        # stage 2\n",
    "        x, H, W = self.patch_embed2(x)\n",
    "        for i, blk in enumerate(self.block2):\n",
    "            x = blk(x, H=H, W=W)\n",
    "        x = self.norm2(x)\n",
    "        x = ops.reshape(x, (B, H, W, ops.shape(x)[-1]))\n",
    "        outs.append(x)\n",
    "\n",
    "        # stage 3\n",
    "        x, H, W = self.patch_embed3(x)\n",
    "        for i, blk in enumerate(self.block3):\n",
    "            x = blk(x, H=H, W=W)\n",
    "        x = self.norm3(x)\n",
    "        x = ops.reshape(x, (B, H, W, ops.shape(x)[-1]))\n",
    "        outs.append(x)\n",
    "\n",
    "        # stage 4\n",
    "        x, H, W = self.patch_embed4(x)\n",
    "        for i, blk in enumerate(self.block4):\n",
    "            x = blk(x, H=H, W=W)\n",
    "        x = self.norm4(x)\n",
    "        x = ops.reshape(x, (B, H, W, ops.shape(x)[-1]))\n",
    "        outs.append(x)\n",
    "\n",
    "        return outs\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.call_features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"mit_b0\": {\n",
    "        \"embed_dims\": [32, 64, 160, 256],\n",
    "        \"depths\": [2, 2, 2, 2],\n",
    "        \"decode_dim\": 256,\n",
    "    },\n",
    "    \"mit_b1\": {\n",
    "        \"embed_dims\": [64, 128, 320, 512],\n",
    "        \"depths\": [2, 2, 2, 2],\n",
    "        \"decode_dim\": 256,\n",
    "    },\n",
    "    \"mit_b2\": {\n",
    "        \"embed_dims\": [64, 128, 320, 512],\n",
    "        \"depths\": [3, 4, 6, 3],\n",
    "        \"decode_dim\": 768,\n",
    "    },\n",
    "    \"mit_b3\": {\n",
    "        \"embed_dims\": [64, 128, 320, 512],\n",
    "        \"depths\": [3, 4, 18, 3],\n",
    "        \"decode_dim\": 768,\n",
    "    },\n",
    "    \"mit_b4\": {\n",
    "        \"embed_dims\": [64, 128, 320, 512],\n",
    "        \"depths\": [3, 8, 27, 3],\n",
    "        \"decode_dim\": 768,\n",
    "    },\n",
    "    \"mit_b5\": {\n",
    "        \"embed_dims\": [64, 128, 320, 512],\n",
    "        \"depths\": [3, 6, 40, 3],\n",
    "        \"decode_dim\": 768,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def SegFormer_B0(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b0\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b0\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b0\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "def SegFormer_B1(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b1\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b1\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b1\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "def SegFormer_B2(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b2\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b2\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b2\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "def SegFormer_B3(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b3\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b3\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b3\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "def SegFormer_B4(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b4\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b4\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b4\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "def SegFormer_B5(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = MixVisionTransformer(\n",
    "        img_size=input_shape[1],\n",
    "        embed_dims=MODEL_CONFIGS[\"mit_b5\"][\"embed_dims\"],\n",
    "        depths=MODEL_CONFIGS[\"mit_b5\"][\"depths\"],\n",
    "    )(input_layer)\n",
    "    x = SegFormerHead(\n",
    "        num_classes=num_classes,\n",
    "        decode_dim=MODEL_CONFIGS[\"mit_b5\"][\"decode_dim\"],\n",
    "    )(x)\n",
    "\n",
    "    x = ResizeLayer(input_shape[0], input_shape[1])(x)\n",
    "    x = ops.softmax(x)\n",
    "    return keras.Model(inputs=input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "\n",
    "class ResizeLayer(keras.layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def call(self, inputs):\n",
    "        resized = ops.image.resize(\n",
    "            inputs,\n",
    "            size=(self.height, self.width),\n",
    "            interpolation=\"bilinear\",\n",
    "        )\n",
    "        return resized\n",
    "\n",
    "\n",
    "class DropPath(keras.layers.Layer):\n",
    "    def __init__(self, drop_path, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = tf.cast(1.0 - self.drop_path, dtype=x.dtype)\n",
    "            shape = (ops.shape(x)[0],) + (1,) * (len(ops.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1, dtype=x.dtype)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n",
    "    \n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = tf.cast(1.0 - self.drop_path, dtype=x.dtype)\n",
    "            shape = (ops.shape(x)[0],) + (1,) * (len(ops.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1, dtype=x.dtype)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
