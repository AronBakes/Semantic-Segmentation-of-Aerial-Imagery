{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import gc\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# --- Sanity ---\n",
    "def test_training_sanity():\n",
    "    print(\"‚úÖ from training.ipynb\")\n",
    "\n",
    "# --- Visualisation ---\n",
    "def visualise_prediction(rgb, true_mask, pred_mask):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    axs[0].imshow(rgb)\n",
    "    axs[0].set_title(\"RGB Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(COLOR_PALETTE[true_mask])\n",
    "    axs[1].set_title(\"True Mask\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(COLOR_PALETTE[pred_mask])\n",
    "    axs[2].set_title(\"Predicted Mask\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "INPUT_TYPE_CONFIG = {\n",
    "    \"1ch\": {\"description\": \"grayscale only\", \"channels\": 1},\n",
    "    \"2ch\": {\"description\": \"grayscale + elevation\", \"channels\": 2},\n",
    "    \"rgb\": {\"description\": \"RGB only\", \"channels\": 3},\n",
    "    \"rgb_elevation\": {\"description\": \"RGB + elevation\", \"channels\": 4}\n",
    "}\n",
    "\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,\n",
    "    (145, 30, 180): 1,\n",
    "    (60, 180, 75): 2,\n",
    "    (245, 130, 48): 3,\n",
    "    (255, 255, 255): 4,\n",
    "    (0, 130, 200): 5\n",
    "}\n",
    "\n",
    "CLASS_TO_COLOR = {v: k for k, v in COLOR_TO_CLASS.items()}\n",
    "NUM_CLASSES = len(COLOR_TO_CLASS)\n",
    "COLOR_PALETTE = np.array(list(COLOR_TO_CLASS.keys()), dtype=np.uint8)\n",
    "COLOR_LOOKUP = {tuple(c): i for c, i in COLOR_TO_CLASS.items()}\n",
    "\n",
    "class ClearMemory(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "def decode_label_image(label_img):\n",
    "    h, w, _ = label_img.shape\n",
    "    label_map = np.zeros((h, w), dtype=np.uint8)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            pixel = tuple(label_img[y, x])\n",
    "            if pixel not in COLOR_LOOKUP:\n",
    "                raise ValueError(f\"‚ùå Unknown label colour {pixel} at ({y}, {x})\")\n",
    "            label_map[y, x] = COLOR_LOOKUP[pixel]\n",
    "    return label_map\n",
    "\n",
    "def load_rgb_pair_batch(image_dir, label_dir, batch_size=4):\n",
    "    x_batch, y_batch = [], []\n",
    "    filenames = [f for f in os.listdir(image_dir) if f.endswith('-ortho.png') and os.path.getsize(os.path.join(image_dir, f)) > 0][:batch_size]\n",
    "\n",
    "    if not filenames:\n",
    "        print(f\"‚ö†Ô∏è No valid image files found in {image_dir}.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    for f in filenames:\n",
    "        base = f.replace('-ortho.png', '')\n",
    "        rgb_path = os.path.join(image_dir, base + '-ortho.png')\n",
    "        label_path = os.path.join(label_dir, base + '-label.png')\n",
    "\n",
    "        if not os.path.exists(rgb_path) or not os.path.exists(label_path):\n",
    "            print(f\"Skipping {base}: Missing files.\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "        label_rgb = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if img is None or label_rgb is None or img.shape != label_rgb.shape:\n",
    "            print(f\"Skipping {base}: Failed to load or mismatched shape.\")\n",
    "            continue\n",
    "\n",
    "        h, w, _ = label_rgb.shape\n",
    "        # Use int type to avoid wrap-around for unknown colors\n",
    "        label = np.full((h, w), -1, dtype=np.int32) # Changed dtype to int32\n",
    "        for color, idx in COLOR_TO_CLASS.items():\n",
    "            mask = np.all(label_rgb == color, axis=-1)\n",
    "            label[mask] = idx\n",
    "\n",
    "        # Check for pixels that are still -1 (unknown colors)\n",
    "        if np.any(label == -1):\n",
    "            print(f\"‚ö†Ô∏è Unknown colours found in label at {label_path}. Skipping this image.\")\n",
    "            continue # Skip this pair if unknown colors are present\n",
    "\n",
    "\n",
    "        # Before converting to categorical, ensure all labels are within the valid range [0, NUM_CLASSES-1]\n",
    "        # The previous check for -1 already handles this if we skip the image,\n",
    "        # but it's good practice to be explicit before to_categorical.\n",
    "        if np.any(label < 0) or np.any(label >= NUM_CLASSES):\n",
    "             print(f\"‚ö†Ô∏è Invalid label values found in label at {label_path} after mapping. Skipping this image.\")\n",
    "             continue\n",
    "\n",
    "\n",
    "        label_onehot = tf.keras.utils.to_categorical(label, num_classes=NUM_CLASSES)\n",
    "\n",
    "        print(f\"Unique label indicies before one-hot for {base}: {np.unique(label)}\")\n",
    "\n",
    "        x_batch.append(img.astype(np.float32) / 255.0)\n",
    "        y_batch.append(label_onehot.astype(np.float32))\n",
    "\n",
    "    try:\n",
    "        # Stack the loaded data.\n",
    "        # Only return arrays if data was actually loaded.\n",
    "        if x_batch and y_batch:\n",
    "             return np.array(x_batch), np.array(y_batch)\n",
    "        else:\n",
    "             print(\"‚ö†Ô∏è No valid data loaded for the batch.\")\n",
    "             return np.array([]), np.array([])\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error creating numpy arrays: {e}\")\n",
    "        print(f\"Shapes of loaded images: {[x.shape for x in x_batch]}\")\n",
    "        print(f\"Shapes of loaded labels: {[y.shape for y in y_batch]}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "\n",
    "\n",
    "def train_model(input_type=\"rgb_elevation\", model_type=\"unet\", batch_size=8, epochs=10, tile_size=512, steps_per_epoch=None, verbose=1):\n",
    "    assert input_type in INPUT_TYPE_CONFIG, f\"Unknown input type: {input_type}\"\n",
    "    num_channels = INPUT_TYPE_CONFIG[input_type][\"channels\"]\n",
    "\n",
    "    print(f\"\\nüîß Training {model_type.upper()} with input type: {input_type} ({num_channels} channels)\")\n",
    "    print(f\"üß™ Computed input shape: ({tile_size}, {tile_size}, {num_channels})\")\n",
    "\n",
    "    base_dir = \"/content/chipped_data/chipped\"\n",
    "    train_images = os.path.join(base_dir, \"train\", \"images\")\n",
    "    train_elev = os.path.join(base_dir, \"train\", \"elevations\")\n",
    "    train_labels = os.path.join(base_dir, \"train\", \"labels\")\n",
    "\n",
    "    val_images = os.path.join(base_dir, \"val\", \"images\")\n",
    "    val_elev = os.path.join(base_dir, \"val\", \"elevations\")\n",
    "    val_labels = os.path.join(base_dir, \"val\", \"labels\")\n",
    "\n",
    "    # --- Generators ---\n",
    "    '''\n",
    "    train_gen = StreamingDataGenerator(train_images, train_elev, train_labels, \n",
    "                                       batch_size=batch_size, input_type=input_type, \n",
    "                                       shuffle=True, steps_per_epoch=steps_per_epoch,\n",
    "                                       )\n",
    "    val_gen = StreamingDataGenerator(val_images, val_elev, val_labels, \n",
    "                                      batch_size=batch_size, input_type=input_type, \n",
    "                                      shuffle=False, steps_per_epoch=steps_per_epoch,\n",
    "                                      )'''\n",
    "    \n",
    "    train_gen = load_rgb_pair_batch(train_images, train_labels, batch_size=16)\n",
    "    val_gen = load_rgb_pair_batch(val_images, val_labels, batch_size=16)\n",
    "\n",
    "\n",
    "    # --- Model ---\n",
    "    if model_type == \"unet\":\n",
    "        print(\"üß™ Calling build_unet...\")\n",
    "        model = build_unet(input_shape=(tile_size, tile_size, num_channels), num_classes=NUM_CLASSES)\n",
    "    elif model_type == \"segformer\":\n",
    "        raise NotImplementedError(\"SegFormer support is coming soon.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    print(f\"üß™ Final model input shape: {model.input_shape}\")\n",
    "\n",
    "    class_weights = compute_class_weights(train_gen)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "        return tf.reduce_mean(weights * loss_fn(y_true, y_pred))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=weighted_loss, metrics=['accuracy'])\n",
    "    print(\"‚úÖ Model compiled with class weights\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    checkpoint = ModelCheckpoint(\"checkpoints/best_model.h5\", monitor='val_accuracy', save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, verbose=1)\n",
    "    nan_terminate = TerminateOnNaN()\n",
    "\n",
    "    class TimeLimitCallback(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, max_minutes=20):\n",
    "            super().__init__()\n",
    "            self.max_duration = max_minutes * 60\n",
    "        def on_train_begin(self, logs=None):\n",
    "            self.start_time = tf.timestamp()\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            elapsed = tf.timestamp() - self.start_time\n",
    "            if elapsed > self.max_duration:\n",
    "                print(f\"‚è±Ô∏è Training time exceeded {self.max_duration // 60} minutes. Stopping early.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    time_limit = TimeLimitCallback(max_minutes=120)\n",
    "    callbacks = [checkpoint, early_stop, reduce_lr, nan_terminate, time_limit, ClearMemory()]\n",
    "\n",
    "    print(\"Shape of data from train_gen:\", next(iter(train_gen))[0].shape)\n",
    "    print(\"Type of data from train_gen:\", type(next(iter(train_gen))[0]))\n",
    "\n",
    "    print(\"üöÄ Starting training...\")\n",
    "    history = model.fit(\n",
    "        train_gen, validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    print(\"üß™ Running evaluation on full validation set...\")\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    shown = 0\n",
    "\n",
    "    for val_imgs, val_lbls in val_gen:\n",
    "        pred = model.predict(val_imgs)\n",
    "        pred_mask = np.argmax(pred, axis=-1).astype(np.uint8)\n",
    "        true_mask = np.argmax(val_lbls, axis=-1).astype(np.uint8)\n",
    "\n",
    "        all_preds.extend(pred_mask.reshape(-1))\n",
    "        all_trues.extend(true_mask.reshape(-1))\n",
    "\n",
    "        for i in range(min(5 - shown, len(val_imgs))):\n",
    "            rgb_tile = (val_imgs[i][:, :, :3] * 255).astype(np.uint8)\n",
    "            visualise_prediction(rgb_tile, true_mask[i], pred_mask[i])\n",
    "            shown += 1\n",
    "            if shown >= 5:\n",
    "                break\n",
    "        if shown >= 5:\n",
    "            break\n",
    "\n",
    "    print(\"\\nüìä Evaluation Results:\")\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_true = np.array(all_trues)\n",
    "\n",
    "    evaluate_predictions(y_pred, y_true)\n",
    "\n",
    "    print(\"\\nüìä Class distribution in training set:\")\n",
    "    plot_class_distribution(train_gen, title=\"Training Class Distribution\")\n",
    "\n",
    "    print(\"\\nüìä Class distribution in validation set:\")\n",
    "    plot_class_distribution(val_gen, title=\"Validation Class Distribution\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPw4dXqbrOaTut/+CDo+nZ1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
