{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPw4dXqbrOaTut/+CDo+nZ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iNmbNrRDlS18"},"outputs":[],"source":["# training.ipynb (converted to be run from main.ipynb)\n","\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n","import cv2\n","\n","# Supported input types\n","INPUT_TYPE_CONFIG = {\n","    \"1ch\": {\"description\": \"grayscale only\", \"channels\": 1},\n","    \"2ch\": {\"description\": \"grayscale + elevation\", \"channels\": 2},\n","    \"rgb\": {\"description\": \"RGB only\", \"channels\": 3},\n","    \"rgb_elevation\": {\"description\": \"RGB + elevation\", \"channels\": 4}\n","}\n","\n","# Colour-to-class mapping (used for decoding masks)\n","COLOR_TO_CLASS = {\n","    (75, 25, 230): 0,       # BUILDING\n","    (180, 30, 145): 1,      # CLUTTER\n","    (75, 180, 60): 2,       # VEGETATION\n","    (48, 130, 245): 3,      # WATER\n","    (255, 255, 255): 4,     # GROUND\n","    (200, 130, 0): 5        # CAR\n","}\n","\n","COLOR_PALETTE = np.array(list(COLOR_TO_CLASS.keys()), dtype=np.uint8)\n","COLOR_LOOKUP = {tuple(c): i for c, i in COLOR_TO_CLASS.items()}\n","\n","def decode_label_image(label_img):\n","    h, w, _ = label_img.shape\n","    label_map = np.zeros((h, w), dtype=np.uint8)\n","    for y in range(h):\n","        for x in range(w):\n","            pixel = tuple(label_img[y, x])\n","            if pixel not in COLOR_LOOKUP:\n","                raise ValueError(f\"‚ùå Unknown label colour {pixel} at ({y}, {x})\")\n","            label_map[y, x] = COLOR_LOOKUP[pixel]\n","    return label_map\n","\n","def train_model(input_type=\"rgb_elevation\", model_type=\"unet\", batch_size=8, epochs=10, tile_size=512):\n","    assert input_type in INPUT_TYPE_CONFIG, f\"Unknown input type: {input_type}\"\n","    num_channels = INPUT_TYPE_CONFIG[input_type][\"channels\"]\n","\n","    print(f\"\\nüîß Training {model_type.upper()} with input type: {input_type} ({num_channels} channels)\")\n","\n","    # --- Paths ---\n","    base_dir = \"/content/chipped_data\"\n","    train_images = os.path.join(base_dir, \"train\", \"images\")\n","    train_elev = os.path.join(base_dir, \"train\", \"elevations\")\n","    train_labels = os.path.join(base_dir, \"train\", \"labels\")\n","\n","    val_images = os.path.join(base_dir, \"val\", \"images\")\n","    val_elev = os.path.join(base_dir, \"val\", \"elevations\")\n","    val_labels = os.path.join(base_dir, \"val\", \"labels\")\n","\n","    # --- Files ---\n","    train_files = sorted([f for f in os.listdir(train_images) if f.endswith(\"-ortho.png\")])\n","    val_files = sorted([f for f in os.listdir(val_images) if f.endswith(\"-ortho.png\")])\n","\n","    # --- Data Generators (StreamingDataGenerator assumed loaded) ---\n","    train_gen = StreamingDataGenerator(train_images, train_elev, train_labels, batch_size=batch_size, input_type=input_type)\n","    val_gen = StreamingDataGenerator(val_images, val_elev, val_labels, batch_size=batch_size, input_type=input_type)\n","\n","    # --- Model Selection (build_unet must be loaded in global scope) ---\n","    if model_type == \"unet\":\n","        model = build_unet(input_shape=(tile_size, tile_size, num_channels), num_classes=6)\n","    elif model_type == \"segformer\":\n","        raise NotImplementedError(\"SegFormer support is coming soon.\")\n","    else:\n","        raise ValueError(f\"Unknown model_type: {model_type}\")\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","\n","    # --- Callbacks ---\n","    os.makedirs(\"checkpoints\", exist_ok=True)\n","    checkpoint = ModelCheckpoint(\"checkpoints/best_model.h5\", monitor='val_accuracy', save_best_only=True)\n","    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n","    nan_terminate = TerminateOnNaN()\n","\n","    class TimeLimitCallback(tf.keras.callbacks.Callback):\n","        def __init__(self, max_minutes=20):\n","            super().__init__()\n","            self.max_duration = max_minutes * 60\n","        def on_train_begin(self, logs=None):\n","            self.start_time = tf.timestamp()\n","        def on_epoch_end(self, epoch, logs=None):\n","            elapsed = tf.timestamp() - self.start_time\n","            if elapsed > self.max_duration:\n","                print(f\"‚è±Ô∏è Training time exceeded {self.max_duration // 60} minutes. Stopping early.\")\n","                self.model.stop_training = True\n","\n","    time_limit = TimeLimitCallback(max_minutes=20)\n","    callbacks = [checkpoint, early_stop, reduce_lr, nan_terminate, time_limit]\n","\n","    # --- Training ---\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=epochs,\n","        callbacks=callbacks\n","    )\n","\n","    # --- Evaluate ---\n","    val_imgs, val_lbls = next(iter(val_gen))\n","    pred = model.predict(val_imgs)\n","    pred_mask = np.argmax(pred[0], axis=-1)\n","    true_mask = np.argmax(val_lbls[0], axis=-1)\n","\n","    print(\"\\nüìä Evaluation Results:\")\n","    evaluate_predictions(pred_mask, true_mask)\n"]}]}