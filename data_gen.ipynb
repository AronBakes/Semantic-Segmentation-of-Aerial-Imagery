{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code should be in a cell in your main Colab notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Configuration ---\n",
    "# These are used by the functions below. Ensure they are defined in your notebook's global scope\n",
    "# before running this cell.\n",
    "# TILE_SIZE = 512\n",
    "# BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 400\n",
    "# COLOR_TO_CLASS = { ... }\n",
    "\n",
    "# Set image dimensions based on TILE_SIZE\n",
    "IMG_WIDTH = TILE_SIZE\n",
    "IMG_HEIGHT = TILE_SIZE\n",
    "\n",
    "\n",
    "# --- Helper Function to Decode Labels ---\n",
    "def decode_coloured_label(label_rgb: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Decodes an RGB label image into a single-channel integer class ID mask.\"\"\"\n",
    "    label_rgb = tf.cast(label_rgb, tf.uint8)\n",
    "    flat = tf.reshape(label_rgb, [-1, 3])\n",
    "    keys = tf.constant(list(COLOR_TO_CLASS.keys()), dtype=tf.uint8)\n",
    "    values = tf.constant(list(COLOR_TO_CLASS.values()), dtype=tf.int32)\n",
    "    match = tf.reduce_all(tf.equal(tf.expand_dims(flat, 1), keys), axis=2)\n",
    "    indices = tf.argmax(tf.cast(match, tf.int32), axis=1)\n",
    "    return tf.reshape(indices, tf.shape(label_rgb)[:2])\n",
    "\n",
    "\n",
    "# --- Core Data Loading and Preprocessing Functions ---\n",
    "\n",
    "def load_image_pair(label_path_tensor, image_path_tensor):\n",
    "    \"\"\"Loads a label and its corresponding real image from their file paths.\"\"\"\n",
    "    # This function is designed to be wrapped by tf.py_function, which handles tensor-to-string conversion\n",
    "    label = tf.io.read_file(label_path_tensor)\n",
    "    label = tf.image.decode_png(label, channels=3)\n",
    "\n",
    "    image = tf.io.read_file(image_path_tensor)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "\n",
    "    return label, image\n",
    "\n",
    "\n",
    "def normalize(label, image):\n",
    "    \"\"\"Normalizes images to the [-1, 1] range, required for GAN training.\"\"\"\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = (label / 127.5) - 1\n",
    "    image = (image / 127.5) - 1\n",
    "    return label, image\n",
    "\n",
    "\n",
    "def random_jitter(label, image):\n",
    "    \"\"\"Applies random jitter/augmentation: resizing and random cropping.\"\"\"\n",
    "    label = tf.image.resize(label, [IMG_HEIGHT + 30, IMG_WIDTH + 30],\n",
    "                           method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT + 30, IMG_WIDTH + 30],\n",
    "                           method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    stacked_image = tf.stack([label, image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "\n",
    "\n",
    "def random_mirror(label, image):\n",
    "    \"\"\"Applies random horizontal flip.\"\"\"\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        label = tf.image.flip_left_right(label)\n",
    "        image = tf.image.flip_left_right(image)\n",
    "    return label, image\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def parse_image_pair(label_path, image_path, augment=True):\n",
    "    \"\"\"The main parsing function for loading and augmenting an image-label pair.\"\"\"\n",
    "    label, image = tf.py_function(\n",
    "        func=load_image_pair, inp=[label_path, image_path], Tout=[tf.uint8, tf.uint8]\n",
    "    )\n",
    "\n",
    "    # Ensure shape is set after py_function\n",
    "    label.set_shape([None, None, 3])\n",
    "    image.set_shape([None, None, 3])\n",
    "\n",
    "    if augment:\n",
    "        label, image = random_jitter(label, image)\n",
    "        label, image = random_mirror(label, image)\n",
    "\n",
    "    label, image = normalize(label, image)\n",
    "\n",
    "    return label, image\n",
    "\n",
    "\n",
    "# --- Main Function to Build the Dataset ---\n",
    "\n",
    "def get_gan_dataset(chipped_data_dir, augment=True, shuffle=True):\n",
    "    \"\"\"\n",
    "    Builds and returns a tf.data.Dataset for training a GAN.\n",
    "    \"\"\"\n",
    "    label_dir = os.path.join(chipped_data_dir, 'train', 'labels')\n",
    "    image_dir = os.path.join(chipped_data_dir, 'train', 'images')\n",
    "\n",
    "    # Use the more robust path matching logic\n",
    "    all_label_paths = sorted(glob.glob(os.path.join(label_dir, '*-label.png')))\n",
    "    all_image_paths = sorted(glob.glob(os.path.join(image_dir, '*-ortho.png')))\n",
    "\n",
    "    image_map = {os.path.basename(p).replace('-ortho.png', ''): p for p in all_image_paths}\n",
    "\n",
    "    final_label_paths = []\n",
    "    final_image_paths = []\n",
    "\n",
    "    for label_path in all_label_paths:\n",
    "        tile_id = os.path.basename(label_path).replace('-label.png', '')\n",
    "        if tile_id in image_map:\n",
    "            final_label_paths.append(label_path)\n",
    "            final_image_paths.append(image_map[tile_id])\n",
    "\n",
    "    if not final_label_paths:\n",
    "        print(f\"Error: No matching image/label pairs found in {chipped_data_dir}.\")\n",
    "        return tf.data.Dataset.from_tensor_slices(([], []))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((final_label_paths, final_image_paths))\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    def map_func(label_path, image_path):\n",
    "        return parse_image_pair(label_path, image_path, augment=augment)\n",
    "\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
