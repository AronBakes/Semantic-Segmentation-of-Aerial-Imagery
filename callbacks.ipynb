{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback # Base class for custom Keras Callbacks\n",
    "from datetime import datetime # For TimeLimitCallback\n",
    "from sklearn.metrics import f1_score # For DynamicClassWeightUpdater\n",
    "\n",
    "# --- Global Constants (Ensure these are available in your main script or imported) ---\n",
    "# Assuming these are consistent across your project.\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Define `class_weights` as a tf.Variable *outside* the DynamicClassWeightUpdater class.\n",
    "# This variable will be dynamically updated by the callback and used by your loss function.\n",
    "class_weights = tf.Variable([1.0] * NUM_CLASSES, trainable=False, dtype=tf.float32, name=\"dynamic_class_weights\")\n",
    "\n",
    "\n",
    "# --- Custom Callbacks ---\n",
    "\n",
    "class LRScheduleLogger(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Callback to log the learning rate at the beginning of each epoch.\"\"\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Retrieves and prints the current learning rate.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        lr = self.model.optimizer._decayed_lr(tf.float32).numpy()\n",
    "        print(f\"🔁 Epoch {epoch+1}: Learning Rate = {lr:.6e}\")\n",
    "\n",
    "\n",
    "class TimeLimitCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to stop training early if a specified time limit (in minutes) is exceeded.\n",
    "    This prevents runs from consuming excessive computational resources.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_minutes: float = 20):\n",
    "        \"\"\"\n",
    "        Initializes the TimeLimitCallback.\n",
    "\n",
    "        Args:\n",
    "            max_minutes (float): The maximum number of minutes training is allowed to run.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_duration = max_minutes * 60 # Convert minutes to seconds\n",
    "        self.start_time = None # Will store the timestamp when training begins\n",
    "\n",
    "    def on_train_begin(self, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the beginning of training. Records the training start time using tf.timestamp().\n",
    "        \"\"\"\n",
    "        self.start_time = tf.timestamp()\n",
    "        print(f\"⏰ Training started. Maximum duration set to {self.max_duration / 60:.1f} minutes.\")\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Checks if the elapsed time exceeds the maximum duration.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if self.start_time is None: # Safety check\n",
    "            return\n",
    "\n",
    "        elapsed = tf.timestamp() - self.start_time # Calculate elapsed time in seconds\n",
    "        if elapsed > self.max_duration:\n",
    "            print(f\"\\nTraining time exceeded {self.max_duration / 60:.1f} minutes ({elapsed:.2f} seconds). Stopping early at epoch {epoch + 1}.\")\n",
    "            self.model.stop_training = True # Signal Keras to stop training\n",
    "\n",
    "\n",
    "class StepTimer(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to measure and report the average time taken per training step (batch).\n",
    "    Provides insight into training throughput.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the start of training. Initializes variables to track total time and steps.\n",
    "        \"\"\"\n",
    "        self.total_time = 0.0\n",
    "        self.total_steps = 0\n",
    "        self.start_time_batch = None # Will store the start time for the current batch\n",
    "\n",
    "    def on_train_batch_begin(self, batch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the beginning of each training batch. Records the start time of the batch.\n",
    "\n",
    "        Args:\n",
    "            batch (int): The current batch index.\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.start_time_batch = tf.timestamp()\n",
    "\n",
    "    def on_train_batch_end(self, batch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each training batch. Calculates the elapsed time for the batch\n",
    "        and accumulates it.\n",
    "\n",
    "        Args:\n",
    "            batch (int): The current batch index.\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if self.start_time_batch is None: # Safety check\n",
    "            return\n",
    "            \n",
    "        elapsed = tf.timestamp() - self.start_time_batch\n",
    "        self.total_time += elapsed.numpy() # Convert to NumPy float for accumulation\n",
    "        self.total_steps += 1\n",
    "\n",
    "    def on_train_end(self, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of training. Calculates and prints the average time per step.\n",
    "\n",
    "        Args:\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if self.total_steps > 0:\n",
    "            avg_step_time = self.total_time / self.total_steps\n",
    "            print(f\"\\nAverage training step time over {self.total_steps} steps: {avg_step_time:.4f} sec\")\n",
    "        else:\n",
    "            print(\"No training steps completed for average step time calculation.\")\n",
    "\n",
    "\n",
    "class DynamicClassWeightUpdater(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to dynamically update class weights during training based on\n",
    "    per-class performance (F1-score or IoU) on the validation set.\n",
    "    Weights are updated every `update_every` epochs, giving higher weights to classes\n",
    "    that perform poorly. It requires `class_weights` to be a `tf.Variable`\n",
    "    defined in a scope accessible by this callback (e.g., globally).\n",
    "    \"\"\"\n",
    "    def __init__(self, val_data: tf.data.Dataset, update_every: int = 5, \n",
    "                 target: str = 'f1', ignore_class: int = None):\n",
    "        \"\"\"\n",
    "        Initializes the DynamicClassWeightUpdater callback.\n",
    "\n",
    "        Args:\n",
    "            val_data (tf.data.Dataset): The TensorFlow Dataset to use for validation metrics.\n",
    "            update_every (int): How often (in epochs) to update the class weights.\n",
    "            target (str): The metric to target for weighting ('f1' or 'iou').\n",
    "            ignore_class (int, optional): Class ID to ignore (set its weight to 0.0) when calculating\n",
    "                                          and applying new weights. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.val_data = val_data\n",
    "        self.update_every = update_every\n",
    "        self.target = target.lower() # Ensure target is lowercase for robust comparison\n",
    "        self.ignore_class = ignore_class\n",
    "        self.num_classes = NUM_CLASSES # Use global NUM_CLASSES for consistency\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Method called at the end of each epoch. Updates weights if `epoch + 1` is a multiple\n",
    "        of `update_every`.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Only update weights if the current epoch is a multiple of `update_every`\n",
    "        if (epoch + 1) % self.update_every != 0:\n",
    "            return\n",
    "\n",
    "        print(f\"\\n📊 Epoch {epoch+1}: Computing per-class metrics for dynamic weight update...\")\n",
    "        \n",
    "        y_true_all = [] # List to collect all true class labels (flattened) from validation set\n",
    "        y_pred_all = [] # List to collect all predicted class labels (flattened) from validation set\n",
    "\n",
    "        # Iterate over a limited number of validation batches to compute per-class metrics\n",
    "        # Using .take(max_batches_for_metrics) can prevent long evaluation times if val_data is large.\n",
    "        # For full accuracy, iterate over the entire self.val_data.\n",
    "        # Example: for x_batch, y_batch in self.val_data.take(50): # limit to 50 batches\n",
    "        for x_batch, y_batch in self.val_data:\n",
    "            # Predict with verbose=0 to suppress per-batch output during validation prediction\n",
    "            preds = self.model.predict(x_batch, verbose=0) \n",
    "            \n",
    "            # Convert one-hot encoded true labels to class IDs (flattened)\n",
    "            y_true = tf.argmax(y_batch, axis=-1).numpy().flatten()\n",
    "            # Convert softmax predictions to class IDs (flattened)\n",
    "            y_pred = tf.argmax(preds, axis=-1).numpy().flatten()\n",
    "\n",
    "            y_true_all.extend(y_true)\n",
    "            y_pred_all.extend(y_pred)\n",
    "\n",
    "        # Convert collected lists to NumPy arrays for scikit-learn metric calculations\n",
    "        y_true_all = np.array(y_true_all)\n",
    "        y_pred_all = np.array(y_pred_all)\n",
    "\n",
    "        new_weights = [] # List to store the newly calculated weights\n",
    "\n",
    "        # Calculate weight for each class based on target metric ('f1' or 'iou')\n",
    "        for i in range(self.num_classes):\n",
    "            if self.ignore_class is not None and i == self.ignore_class:\n",
    "                new_weights.append(0.0) # Explicitly set weight to 0.0 for the ignored class\n",
    "                continue\n",
    "\n",
    "            metric_value = 0.0 # Default value if class not present or union is zero\n",
    "            if self.target == 'f1':\n",
    "                # Calculate F1-score for the current class\n",
    "                # zero_division=0 means F1 is 0 if no true samples for class or no predictions\n",
    "                metric_value = f1_score(y_true_all == i, y_pred_all == i, zero_division=0)\n",
    "            elif self.target == 'iou':\n",
    "                # Manually calculate IoU for the current class\n",
    "                intersection = np.logical_and(y_true_all == i, y_pred_all == i).sum()\n",
    "                union = (y_true_all == i).sum() + (y_pred_all == i).sum() - intersection\n",
    "                metric_value = intersection / union if union > 0 else 0.0 # Avoid division by zero\n",
    "            else:\n",
    "                print(f\"Warning: Unknown target metric '{self.target}'. Using default weight 1.0.\")\n",
    "                metric_value = 1.0 # Fallback for unknown target\n",
    "\n",
    "            # Weight is inversely proportional to the metric value.\n",
    "            # Add a small epsilon to the denominator to prevent division by zero if metric_value is 0.\n",
    "            weight = 1.0 / (metric_value + tf.keras.backend.epsilon()) \n",
    "            new_weights.append(weight)\n",
    "\n",
    "        # Normalize weights to prevent extremely large values and scale them\n",
    "        new_weights = np.array(new_weights, dtype=tf.float32)\n",
    "        # Normalize by the maximum weight to scale values between 0 and 1 (or max_weight)\n",
    "        # Add epsilon to denominator to prevent division by zero if all weights are effectively 0\n",
    "        new_weights = new_weights / (tf.reduce_max(new_weights) + tf.keras.backend.epsilon()) \n",
    "\n",
    "        # Access the global class_weights tf.Variable and update its value\n",
    "        # This is CRITICAL for the dynamic update to affect the loss function defined in your main pipeline.\n",
    "        global class_weights\n",
    "        class_weights.assign(new_weights)\n",
    "        print(f\"\\nEpoch {epoch+1}: Dynamically updated class weights: {new_weights.numpy()}\\n\")\n",
    "\n",
    "\n",
    "class DualCheckpointSaver(Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to save model checkpoints to two locations (local and Google Drive, if mounted)\n",
    "    when the monitored metric improves.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model: tf.keras.Model, monitor: str = 'val_iou_score', mode: str = 'max',\n",
    "                 out_dir: str = \"checkpoints\", drive_dir: str = \"/content/drive/MyDrive/checkpoints\"):\n",
    "        \"\"\"\n",
    "        Initializes the DualCheckpointSaver.\n",
    "\n",
    "        Args:\n",
    "            base_model (tf.keras.Model): The model to save. If your main model has a separate\n",
    "                                        base_model (e.g., in a flexible U-Net), pass that.\n",
    "                                        Otherwise, pass the main `model` instance.\n",
    "            monitor (str): The metric to monitor for improvement (e.g., 'val_loss', 'val_iou_score').\n",
    "            mode (str): One of {'auto', 'min', 'max'}. In 'min' mode, training will stop when the\n",
    "                        quantity monitored has stopped decreasing; in 'max' mode it will stop when\n",
    "                        the quantity monitored has stopped increasing.\n",
    "            out_dir (str): Local directory path to save checkpoints.\n",
    "            drive_dir (str): Google Drive directory path to save checkpoints (assumes mounted).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.out_dir = out_dir\n",
    "        self.drive_dir = drive_dir\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Unique timestamp for model filenames\n",
    "        self.best_value = -float('inf') if mode == 'max' else float('inf') # Initialize best value based on mode\n",
    "\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "        # Check if Google Drive path is accessible before creating\n",
    "        if os.path.exists(os.path.dirname(self.drive_dir)): # Check parent directory exists\n",
    "            os.makedirs(self.drive_dir, exist_ok=True)\n",
    "        else:\n",
    "            print(f\"Warning: Google Drive path '{self.drive_dir}' not accessible. Skipping Drive checkpoints.\")\n",
    "            self.drive_dir = None # Disable saving to Drive\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Checks if the monitored metric has improved\n",
    "        and saves the model if it has.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if logs is None or self.monitor not in logs:\n",
    "            print(f\"Warning: Monitored metric '{self.monitor}' not found in logs for epoch {epoch+1}. Skipping checkpoint.\")\n",
    "            return\n",
    "\n",
    "        current = logs[self.monitor] # Current value of the monitored metric\n",
    "        # Check for improvement based on mode\n",
    "        improved = (current > self.best_value) if self.mode == 'max' else (current < self.best_value)\n",
    "\n",
    "        if improved:\n",
    "            self.best_value = current # Update best value\n",
    "            epoch_num = epoch + 1\n",
    "            # Generate model filename with timestamp and epoch number\n",
    "            model_name = f\"{self.base_model.name}_{self.timestamp}_epoch{epoch_num:03d}_{self.monitor}{current:.4f}.keras\"\n",
    "\n",
    "            local_path = os.path.join(self.out_dir, model_name)\n",
    "            \n",
    "            # Save to local directory\n",
    "            self.base_model.save(local_path, save_format='tf') # Use save_format='tf' for Keras SavedModel format\n",
    "            print(f\"Saved improved model locally: {local_path}\")\n",
    "\n",
    "            # Save to Google Drive if accessible\n",
    "            if self.drive_dir:\n",
    "                drive_path = os.path.join(self.drive_dir, model_name)\n",
    "                # Use tf.keras.models.save_model for consistency if base_model is a Model\n",
    "                tf.keras.models.save_model(self.base_model, drive_path, save_format='tf')\n",
    "                print(f\"Saved improved model to Google Drive: {drive_path}\")\n",
    "            \n",
    "            print(f\"Model improved at epoch {epoch_num} with {self.monitor}: {current:.4f}\")\n",
    "        else:\n",
    "            print(f\"⏭ Epoch {epoch+1}: {self.monitor} did not improve ({current:.4f}). Best: {self.best_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Additional Callbacks for Dataset Analysis, Comes with Massive Overhead (Use with Caution) ---\n",
    "\n",
    "class DistributionLogger(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to log and visualize the class distribution of training (or validation) data\n",
    "    at the end of each epoch. It can help monitor dataset balance and augmentation effectiveness.\n",
    "    This callback adds significant overhead if max_batches is large.\n",
    "    \"\"\"\n",
    "    def __init__(self, generator: tf.data.Dataset, name: str = \"Training\", max_batches: int = 16):\n",
    "        \"\"\"\n",
    "        Initializes the DistributionLogger.\n",
    "\n",
    "        Args:\n",
    "            generator (tf.data.Dataset): The TensorFlow Dataset to analyze.\n",
    "            name (str): A descriptive name for the generator (e.g., \"Training\", \"Validation\").\n",
    "            max_batches (int): The maximum number of batches to process for distribution analysis\n",
    "                               in each epoch (to control overhead).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.name = name\n",
    "        self.max_batches = max_batches\n",
    "        self.cumulative_class_counts = defaultdict(int) # To track counts across all epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Collects and logs the class distribution\n",
    "        for a subset of the generator's data.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        batch_class_counts = defaultdict(int) # To track counts for the current epoch's analyzed batches\n",
    "        batches_seen = 0\n",
    "\n",
    "        # Iterate over a limited number of batches to compute the distribution\n",
    "        for _, batch_labels in self.generator.take(self.max_batches):\n",
    "            # Convert one-hot labels to class IDs\n",
    "            batch_preds_ids = tf.argmax(batch_labels, axis=-1).numpy()\n",
    "            # Get unique class IDs and their counts in the current batch\n",
    "            unique, counts = np.unique(batch_preds_ids, return_counts=True)\n",
    "\n",
    "            for u, c in zip(unique, counts):\n",
    "                batch_class_counts[u] += c\n",
    "                self.cumulative_class_counts[u] += c # Accumulate for cumulative report\n",
    "\n",
    "            batches_seen += 1\n",
    "\n",
    "        total_pixels_in_sample = sum(batch_class_counts.values())\n",
    "        # The number of images processed might be less than max_batches * batch_size if generator ends early\n",
    "        # total_images = batches_seen * self.generator.element_spec[0].shape[0] # Not reliable if batch_size is None or last batch smaller\n",
    "\n",
    "        if total_pixels_in_sample > 0:\n",
    "            print(f\"\\n{self.name} Class Distribution Sampled After Epoch {epoch + 1}:\")\n",
    "            for cls_id in sorted(batch_class_counts.keys()):\n",
    "                count = batch_class_counts[cls_id]\n",
    "                percent = 100.0 * count / total_pixels_in_sample\n",
    "                # Ensure class_id is within NUM_CLASSES bounds\n",
    "                class_name = CLASS_NAMES[cls_id] if cls_id < NUM_CLASSES else f\"Class {cls_id}\"\n",
    "                print(f\"  Class {cls_id} ({class_name}): {count:,} px ({percent:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"\\n{self.name} Class Distribution: No pixels found in sampled batches for Epoch {epoch + 1}.\")\n",
    "\n",
    "    def on_train_end(self, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of training. Prints the final cumulative class distribution\n",
    "        across all epochs. Also plots the distribution.\n",
    "        \"\"\"\n",
    "        total_pixels_cumulative = sum(self.cumulative_class_counts.values())\n",
    "\n",
    "        if total_pixels_cumulative > 0:\n",
    "            print(\"\\nFinal Cumulative Training Class Distribution:\")\n",
    "            print(f\"Total pixels analyzed: {total_pixels_cumulative:,} px\")\n",
    "            for cls_id in sorted(self.cumulative_class_counts.keys()):\n",
    "                count = self.cumulative_class_counts[cls_id]\n",
    "                percent = 100.0 * count / total_pixels_cumulative\n",
    "                class_name = CLASS_NAMES[cls_id] if cls_id < NUM_CLASSES else f\"Class {cls_id}\"\n",
    "                print(f\"  Class {cls_id} ({class_name}): {count:,} px ({percent:.2f}%)\")\n",
    "            \n",
    "            # Plot the cumulative distribution\n",
    "            self._plot_cumulative_distribution()\n",
    "        else:\n",
    "            print(\"No cumulative pixels were recorded for distribution analysis.\")\n",
    "\n",
    "    def _plot_cumulative_distribution(self):\n",
    "        \"\"\"Helper function to plot the cumulative class distribution.\"\"\"\n",
    "        class_ids = sorted(self.cumulative_class_counts.keys())\n",
    "        pixel_counts = [self.cumulative_class_counts[cid] for cid in class_ids]\n",
    "        \n",
    "        total_pixels = sum(pixel_counts)\n",
    "        if total_pixels == 0:\n",
    "            print(\"Cannot plot distribution: No pixels recorded.\")\n",
    "            return\n",
    "\n",
    "        pixel_props = [count / total_pixels for count in pixel_counts]\n",
    "        \n",
    "        class_labels = [CLASS_NAMES[cid] if cid < NUM_CLASSES else f\"Class {cid}\" for cid in class_ids]\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        bars = plt.bar(class_labels, pixel_props, edgecolor='black')\n",
    "        plt.title(f\"Cumulative Class Distribution ({self.name} Data)\")\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Proportion\")\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "        for bar, prop in zip(bars, pixel_props):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f\"{prop:.2%}\",\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "class ValidationPredictionLogger(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Keras Callback to visualize and save example predictions on the validation set\n",
    "    at specified intervals (e.g., every N epochs). This helps monitor the model's\n",
    "    qualitative performance during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, val_gen: tf.data.Dataset, user_model: tf.keras.Model, \n",
    "                 out_dir: str = \"/content/figs\", max_batches_to_process: int = 1,\n",
    "                 num_samples_to_plot: int = 8, plot_every_n_epochs: int = 8):\n",
    "        \"\"\"\n",
    "        Initializes the ValidationPredictionLogger.\n",
    "\n",
    "        Args:\n",
    "            val_gen (tf.data.Dataset): The validation data generator.\n",
    "            user_model (tf.keras.Model): The model being trained (needed for predictions).\n",
    "            out_dir (str): Directory to save the visualization plots.\n",
    "            max_batches_to_process (int): Max number of validation batches to process for predictions.\n",
    "            num_samples_to_plot (int): Number of (RGB, GT, Pred) samples to display in the plot.\n",
    "                                       This should typically be <= (max_batches_to_process * batch_size of val_gen).\n",
    "            plot_every_n_epochs (int): The interval (in epochs) at which to generate plots.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.val_gen = val_gen\n",
    "        self.user_model = user_model # Reference to the model itself\n",
    "        self.out_dir = out_dir\n",
    "        self.max_batches_to_process = max_batches_to_process\n",
    "        self.num_samples_to_plot = num_samples_to_plot\n",
    "        self.plot_every_n_epochs = plot_every_n_epochs\n",
    "\n",
    "        # Define ignore color and class_to_color mapping (ensure consistency with main script)\n",
    "        self.ignore_color = (255, 0, 255) # Magenta for ignored pixels\n",
    "        self.class_to_color = {\n",
    "            0: (230, 25, 75),    # Building\n",
    "            1: (145, 30, 180),   # Clutter\n",
    "            2: (60, 180, 75),    # Vegetation\n",
    "            3: (245, 130, 48),   # Water\n",
    "            4: (255, 255, 255),  # Background\n",
    "            5: (0, 130, 200),    # Car\n",
    "        }\n",
    "        # Create output directory for plots\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Generates and saves a plot of validation predictions\n",
    "        if the current epoch is a multiple of `plot_every_n_epochs`.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number (0-indexed).\n",
    "            logs (dict, optional): Dictionary of logs. Defaults to None.\n",
    "        \"\"\"\n",
    "        if (epoch + 1) % self.plot_every_n_epochs != 0:\n",
    "            return\n",
    "\n",
    "        print(f\"\\n🎨 Epoch {epoch+1}: Generating validation prediction visualization...\")\n",
    "\n",
    "        all_batch_images = []\n",
    "        all_batch_labels = []\n",
    "\n",
    "        batches_seen = 0\n",
    "        # Iterate over a limited number of validation batches\n",
    "        for batch_images, batch_labels in self.val_gen.take(self.max_batches_to_process):\n",
    "            all_batch_images.append(batch_images.numpy())\n",
    "            all_batch_labels.append(batch_labels.numpy())\n",
    "            batches_seen += 1\n",
    "            if batches_seen >= self.max_batches_to_process:\n",
    "                break\n",
    "        \n",
    "        # Concatenate collected batches into single arrays\n",
    "        if not all_batch_images:\n",
    "            print(\"Warning: No validation batches found for visualization.\")\n",
    "            return\n",
    "\n",
    "        full_images = np.concatenate(all_batch_images, axis=0)\n",
    "        full_labels = np.concatenate(all_batch_labels, axis=0)\n",
    "\n",
    "        # Get predictions for the collected samples\n",
    "        preds = self.user_model.predict(full_images, verbose=0)\n",
    "        preds_argmax = np.argmax(preds, axis=-1) # Predicted class IDs\n",
    "        true_argmax = np.argmax(full_labels, axis=-1) # True class IDs\n",
    "\n",
    "        # Determine number of samples to plot (min of requested, actual collected, or max 8 as per original code)\n",
    "        num_samples_to_display = min(self.num_samples_to_plot, len(full_images))\n",
    "        \n",
    "        # Grid layout for plots: 4 rows, 3 columns per sample (Input, GT, Pred)\n",
    "        # Total columns = 3 (for Input, GT, Pred)\n",
    "        # Total rows = num_samples_to_display\n",
    "        fig, axs = plt.subplots(num_samples_to_display, 3, figsize=(18, num_samples_to_display * 4))\n",
    "\n",
    "        # Handle cases where axs might be 1D (e.g., if num_samples_to_display == 1)\n",
    "        if num_samples_to_display == 1:\n",
    "            axs = np.array([axs]) # Make it 2D for consistent indexing\n",
    "\n",
    "        # Iterate through samples and plot\n",
    "        for i in range(num_samples_to_display):\n",
    "            # Extract RGB image (scale from [0,1] to [0,255] and cast to uint8)\n",
    "            rgb = (full_images[i] * 255).astype(np.uint8)\n",
    "            h, w = true_argmax[i].shape\n",
    "\n",
    "            # Create colored versions of true and predicted masks\n",
    "            true_rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            pred_rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "            for cid, col_rgb in self.class_to_color.items():\n",
    "                true_rgb_mask[true_argmax[i] == cid] = np.array(col_rgb, dtype=np.uint8)\n",
    "                pred_rgb_mask[preds_argmax[i] == cid] = np.array(col_rgb, dtype=np.uint8)\n",
    "\n",
    "            # Apply ignore color (magenta) to ignored regions in both masks\n",
    "            # Based on the original one-hot encoded labels\n",
    "            ignore_mask_bool = np.all(full_labels[i] == 0, axis=-1)\n",
    "            true_rgb_mask[ignore_mask_bool] = np.array(self.ignore_color, dtype=np.uint8)\n",
    "            pred_rgb_mask[ignore_mask_bool] = np.array(self.ignore_color, dtype=np.uint8)\n",
    "\n",
    "            # Plotting on the subplots\n",
    "            axs[i, 0].imshow(rgb)\n",
    "            axs[i, 0].set_title(\"Input\", fontsize=10)\n",
    "            axs[i, 0].axis(\"off\")\n",
    "\n",
    "            axs[i, 1].imshow(true_rgb_mask)\n",
    "            axs[i, 1].set_title(\"Ground Truth\", fontsize=10)\n",
    "            axs[i, 1].axis(\"off\")\n",
    "\n",
    "            axs[i, 2].imshow(pred_rgb_mask)\n",
    "            axs[i, 2].set_title(\"Prediction\", fontsize=10)\n",
    "            axs[i, 2].axis(\"off\")\n",
    "\n",
    "        # Adjust layout and save the figure\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Validation Predictions After Epoch {epoch + 1}\", y=1.02, fontsize=16)\n",
    "        save_path = os.path.join(self.out_dir, f\"val_preds_epoch{epoch+1:03d}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "        plt.close(fig) # Explicitly close the figure to free memory\n",
    "        print(f\"Validation prediction plot saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
