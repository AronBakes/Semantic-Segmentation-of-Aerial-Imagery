{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Callbacks ---\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "\n",
    "\n",
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy()\n",
    "        print(f\"Learning Rate at epoch {epoch + 1}: {lr:.6f}\")\n",
    "\n",
    "class TimeLimitCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, max_minutes=20):\n",
    "        super().__init__()\n",
    "        self.max_duration = max_minutes * 60\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = tf.timestamp()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed = tf.timestamp() - self.start_time\n",
    "        if elapsed > self.max_duration:\n",
    "            print(f\"\\n Training time exceeded {self.max_duration // 60} minutes. Stopping early.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "class StepTimer(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.total_time = 0.0\n",
    "        self.total_steps = 0\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.start_time = tf.timestamp()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        elapsed = tf.timestamp() - self.start_time\n",
    "        self.total_time += elapsed\n",
    "        self.total_steps += 1\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        avg_step_time = self.total_time / self.total_steps\n",
    "        print(f\"ðŸ•’ Average training step time: {avg_step_time:.4f} sec\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DistributionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, generator, name=\"Training\", max_batches=16, visualise_samples=2):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.name = name\n",
    "        self.max_batches = max_batches\n",
    "        self.visualise_samples = visualise_samples\n",
    "        self.cumulative_class_counts = defaultdict(int)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        batch_class_counts = defaultdict(int)\n",
    "        all_samples = []\n",
    "        batches_seen = 0\n",
    "\n",
    "        for batch_images, batch_labels in self.generator:\n",
    "            if batches_seen >= self.max_batches:\n",
    "                break\n",
    "\n",
    "            batch_preds = np.argmax(batch_labels, axis=-1)\n",
    "            unique, counts = np.unique(batch_preds, return_counts=True)\n",
    "\n",
    "            for u, c in zip(unique, counts):\n",
    "                batch_class_counts[u] += c\n",
    "                self.cumulative_class_counts[u] += c\n",
    "\n",
    "            for img, label in zip(batch_images, batch_preds):\n",
    "                all_samples.append((img, label))\n",
    "\n",
    "            batches_seen += 1\n",
    "\n",
    "        total_pixels = sum(batch_class_counts.values())\n",
    "        total_images = batches_seen * self.generator.batch_size\n",
    "\n",
    "        print(f\"{self.name} Distribution After Epoch {epoch + 1} ({total_images:,} images):\")\n",
    "        for cls in sorted(batch_class_counts):\n",
    "            count = batch_class_counts[cls]\n",
    "            percent = 100.0 * count / total_pixels\n",
    "            print(f\"  Class {cls} ({CLASS_NAMES[cls]}): {count:,} px ({percent:.2f}%)\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        total_pixels = sum(self.cumulative_class_counts.values())\n",
    "        print(\"Final Cumulative Training Class Distribution:\")\n",
    "        print(f\"Total pixels: {total_pixels:,} px\")\n",
    "        for cls in sorted(self.cumulative_class_counts):\n",
    "            count = self.cumulative_class_counts[cls]\n",
    "            percent = 100.0 * count / total_pixels\n",
    "            print(f\"  Class {cls} ({CLASS_NAMES[cls]}): {count:,} px ({percent:.2f}%)\")\n",
    "\n",
    "        plot_class_distribution(self.cumulative_class_counts)\n",
    "\n",
    "\n",
    "\n",
    "class ValidationPredictionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_gen, user_model, out_dir=\"/content/figs\", max_batches=1):\n",
    "        super().__init__()\n",
    "        self.val_gen = val_gen\n",
    "        self.user_model = user_model\n",
    "        self.max_batches = max_batches\n",
    "        self.out_dir = out_dir\n",
    "        self.ignore_color = (255, 0, 255)\n",
    "        self.class_to_color = {\n",
    "            0: (230, 25, 75),    # Building\n",
    "            1: (145, 30, 180),   # Clutter\n",
    "            2: (60, 180, 75),    # Vegetation\n",
    "            3: (245, 130, 48),   # Water\n",
    "            4: (255, 255, 255),  # Background\n",
    "            5: (0, 130, 200),    # Car\n",
    "        }\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 8 != 0:\n",
    "            return\n",
    "\n",
    "        batches_seen = 0\n",
    "        for batch_images, batch_labels in self.val_gen:\n",
    "            if batches_seen >= self.max_batches:\n",
    "                break\n",
    "\n",
    "            preds = self.user_model.predict(batch_images)\n",
    "            preds_argmax = np.argmax(preds, axis=-1)\n",
    "            true_argmax = np.argmax(batch_labels.numpy(), axis=-1)\n",
    "\n",
    "            num_samples = min(8, len(batch_images))\n",
    "            fig, axs = plt.subplots(4, 6, figsize=(18, 12))\n",
    "\n",
    "            for i in range(num_samples):\n",
    "                row = i // 2\n",
    "                col = (i % 2) * 3\n",
    "\n",
    "                rgb = (batch_images[i].numpy() * 255).astype(np.uint8)\n",
    "                h, w = true_argmax[i].shape\n",
    "\n",
    "                true_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "                pred_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "                for cid, col_rgb in self.class_to_color.items():\n",
    "                    true_rgb[true_argmax[i] == cid] = col_rgb\n",
    "                    pred_rgb[preds_argmax[i] == cid] = col_rgb\n",
    "\n",
    "                # Convert batch_labels[i] to numpy if not already\n",
    "                mask = batch_labels[i].numpy()\n",
    "                ignore_mask = np.all(mask == 0, axis=-1)\n",
    "                true_rgb[ignore_mask] = self.ignore_color\n",
    "                pred_rgb[ignore_mask] = self.ignore_color\n",
    "\n",
    "                axs[row, col].imshow(rgb)\n",
    "                axs[row, col].set_title(\"Input\")\n",
    "                axs[row, col].axis(\"off\")\n",
    "\n",
    "                axs[row, col + 1].imshow(true_rgb)\n",
    "                axs[row, col + 1].set_title(\"Ground Truth\")\n",
    "                axs[row, col + 1].axis(\"off\")\n",
    "\n",
    "                axs[row, col + 2].imshow(pred_rgb)\n",
    "                axs[row, col + 2].set_title(\"Prediction\")\n",
    "                axs[row, col + 2].axis(\"off\")\n",
    "\n",
    "            os.makedirs(self.out_dir, exist_ok=True)\n",
    "            save_path = os.path.join(self.out_dir, f\"val_preds_epoch{epoch+1:03d}.png\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f\"Validation Predictions After Epoch {epoch + 1}\", y=1.02)\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "\n",
    "            batches_seen += 1\n",
    "\n",
    "\n",
    "class DualCheckpointSaver(Callback):\n",
    "    def __init__(self, base_model, monitor='val_iou_score', mode='max',\n",
    "                 out_dir=\"checkpoints\", drive_dir=\"/content/drive/MyDrive/checkpoints\"):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.out_dir = out_dir\n",
    "        self.drive_dir = drive_dir\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.best_value = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "        os.makedirs(self.drive_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None or self.monitor not in logs:\n",
    "            print(f\"{self.monitor} not found in logs. Skipping checkpoint.\")\n",
    "            return\n",
    "\n",
    "        current = logs[self.monitor]\n",
    "        improved = (current > self.best_value) if self.mode == 'max' else (current < self.best_value)\n",
    "\n",
    "        if improved:\n",
    "            self.best_value = current\n",
    "            epoch_num = epoch + 1\n",
    "            model_name = f\"{self.base_model.name}_{self.timestamp}_epoch{epoch_num:03d}.keras\"\n",
    "\n",
    "            local_path = os.path.join(self.out_dir, model_name)\n",
    "            drive_path = os.path.join(self.drive_dir, model_name)\n",
    "\n",
    "            self.base_model.save(local_path)\n",
    "            tf.keras.models.save_model(self.base_model, drive_path)\n",
    "            print(f\"âœ… Saved improved model at epoch {epoch_num} with {self.monitor}: {current:.4f}\")\n",
    "        else:\n",
    "            print(f\"â­Epoch {epoch+1}: {self.monitor} did not improve ({current:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
