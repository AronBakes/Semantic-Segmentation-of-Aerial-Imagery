{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_gan.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "\n",
    "# The number of output channels for the generator is 3 (for RGB)\n",
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    \"\"\"Creates a downsampling block used in the Generator's encoder.\"\"\"\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                      kernel_initializer=initializer, use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(layers.BatchNormalization())\n",
    "    result.add(layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    \"\"\"Creates an upsampling block used in the Generator's decoder.\"\"\"\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                               kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(layers.BatchNormalization())\n",
    "    if apply_dropout:\n",
    "        result.add(layers.Dropout(0.5))\n",
    "    result.add(layers.ReLU())\n",
    "    return result\n",
    "\n",
    "def Generator(input_shape=(TILE_SIZE, TILE_SIZE, 3)):\n",
    "    \"\"\"\n",
    "    Builds the Generator model based on a modified U-Net architecture.\n",
    "    It takes a 3-channel label map and outputs a 3-channel RGB image.\n",
    "    \"\"\"\n",
    "    # The input is a label map, but it's represented as a 3-channel image\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder (Downsampling path)\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),  # (bs, 256, 256, 64)\n",
    "        downsample(128, 4),  # (bs, 128, 128, 128)\n",
    "        downsample(256, 4),  # (bs, 64, 64, 256)\n",
    "        downsample(512, 4),  # (bs, 32, 32, 512)\n",
    "        downsample(512, 4),  # (bs, 16, 16, 512)\n",
    "        downsample(512, 4),  # (bs, 8, 8, 512)\n",
    "        downsample(512, 4),  # (bs, 4, 4, 512)\n",
    "        downsample(512, 4),  # (bs, 2, 2, 512)\n",
    "    ]\n",
    "\n",
    "    # Decoder (Upsampling path)\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 16, 16, 1024)\n",
    "        upsample(512, 4),  # (bs, 32, 32, 1024)\n",
    "        upsample(256, 4),  # (bs, 64, 64, 512)\n",
    "        upsample(128, 4),  # (bs, 128, 128, 256)\n",
    "        upsample(64, 4),   # (bs, 256, 256, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                  strides=2,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  activation='tanh')  # tanh activation outputs in [-1, 1] range\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "def Discriminator(input_shape=(TILE_SIZE, TILE_SIZE, 3), target_shape=(TILE_SIZE, TILE_SIZE, 3)):\n",
    "    \"\"\"\n",
    "    Builds the PatchGAN Discriminator model.\n",
    "    It takes both the input label map and the real/fake image as input.\n",
    "    \"\"\"\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    # The discriminator receives two inputs\n",
    "    inp = Input(shape=input_shape, name='input_image')\n",
    "    tar = Input(shape=target_shape, name='target_image')\n",
    "\n",
    "    x = layers.concatenate([inp, tar])  # (bs, 512, 512, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)  # (bs, 256, 256, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (bs, 128, 128, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (bs, 64, 64, 256)\n",
    "\n",
    "    zero_pad1 = layers.ZeroPadding2D()(down3)  # (bs, 66, 66, 256)\n",
    "    conv = layers.Conv2D(512, 4, strides=1,\n",
    "                         kernel_initializer=initializer,\n",
    "                         use_bias=False)(zero_pad1)  # (bs, 63, 63, 512)\n",
    "\n",
    "    batchnorm1 = layers.BatchNormalization()(conv)\n",
    "    leaky_relu = layers.LeakyReLU()(batchnorm1)\n",
    "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)  # (bs, 65, 65, 512)\n",
    "\n",
    "    # This is the final output patch\n",
    "    last = layers.Conv2D(1, 4, strides=1,\n",
    "                         kernel_initializer=initializer)(zero_pad2)  # (bs, 62, 62, 1)\n",
    "\n",
    "    return Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "# --- Example Usage (for testing the script directly) ---\n",
    "if __name__ == '__main__':\n",
    "    # This block will only run if you execute this script directly\n",
    "    if 'TILE_SIZE' not in globals():\n",
    "        TILE_SIZE = 512\n",
    "\n",
    "    print(\"--- Building Generator ---\")\n",
    "    generator = Generator()\n",
    "    generator.summary()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "    print(\"--- Building Discriminator ---\")\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
