{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQjE6nMdo_Bh",
        "outputId": "5f462c27-98bb-41c4-c5db-90428f5c3a0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Chipping Scenes: 100%|██████████| 55/55 [17:53<00:00, 19.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "--- CHIPPING COMPLETE: FINAL SUMMARY ---\n",
            "========================================\n",
            "Total Chips Encountered: 33361\n",
            "Chips Successfully Saved: 16449 (49.31%)\n",
            "----------------------------------------\n",
            "Total Chips Skipped: 16912 (50.69%)\n",
            "  - Skipped due to 'Ignore' pixel: 16888\n",
            "  - Skipped due to missing elevation (NaN): 0\n",
            "  - Skipped due to RGB transparency: 22\n",
            "  - Skipped due to unknown label colors: 2\n",
            "========================================\n",
            "Transparency Tiles: ['1476907971_CHADGRISMOPENPIPELINE_3072_4352', '1476907971_CHADGRISMOPENPIPELINE_3328_4352', '107f24d6e9_F1BE1D4184INSPIRE_8448_256', '25f1c24f30_EB81FE6E2BOPENPIPELINE_768_9984', '25f1c24f30_EB81FE6E2BOPENPIPELINE_1024_9984', '25f1c24f30_EB81FE6E2BOPENPIPELINE_768_10240', 'cc4b443c7d_A9CBEF2C97INSPIRE_1024_768', 'b771104de5_7E02A41EBEOPENPIPELINE_1024_768', 'b771104de5_7E02A41EBEOPENPIPELINE_1280_768', 'b771104de5_7E02A41EBEOPENPIPELINE_1024_2048', 'b771104de5_7E02A41EBEOPENPIPELINE_1280_2048', 'b771104de5_7E02A41EBEOPENPIPELINE_256_2560', 'b771104de5_7E02A41EBEOPENPIPELINE_512_2560', 'b771104de5_7E02A41EBEOPENPIPELINE_768_2816', 'b771104de5_7E02A41EBEOPENPIPELINE_1024_2816', 'ec09336a6f_06BA0AF311OPENPIPELINE_3584_256', '1553627230_APIGENERATED_2816_1024', '2ef883f08d_F317F9C1DFOPENPIPELINE_1792_3328', '84410645db_8D20F02042OPENPIPELINE_768_256', '84410645db_8D20F02042OPENPIPELINE_3584_3840', '420d6b69b8_84B52814D2OPENPIPELINE_4096_6400', '420d6b69b8_84B52814D2OPENPIPELINE_2560_6912']\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from scipy.stats import entropy\n",
        "import warnings\n",
        "import rasterio\n",
        "\n",
        "# Suppress noisy warnings from rasterio\n",
        "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
        "\n",
        "transparency_tiles = []\n",
        "\n",
        "# === CONFIG ===\n",
        "IN_DIR = 'dataset-medium'\n",
        "OUT_DIR = 'chipped_data'\n",
        "TILE_SIZE = 512\n",
        "STRIDE = 256\n",
        "IGNORE_COLOR = (255, 0, 255)\n",
        "BACKGROUND_COLOR_RGB = (255, 255, 255)\n",
        "\n",
        "# --- Class definitions---\n",
        "NUM_CLASSES = 6\n",
        "CLASS_NAMES = ['Building', 'Vegetation', 'Water', 'Background', 'Car', 'Road']\n",
        "COLOR_TO_CLASS = {\n",
        "    (230, 25, 75): 0,    # Building\n",
        "    (60, 180, 75): 1,    # Vegetation\n",
        "    (0, 130, 200): 2,    # Water\n",
        "    (255, 255, 255): 3,  # Background\n",
        "    (245, 130, 48): 4,   # Car\n",
        "    (128, 128, 128): 5,  # Road\n",
        "}\n",
        "# -----------------------------------------\n",
        "\n",
        "# === UTILS ===\n",
        "def standardise_elevation(elev, raster_nodata=-32767):\n",
        "    valid_mask = elev != raster_nodata\n",
        "    valid_elev = elev[valid_mask]\n",
        "    if valid_elev.size == 0:\n",
        "        return np.zeros_like(elev, dtype=np.float32)\n",
        "    mean = valid_elev.mean()\n",
        "    std = valid_elev.std()\n",
        "    standardised = np.zeros_like(elev, dtype=np.float32)\n",
        "    if std > 0:\n",
        "        standardised[valid_mask] = (valid_elev - mean) / std\n",
        "    return standardised\n",
        "\n",
        "# === CHIP FUNCTION ===\n",
        "def chip_all():\n",
        "    train_rows = []\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "    source_files = [f for f in os.listdir(os.path.join(IN_DIR, 'images')) if f.endswith('-ortho.tif')]\n",
        "\n",
        "    # NEW: Global counters for the final summary\n",
        "    total_chips_encountered = 0\n",
        "    passed_chips = 0\n",
        "    skipped_due_to_ignore = 0\n",
        "    skipped_due_to_elevation = 0\n",
        "    skipped_due_to_transparency = 0\n",
        "    skipped_due_to_unknown_color = 0\n",
        "\n",
        "    for fname in tqdm(source_files, desc=\"Chipping Scenes\"):\n",
        "        # ... (file loading logic is the same)\n",
        "        base = fname.replace('-ortho.tif', '')\n",
        "        rgb_path = os.path.join(IN_DIR, 'images', f'{base}-ortho.tif')\n",
        "        elev_path = os.path.join(IN_DIR, 'elevations', f'{base}-elev.tif')\n",
        "        label_path = os.path.join(IN_DIR, 'labels', f'{base}-label.png')\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        alpha = None\n",
        "        with rasterio.open(rgb_path) as src:\n",
        "            rgb = src.read([1,2,3]).transpose(1, 2, 0)\n",
        "            if src.count >= 4:\n",
        "                alpha = src.read(4)\n",
        "\n",
        "        with rasterio.open(elev_path) as src:\n",
        "            elev = src.read(1).astype(np.float32)\n",
        "\n",
        "        label = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert Clutter to Background\n",
        "        clutter_color = np.array([145, 30, 180])\n",
        "        clutter_mask = np.all(label == clutter_color, axis=2)\n",
        "        label[clutter_mask] = BACKGROUND_COLOR_RGB\n",
        "\n",
        "        h, w = rgb.shape[:2]\n",
        "        elev_std = standardise_elevation(elev)\n",
        "\n",
        "        for y in range(0, h - TILE_SIZE + 1, STRIDE):\n",
        "            for x in range(0, w - TILE_SIZE + 1, STRIDE):\n",
        "                total_chips_encountered += 1\n",
        "\n",
        "                label_tile_rgb = label[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
        "                elev_tile = elev[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
        "\n",
        "                # --- All Skip Conditions ---\n",
        "                if np.any(np.all(label_tile_rgb == IGNORE_COLOR, axis=-1)):\n",
        "                    skipped_due_to_ignore += 1\n",
        "                    continue\n",
        "\n",
        "                if np.isnan(elev_tile).any():\n",
        "                    skipped_due_to_elevation += 1\n",
        "                    continue\n",
        "\n",
        "                if alpha is not None:\n",
        "                    alpha_tile = alpha[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
        "                    if np.any(alpha_tile < 255):\n",
        "                        skipped_due_to_transparency += 1\n",
        "                        transparency_tiles.append(f\"{base}_{x}_{y}\")\n",
        "                        continue\n",
        "\n",
        "                # --- Unknown Color Check/Conversion ---\n",
        "                label_ids = np.full((TILE_SIZE, TILE_SIZE), -1, dtype=np.int32)\n",
        "                for color_rgb, class_idx in COLOR_TO_CLASS.items():\n",
        "                    mask = np.all(label_tile_rgb == color_rgb, axis=-1)\n",
        "                    label_ids[mask] = class_idx\n",
        "\n",
        "                if np.any(label_ids == -1):\n",
        "                    skipped_due_to_unknown_color += 1\n",
        "                    continue # Skip chips with colors not in our final ontology\n",
        "\n",
        "                # --- If all checks pass, save the chip ---\n",
        "                passed_chips += 1\n",
        "                tile_id = f\"{base}_{x}_{y}\"\n",
        "                rgb_tile = rgb[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
        "                elev_tile_std = elev_std[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
        "\n",
        "                # ... (metadata calculation and saving logic is the same)\n",
        "                counts = np.bincount(label_ids.flatten(), minlength=NUM_CLASSES).astype(np.int64)\n",
        "                class_percentages = counts / (TILE_SIZE * TILE_SIZE)\n",
        "                entropy_val = entropy(class_percentages + 1e-9, base=2)\n",
        "\n",
        "                for folder in ['images', 'elevations', 'labels']:\n",
        "                    os.makedirs(os.path.join(OUT_DIR, 'train', folder), exist_ok=True)\n",
        "\n",
        "                cv2.imwrite(os.path.join(OUT_DIR, 'train', 'images', f'{tile_id}-ortho.png'), cv2.cvtColor(rgb_tile, cv2.COLOR_RGB2BGR))\n",
        "                np.save(os.path.join(OUT_DIR, 'train', 'elevations', f'{tile_id}-elev.npy'), elev_tile_std)\n",
        "                cv2.imwrite(os.path.join(OUT_DIR, 'train', 'labels', f'{tile_id}-label.png'), cv2.cvtColor(label_tile_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                train_rows.append([tile_id, base, x, y] + class_percentages.tolist() + [float(entropy_val)] + counts.tolist())\n",
        "\n",
        "    # Save metadata files\n",
        "    with open(os.path.join(OUT_DIR, 'train_metadata.csv'), 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        header = ['tile_id', 'source_file', 'x', 'y'] + [f'dist_{i}:{name}' for i, name in enumerate(CLASS_NAMES)] + ['entropy'] + [f'count_{i}:{name}' for i, name in enumerate(CLASS_NAMES)]\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(train_rows)\n",
        "\n",
        "    # NEW: Final summary printout\n",
        "    total_skipped = total_chips_encountered - passed_chips\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"--- CHIPPING COMPLETE: FINAL SUMMARY ---\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Total Chips Encountered: {total_chips_encountered}\")\n",
        "    print(f\"Chips Successfully Saved: {passed_chips} ({passed_chips/total_chips_encountered:.2%})\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Total Chips Skipped: {total_skipped} ({total_skipped/total_chips_encountered:.2%})\")\n",
        "    print(f\"  - Skipped due to 'Ignore' pixel: {skipped_due_to_ignore}\")\n",
        "    print(f\"  - Skipped due to missing elevation (NaN): {skipped_due_to_elevation}\")\n",
        "    print(f\"  - Skipped due to RGB transparency: {skipped_due_to_transparency}\")\n",
        "    print(f\"  - Skipped due to unknown label colors: {skipped_due_to_unknown_color}\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"Transparency Tiles:\", transparency_tiles)\n",
        "    print(\"=\"*40)\n",
        "\n",
        "# === RUN ===\n",
        "chip_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
