{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "# === CONFIG ===\n",
    "IN_DIR = '/content/dataset-medium'\n",
    "OUT_DIR = '/content/chipped_data'\n",
    "RAW_DIR = os.path.join(OUT_DIR, 'raw')\n",
    "TILE_SIZE = 256\n",
    "STRIDE = 128\n",
    "LARGE_TILE_SIZE = 1024\n",
    "IGNORE_COLOR = (255, 0, 255)\n",
    "IGNORE_THRESHOLD = 0.0\n",
    "BACKGROUND_CLASS = 4\n",
    "BACKGROUND_SKIP_THRESHOLD = 0.95\n",
    "\n",
    "COLOR_TO_CLASS = {\n",
    "    (230, 25, 75): 0,\n",
    "    (145, 30, 180): 1,\n",
    "    (60, 180, 75): 2,\n",
    "    (245, 130, 48): 3,\n",
    "    (255, 255, 255): 4,\n",
    "    (0, 130, 200): 5\n",
    "}\n",
    "\n",
    "RARE_CLASSES = [0, 1, 3, 5]\n",
    "CLASS_NAMES = ['Building', 'Clutter', 'Vegetation', 'Water', 'Background', 'Car']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "PROBLEM_REGIONS = {\n",
    "    \"25f1c24f30_EB81FE6E2BOPENPIPELINE\": [\n",
    "        {\"x\": 4050, \"y\": 0, \"w\": 1300, \"h\": 1050},\n",
    "        {\"x\": 3700, \"y\": 3650, \"w\": 200, \"h\": 170},\n",
    "        {\"x\": 3525, \"y\": 3810, \"w\": 250, \"h\": 190},\n",
    "        {\"x\": 3780, \"y\": 3580, \"w\": 200, \"h\": 160}\n",
    "    ],\n",
    "    \"39e77bedd0_729FB913CDOPENPIPELINE\": [\n",
    "        {\"x\": 2900, \"y\": 2700, \"w\": 250, \"h\": 100}\n",
    "    ],\n",
    "    \"a1af86939f_F1BE1D4184OPENPIPELINE\": [\n",
    "        {\"x\": 0, \"y\": 800, \"w\": 300, \"h\": 110}\n",
    "    ]\n",
    "}\n",
    "\n",
    "def read_elevation_float32(path):\n",
    "    tif = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if tif is None:\n",
    "        return None\n",
    "    if len(tif.shape) == 3 and tif.shape[2] > 1:\n",
    "        tif = tif[:, :, 0]\n",
    "    return tif.astype(np.float32)\n",
    "\n",
    "def overlaps_problem_region(x, y, base_name):\n",
    "    if base_name not in PROBLEM_REGIONS:\n",
    "        return False\n",
    "    for region in PROBLEM_REGIONS[base_name]:\n",
    "        rx, ry, rw, rh = region['x'], region['y'], region['w'], region['h']\n",
    "        if (x + TILE_SIZE > rx and x < rx + rw and y + TILE_SIZE > ry and y < ry + rh):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def chip_image(rgb_path, elev_path, label_path, base_name, metadata_rows):\n",
    "    rgb = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "    elev = read_elevation_float32(elev_path)\n",
    "    label = cv2.imread(label_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    h, w, _ = rgb.shape\n",
    "\n",
    "    for y in range(0, h - TILE_SIZE + 1, STRIDE):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STRIDE):\n",
    "            if overlaps_problem_region(x, y, base_name):\n",
    "                continue\n",
    "\n",
    "            rgb_tile = rgb[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "            elev_tile = elev[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "            label_tile = label[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "\n",
    "            if np.mean(np.all(label_tile == IGNORE_COLOR, axis=-1)) > IGNORE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            label_tile_rgb = cv2.cvtColor(label_tile, cv2.COLOR_BGR2RGB)\n",
    "            label_ids = np.full((TILE_SIZE, TILE_SIZE), -1, dtype=np.int32)\n",
    "            for color_rgb, class_idx in COLOR_TO_CLASS.items():\n",
    "                mask = np.all(label_tile_rgb == color_rgb, axis=-1)\n",
    "                label_ids[mask] = class_idx\n",
    "\n",
    "            if np.any(label_ids == -1):\n",
    "                continue\n",
    "\n",
    "            counts = np.array([(label_ids == i).sum() for i in range(NUM_CLASSES)], dtype=np.float32)\n",
    "            class_percentages = counts / max(counts.sum(), 1)\n",
    "            background_pct = class_percentages[BACKGROUND_CLASS]\n",
    "\n",
    "            if background_pct == 1.0 or (background_pct > BACKGROUND_SKIP_THRESHOLD and not any(counts[i] > 0 for i in RARE_CLASSES)):\n",
    "                continue\n",
    "\n",
    "            tile_id = f\"{base_name}_{x}_{y}\"\n",
    "\n",
    "            for folder in ['images', 'elevations', 'labels']:\n",
    "                os.makedirs(os.path.join(OUT_DIR, 'train', folder), exist_ok=True)\n",
    "\n",
    "            cv2.imwrite(os.path.join(OUT_DIR, 'train', 'images', f'{tile_id}-ortho.png'), cv2.cvtColor(rgb_tile, cv2.COLOR_RGB2BGR))\n",
    "            np.save(os.path.join(OUT_DIR, 'train', 'elevations', f'{tile_id}-elev.npy'), elev_tile)\n",
    "            cv2.imwrite(os.path.join(OUT_DIR, 'train', 'labels', f'{tile_id}-label.png'), label_tile)\n",
    "\n",
    "            entropy_val = entropy(class_percentages + 1e-9, base=2)\n",
    "            metadata_rows.append([tile_id, base_name, x, y] + class_percentages.tolist() + [float(entropy_val)])\n",
    "    pass\n",
    "\n",
    "def chip_raw_large_tiles():\n",
    "    metadata_rows = []\n",
    "    for fname in tqdm(os.listdir(os.path.join(IN_DIR, 'images')), desc=\"üîÑ Chipping raw directory\"):\n",
    "        if not fname.endswith('-ortho.tif'):\n",
    "            continue\n",
    "        base = fname.replace('-ortho.tif', '')\n",
    "\n",
    "        rgb_path = os.path.join(IN_DIR, 'images', f'{base}-ortho.tif')\n",
    "        elev_path = os.path.join(IN_DIR, 'elevations', f'{base}-elev.tif')\n",
    "        label_path = os.path.join(IN_DIR, 'labels', f'{base}-label.png')\n",
    "\n",
    "        rgb = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "        elev = read_elevation_float32(elev_path)\n",
    "        label = cv2.imread(label_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        h, w, _ = rgb.shape\n",
    "        nx = max(1, w // LARGE_TILE_SIZE)\n",
    "        ny = max(1, h // LARGE_TILE_SIZE)\n",
    "\n",
    "        x_start = (w - nx * LARGE_TILE_SIZE) // 2\n",
    "        y_start = (h - ny * LARGE_TILE_SIZE) // 2\n",
    "\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                x = x_start + i * LARGE_TILE_SIZE\n",
    "                y = y_start + j * LARGE_TILE_SIZE\n",
    "\n",
    "                rgb_tile = rgb[y:y+LARGE_TILE_SIZE, x:x+LARGE_TILE_SIZE]\n",
    "                elev_tile = elev[y:y+LARGE_TILE_SIZE, x:x+LARGE_TILE_SIZE]\n",
    "                label_tile = label[y:y+LARGE_TILE_SIZE, x:x+LARGE_TILE_SIZE]\n",
    "\n",
    "                tile_id = f\"{base}_{x}_{y}\"\n",
    "                for folder in ['images', 'elevations', 'labels']:\n",
    "                    os.makedirs(os.path.join(RAW_DIR, folder), exist_ok=True)\n",
    "\n",
    "                cv2.imwrite(os.path.join(RAW_DIR, 'images', f'{tile_id}-ortho.png'), cv2.cvtColor(rgb_tile, cv2.COLOR_RGB2BGR))\n",
    "                np.save(os.path.join(RAW_DIR, 'elevations', f'{tile_id}-elev.npy'), elev_tile)\n",
    "                cv2.imwrite(os.path.join(RAW_DIR, 'labels', f'{tile_id}-label.png'), label_tile)\n",
    "\n",
    "                label_tile_rgb = cv2.cvtColor(label_tile, cv2.COLOR_BGR2RGB)\n",
    "                label_ids = np.full((LARGE_TILE_SIZE, LARGE_TILE_SIZE), -1, dtype=np.int32)\n",
    "                for color_rgb, class_idx in COLOR_TO_CLASS.items():\n",
    "                    mask = np.all(label_tile_rgb == color_rgb, axis=-1)\n",
    "                    label_ids[mask] = class_idx\n",
    "\n",
    "                counts = np.array([(label_ids == i).sum() for i in range(NUM_CLASSES)], dtype=np.float32)\n",
    "                class_percentages = counts / max(counts.sum(), 1)\n",
    "                entropy_val = entropy(class_percentages + 1e-9, base=2)\n",
    "                metadata_rows.append([tile_id, base, x, y] + class_percentages.tolist() + [float(entropy_val)])\n",
    "\n",
    "    csv_path = os.path.join(RAW_DIR, 'raw_metadata.csv')\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = ['tile_id', 'source_file', 'x', 'y'] + [f'{i}: {name}' for i, name in enumerate(CLASS_NAMES)] + ['entropy']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(metadata_rows)\n",
    "    print(f\"‚úÖ Raw metadata saved to {csv_path}\")\n",
    "    print(f\"üìä Total raw tiles: {len(metadata_rows)}\")\n",
    "\n",
    "def chip_all():\n",
    "    metadata = {'train': []}\n",
    "\n",
    "    for fname in tqdm(os.listdir(os.path.join(IN_DIR, 'images')), desc=\"üîÑ Chipping dataset\"):\n",
    "        if not fname.endswith('-ortho.tif'):\n",
    "            continue\n",
    "        base = fname.replace('-ortho.tif', '')\n",
    "        rgb_path = os.path.join(IN_DIR, 'images', f'{base}-ortho.tif')\n",
    "        elev_path = os.path.join(IN_DIR, 'elevations', f'{base}-elev.tif')\n",
    "        label_path = os.path.join(IN_DIR, 'labels', f'{base}-label.png')\n",
    "\n",
    "        if os.path.exists(rgb_path) and os.path.exists(elev_path) and os.path.exists(label_path):\n",
    "            chip_image(rgb_path, elev_path, label_path, base, metadata['train'])\n",
    "\n",
    "    csv_path = os.path.join(OUT_DIR, 'train_metadata.csv')\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = ['tile_id', 'source_file', 'x', 'y'] + [f'{i}: {name}' for i, name in enumerate(CLASS_NAMES)] + ['entropy']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(metadata['train'])\n",
    "\n",
    "    print(f\"‚úÖ Train metadata saved to {csv_path}\")\n",
    "    print(f\"üìä Total train tiles: {len(metadata['train'])}\")\n",
    "\n",
    "def copy_raw_dataset():\n",
    "    for folder in ['images', 'elevations', 'labels']:\n",
    "        os.makedirs(os.path.join(RAW_DIR, folder), exist_ok=True)\n",
    "\n",
    "    for src_file in os.listdir(os.path.join(IN_DIR, 'images')):\n",
    "        base = src_file.replace('-ortho.tif', '')\n",
    "        try:\n",
    "            shutil.copy(os.path.join(IN_DIR, 'images', f'{base}-ortho.tif'), os.path.join(RAW_DIR, 'images', f'{base}-ortho.tif'))\n",
    "            shutil.copy(os.path.join(IN_DIR, 'elevations', f'{base}-elev.tif'), os.path.join(RAW_DIR, 'elevations', f'{base}-elev.tif'))\n",
    "            shutil.copy(os.path.join(IN_DIR, 'labels', f'{base}-label.png'), os.path.join(RAW_DIR, 'labels', f'{base}-label.png'))\n",
    "        except:\n",
    "            print(f\"‚ùå Skipping {base} due to missing files\")\n",
    "\n",
    "\n",
    "# === Run ===\n",
    "for split in ['train']:\n",
    "    for folder in ['images', 'elevations', 'labels']:\n",
    "        os.makedirs(os.path.join(OUT_DIR, split, folder), exist_ok=True)\n",
    "\n",
    "chip_all()\n",
    "chip_raw_large_tiles()\n",
    "print(\"\\n‚úÖ Done! Train = chips, Raw = full image chips.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
